{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"my-nequip-tutorial.ipynb","provenance":[{"file_id":"1_r348f6oIyKxH4FnpKeD8g4QjwDhP8mT","timestamp":1656689687220}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"CFpAi8g9XmUU"},"source":["# Molecular Dynamics with NequIP \n","\n","### Authors: Simon Batzner, Albert Musaelian, Lixin Sun, Anders Johansson, Boris Kozinsky"]},{"cell_type":"markdown","metadata":{"id":"xMnK_PtDZ32t"},"source":["<img src=\"https://github.com/mir-group/nequip_mrs_tutorial/blob/master/nequip3.png?raw=true\" width=\"60%\">"]},{"cell_type":"markdown","metadata":{"id":"O6YiV6ShQWB2"},"source":["## What is this? \n","\n","This is a Colab tutorial for NequIP, software for building extremely accurate Machine Learning Interatomic Potentials. The ideas are described in the paper below. We have released an open-source software with the goal of building NequIP potentials with a few simple commands, at the Github link below. This tutorial serves as a simple introduction into the NequIP code. \n","\n","The goal of NequIP is to be as simple as possible. You will never have to write a single line of Python, but instead you can train a network with one single command and you will be ready to run MD with it in LAMMPS or ASE. \n","\n","Paper: https://www.nature.com/articles/s41467-022-29939-5\n","\n","Code: https://github.com/mir-group/nequip"]},{"cell_type":"markdown","metadata":{"id":"_8gImqa_N_e1"},"source":["## Contents\n","\n","This tutorial will teach you how to:\n","\n","* Train a model \n","* Deploy the model intro production\n","* Run MD with it in LAMMPS\n","\n","We will do all this in this Colab, including LAMMPS. Training + inference will take only about 10 minutes. Before you get started, however, you will have to compile LAMMPS which takes approximately 5 minutes. Once we have installed NequIP + LAMMPS, we're ready to get started. \n"]},{"cell_type":"markdown","metadata":{"id":"jYSB405TdZWF"},"source":["## Before you begin üõë\n","\n","1. Save a copy of this colab in your own drive \n","2. Run the first two code cells below to install NequIP and the Molecular Dynamics code LAMMPS \n","\n","## Now you're ready to get started :) ‚úÖ"]},{"cell_type":"code","source":["import warnings\n","import os\n","\n","USE_COLAB = True\n","if USE_COLAB == True:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    work_dir = '/content/drive/MyDrive/Colab Notebooks/nequip/'\n","else:\n","    work_dir = '/Users/gabrieletocci/Google Drive/My Drive/Colab Notebooks/nequip/'\n","\n","! rm -r /content/AIMD-water-ions-traj\n","! rm -r /content/AIMD-water\n","! unzip /Users/gabrieletocci/Google\\ \\Drive/My\\ \\Drive/Colab\\ \\Notebooks/MD_DFT/*zip\n","! unzip /content/drive/MyDrive/Colab\\ \\Notebooks/MD_DFT/AIMD-water.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZOLIFOJZaeZ5","executionInfo":{"status":"ok","timestamp":1656690045374,"user_tz":-120,"elapsed":14579,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"6891a17d-1348-44d7-979d-6c729607f8a6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","rm: cannot remove '/content/AIMD-water-ions-traj': No such file or directory\n","rm: cannot remove '/content/AIMD-water': No such file or directory\n","unzip:  cannot find or open /Users/gabrieletocci/Google Drive/My Drive/Colab Notebooks/MD_DFT/*zip, /Users/gabrieletocci/Google Drive/My Drive/Colab Notebooks/MD_DFT/*zip.zip or /Users/gabrieletocci/Google Drive/My Drive/Colab Notebooks/MD_DFT/*zip.ZIP.\n","\n","No zipfiles found.\n","Archive:  /content/drive/MyDrive/Colab Notebooks/MD_DFT/AIMD-water.zip\n","   creating: AIMD-water/\n","  inflating: AIMD-water/WATER-frc-1.xyz.gz  \n","  inflating: AIMD-water/celldata.dat  \n","  inflating: AIMD-water/WATER-pos-1.xyz.gz  \n"]}]},{"cell_type":"code","source":["def MD_reader_xyz(f, data_dir, no_skip = 0):\n","  filename = os.path.join(data_dir, f)\n","  fo = open(filename, 'r')\n","  natoms_str = fo.read().rsplit(' i = ')[0]\n","  natoms = int(natoms_str.split('\\n')[0])\n","  fo.close()  \n","  fo = open(filename, 'r')\n","  samples = fo.read().split(natoms_str)[1:]\n","  steps = []\n","  xyz = []\n","  temperatures = []\n","  energies = []\n","  for sample in samples[::no_skip]:\n","     entries = sample.split('\\n')[:-1]\n","     energies.append(float(entries[0].split(\"=\")[-1]))\n","     temp = np.array([list(map(float, lv.split()[1:])) for lv in entries[1:]])\n","     xyz.append(temp[:,:])\n","  return natoms_str, np.array(xyz), np.array(energies)     "],"metadata":{"id":"jDJ9Re0arOb0","executionInfo":{"status":"ok","timestamp":1656694348490,"user_tz":-120,"elapsed":222,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["def read_cell(f,data_dir):\n","  filename = os.path.join(data_dir,f)\n","  fo = open(filename,'r')\n","  cell_list_abc = fo.read().split('\\n')[:-1]\n","  cell_vec_abc = np.array([list(map(float, lv.split())) for lv in cell_list_abc]).squeeze()\n","  return(cell_vec_abc)\n","\n","cell_vec_abc = read_cell('celldata.dat','/content/AIMD-water')\n","cell_vec_abc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2U5i3IZqLBI","executionInfo":{"status":"ok","timestamp":1656694043933,"user_tz":-120,"elapsed":3,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"5962bc78-8285-4935-bb86-c94cc4a77b4a"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([9.85, 9.85, 9.85])"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["H2 = read(work_dir+'../MD_DFT/H2.extxyz')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vdKm0dSFoo-9","executionInfo":{"status":"ok","timestamp":1656693783159,"user_tz":-120,"elapsed":215,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"02341899-da20-46a9-83f8-0af4d1c9a0cc"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-0.        , -0.        , -0.00053835],\n","       [-0.        , -0.        ,  0.00053835]])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["! head /content/drive/MyDrive/Colab\\ \\Notebooks/MD_DFT/H2.extxyz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9EB3TV52stVU","executionInfo":{"status":"ok","timestamp":1656694720525,"user_tz":-120,"elapsed":1012,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"c6460b77-9ba7-4ef8-fe38-67f5e444a7cf"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n","Lattice=\"6.0 0.0 0.0 0.0 6.0 0.0 0.0 0.0 6.0\" Properties=species:S:1:pos:R:3:forces:R:3:magmoms:R:1 energy=-6.801137982077364 dipole=\"-1.3543798178593251e-15 -1.5609399349163789e-15 6.566746345129899e-16\" magmom=0.0 pbc=\"F F F\"\n","H        3.00000000       3.00000000       2.62674398      -0.00000000      -0.00000000      -0.00053835       0.00000000\n","H        3.00000000       3.00000000       3.37325602      -0.00000000      -0.00000000       0.00053835       0.00000000\n"]}]},{"cell_type":"code","source":["H2.get_forces()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CriwddQ4r067","executionInfo":{"status":"ok","timestamp":1656694908751,"user_tz":-120,"elapsed":4,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"a5a4d899-a2ba-4155-f5b9-0de80563cf3d"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-0.        , -0.        , -0.00053835],\n","       [-0.        , -0.        ,  0.00053835]])"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["! gunzip /content/AIMD-water/WATER-frc-1.xyz.gz\n","! gunzip /content/AIMD-water/WATER-pos-1.xyz.gz"],"metadata":{"id":"Gyy4J3b6bDHO","executionInfo":{"status":"ok","timestamp":1656690084267,"user_tz":-120,"elapsed":21110,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["wat_traj = read('/content/AIMD-water/WATER-pos-1.xyz',index=':')\n","wat_frc = read('/content/AIMD-water/WATER-frc-1.xyz',index=':')"],"metadata":{"id":"X9fcRMYnu5-V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["natoms, positions, energies = MD_reader_xyz('WATER-pos-1.xyz', '/content/AIMD-water/', no_skip = 1)"],"metadata":{"id":"jT7B4ryYu82t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZPqnt-SAXyvL"},"source":["### Turn on GPU\n","\n","Make sure Runtime --> Change runtime type is set to GPU"]},{"cell_type":"code","metadata":{"id":"0XTzJ0cj-jmS","executionInfo":{"status":"ok","timestamp":1656690215178,"user_tz":-120,"elapsed":23549,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}}},"source":["%%capture\n","# install wandb\n","!pip install wandb\n","# install nequip\n","!git clone --depth 1 \"https://github.com/gabriele16/nequip.git\"\n","!pip install nequip/\n","# fix colab imports\n","import site\n","site.main()\n","# set to allow anonymous WandB\n","import os\n","os.environ[\"WANDB_ANONYMOUS\"] = \"must\"\n","import numpy as np\n","import torch \n","from ase.io import read, write\n","np.random.seed(0)\n","torch.manual_seed(0)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"u0j3j9gVp0C7","executionInfo":{"status":"ok","timestamp":1656690559896,"user_tz":-120,"elapsed":334205,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}}},"source":["%%capture\n","# compile lammps\n","!wget \"https://github.com/lammps/lammps/archive/stable.zip\"\n","!unzip -q stable.zip\n","!rm stable.zip\n","!mv lammps-stable lammps\n","!wget \"https://github.com/mir-group/pair_nequip/archive/main.zip\"\n","!unzip -q main.zip\n","!rm main.zip\n","!mv pair_nequip-main pair_nequip\n","!cd pair_nequip && ./patch_lammps.sh ../lammps\n","!pip install mkl mkl-include\n","!cd lammps && mkdir -p build && cd build && cmake ../cmake -DCMAKE_PREFIX_PATH=`python -c 'import torch;print(torch.utils.cmake_prefix_path)'` && make -j4"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-HDmxkn3z8_m"},"source":["## 3 Steps: \n","* Train: using a data set, train the neural network üß† \n","* Deploy: convert the Python-based model into a stand-alone potential file for fast execution ‚ö°\n","* Run: run Molecular Dynamics, Monte Carlo, Structural Minimization, ...  with it in LAMMPS üèÉ"]},{"cell_type":"markdown","metadata":{"id":"6OD71eeDz7dA"},"source":["<img src=\"https://github.com/mir-group/nequip_mrs_tutorial/blob/master/all.png?raw=true\" width=\"60%\">"]},{"cell_type":"markdown","metadata":{"id":"62aEgq6QYFIn"},"source":["### Train a model"]},{"cell_type":"markdown","metadata":{"id":"ELdBzH_8z4_2"},"source":["<img src=\"https://github.com/mir-group/nequip_mrs_tutorial/blob/master/train.png?raw=true\" width=\"60%\">"]},{"cell_type":"markdown","metadata":{"id":"qX0QKkAauSZO"},"source":["This tutorial is set up to use `wandb` in anonymous mode; when you use NequIP yourself you will be presented with a login prompt."]},{"cell_type":"markdown","metadata":{"id":"1KuOIippfVfd"},"source":["Here, we will train a NequIP potential on the following system\n","\n","* Toluene\n","* sampled at T=500K from AIMD\n","* at CCSD(T) accuracy (gold standard of quantum chemistry)\n","* Using 100 training configurations\n","* The units of the reference data are in kcal/mol and A. If you're more familiar with eV, remember 1 kcal/mol is chemical accuracy and is approximately 43 meV"]},{"cell_type":"markdown","metadata":{"id":"2q_GyQfC0npt"},"source":["Start a training run: this will print output to our console, but it is usually more convenient to view the results in a web interface called Weights and Biases. Click the link next to the rocket emoji to watch the run in the WandB interface üöÄ \n","\n","In WandB, watch the followingkeys:\n","\n","* Plot 1: validation_all_f_mae, training_all_f_mae\n","* Plot 2: validation_e/N_mae, training_e/N_mae\n","\n","These are the validation/training error in all force components and the validation/training error in the potential energy, normalized by the number of atoms, respectively. "]},{"cell_type":"code","source":["from nequip.utils import Config\n","config = Config.from_file('./tutorial.yaml')\n","config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"id":"fFCszShRk2RP","executionInfo":{"status":"error","timestamp":1656692646668,"user_tz":-120,"elapsed":648,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"c0f1ae7f-9162-48a0-a0d0-e705bc608d54"},"execution_count":12,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-6ec23e2a3db6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnequip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./tutorial.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nequip/utils/config.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(filename, format, defaults)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0msupported_formats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msupported_formats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0menforced_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         )\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nequip/utils/savenload.py\u001b[0m in \u001b[0;36mload_file\u001b[0;34m(supported_formats, filename, enforced_format)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mabs_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"file {filename} at {abs_path} is not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"json\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: file ./tutorial.yaml at /content/tutorial.yaml is not found"]}]},{"cell_type":"code","source":["!head benchmark_data/toluene_ccsd_t-test.npz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CFlsyXcEhZ0M","executionInfo":{"status":"ok","timestamp":1656691773269,"user_tz":-120,"elapsed":226,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"e4cdcd8c-1724-478f-af83-95ac69f95091"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["PK\u0003\u0004\u0014\u0000\u0000\u0000\b\u0000›Å\u0001M\u0019ÔøΩÔøΩÔøΩV\f\u0000\u0000ÔøΩ\u000f\u0000\u0000\u0005\u0000\u0000\u0000E.npy-Wy8ÔøΩk\u0017ÔøΩ\u0014\u0019\u001a)DÔøΩÔøΩ`LÔøΩÔøΩ&)CÔøΩ\u0012ÔøΩ\u0014\u000eÔøΩ\fq\t\u0019ÔøΩÔøΩ\u001e%\u0014ÔøΩTN\u00177IHÔøΩ‰ö¢ÔøΩ`\bÔøΩ\"S2ÔøΩL\t\u0017ÔøΩ^ÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩ^{ÔøΩÔøΩ7176=ÔøΩŒ∂ÔøΩ-HÔøΩÔøΩÔøΩOÔøΩÔøΩÔøΩ6qYÔøΩc\u001aÔøΩrÔøΩ«º||}\u001c<ÔøΩzÔøΩ89√øÔøΩÔøΩÔøΩOgÔøΩÔøΩyÔøΩÔøΩ3ÔøΩ\u001bTÔøΩÔøΩÔøΩƒï7 âÔøΩÔøΩÔøΩÔøΩÔøΩ-\u0014*ÔøΩ\u001dÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩDEÔøΩ\u0002ÔøΩÁ∂æÔøΩD\u0005\bM\u000ev|ÔøΩ!ÔøΩÔøΩÔøΩwÔøΩÔøΩ\bÔøΩgÔøΩÔøΩ?ÔøΩÔøΩÔøΩ\u00115ÔøΩVÔøΩÔøΩ:^ÔøΩÔøΩÔøΩ~RÔøΩÔøΩRÔøΩ2ÔøΩ\t\u0007v1ÔøΩ(\u0013\n","ÔøΩK2m\tÔøΩ\u00022ÔøΩÔøΩ\u0013ÔøΩÔøΩÔøΩ\\ÔøΩÔøΩ÷±X1ÔøΩÔøΩÔøΩÔøΩ,ÔøΩÔøΩÔøΩ>ÔøΩ3∆ÆÔøΩÔøΩx)sÔøΩÔøΩ\u0003ÔøΩGlÔøΩw\u001a\u0010ÔøΩN]ÔøΩÔøΩ¬ºg<)ÔøΩÔøΩBÔøΩvÔøΩÔøΩ4/rYÔøΩÔøΩoÔøΩÔøΩ\u0014ÔøΩÔøΩ\u0012ÔøΩskÔøΩÔøΩÔøΩÔøΩ>zlLpÔøΩÔøΩÔøΩRÔøΩ[\u0007ÔøΩw\u0007’´ÔøΩB<ÔøΩÔøΩÔøΩ9ÔøΩÔøΩvÔøΩaÔøΩe7ÔøΩ\tÔøΩ'ÔøΩ~ZÔøΩÔøΩpÔøΩÔøΩÔøΩÔøΩ ÔøΩÔøΩÔøΩ\u0018ÔøΩm [@ÔøΩÔøΩÔøΩlvÔøΩÔøΩaÔøΩÔøΩlHÔøΩÔøΩAÔøΩÔøΩ\u000fÔøΩg6\u0013ÔøΩÔøΩÔøΩ\u0013ÔøΩJh`uÔøΩ\u0016ÔøΩ\u0006MÔøΩÔøΩf#LÔøΩÔøΩn\u0016\"ÔøΩÔøΩ5ÔøΩÔøΩq\u0001iÔøΩ6ÔøΩÔøΩM_ÔøΩ!ÔøΩÔøΩÔøΩ\u001cNÔøΩÔøΩÔøΩ\"\rÔøΩ3ÔøΩnÔøΩzdÔøΩwÔøΩÔøΩÔøΩÔøΩ\u0005ÔøΩ?ÔøΩÔøΩc\u00077ÔøΩ~IÔøΩWÔøΩÔøΩ\u001eÔøΩÔøΩÔøΩ'ÔøΩÔøΩsÔøΩm\u0004ÔøΩÔøΩlÔøΩÔøΩo ÔøΩÔøΩ‘â\u001eBoÔøΩÔøΩÔøΩIÔøΩ·±æ&ÔøΩ\u0012ÔøΩ\t\u0017ÔøΩÔøΩ8ÔøΩCÔøΩP\u000f\tÔøΩÔøΩ&ÔøΩÔøΩj\u0019;#JÔøΩÔøΩÔøΩ›£ÔøΩd__ÔøΩÔøΩÔøΩ!{”É2OƒªÔøΩÔøΩÔøΩ+ÔøΩ'ÔøΩR}RÔøΩÔøΩ\u0011ÔøΩÔøΩÔøΩdÔøΩÔøΩ%PÔøΩÔøΩÔøΩHqÔøΩ\u000eÔøΩÔøΩ/ÔøΩ\u001d\u0012'ÔøΩÔøΩÔøΩ⁄∏\u0005uÔøΩ ûÔøΩÔøΩÔøΩ_ÔøΩoÔøΩ!€Æ KÔøΩ\rÔøΩ\u000eA>ÔøΩÔøΩ\u0017ÔøΩ\u0003ÔøΩ%ÔøΩ\u0000GQ\u0005ƒó\u0018ÔøΩ\u0014ÔøΩÔøΩÔøΩÔøΩh.AÔøΩÔøΩÔøΩÔøΩ\u0015GÔøΩ.ÔøΩÔøΩÔøΩÔøΩ:\u0018ÔøΩqÔøΩ\u000eÔøΩ\u001dhÔøΩÔøΩÔøΩEÔøΩÔøΩ-xÔøΩ7ÔøΩÔøΩÔøΩ\bÔøΩ&ÔøΩÔøΩXd\fÔøΩk}ÔøΩfÔøΩ^VfÔøΩÔøΩy\u0011ÔøΩ\u001bÔøΩÔøΩ\u0011ÔøΩÔøΩÔøΩÔøΩ”†ÔøΩ{\rÔøΩWÔøΩ\u001aÔøΩPÔøΩÔøΩz\u000bvÔøΩÔøΩ&A\u000bÔøΩ-%[R&jÔøΩbÔøΩ7ÔøΩ:ÔøΩÔøΩaÔøΩÔøΩA\u000eÔøΩÔøΩ-(ÔøΩÔøΩHXSÔøΩ\u001eÔøΩÔøΩPÔøΩÔøΩÔøΩ\u000bÔøΩÔøΩŸòZÔøΩ\u000eÔøΩ\u000fÔøΩeCÔøΩ&ÔøΩRÔøΩ|ÔøΩyÔøΩ#ÔøΩÔøΩMÔøΩÔøΩÔøΩÔøΩO\u0018ÔøΩ·õ§eÔøΩÔøΩ◊≥ÔøΩkVÔøΩ-ÔøΩÔøΩÔøΩx\u0015ÔøΩÔøΩJ[!ÔøΩrkÔøΩÔøΩÔøΩ8ÔøΩZÔøΩÔøΩÔøΩÔøΩAÔøΩ»à6ÔøΩÔøΩÔøΩÔøΩÔøΩ(ÔøΩ'#ÔøΩ&\tÔøΩﬁæ…≤^DÔøΩi&PLÔøΩÔøΩÔøΩ\\ÔøΩÔøΩxÔøΩ&ÔøΩgÔøΩ\u0017ÔøΩ∆òh‘±ÔøΩ1ÔøΩ\u0005ÔøΩÀ¥M\u0007ÔøΩ{W\u0004ÔøΩw\u0013ÔøΩ\u0013,;ÔøΩHÔøΩxLÔøΩbÔøΩÔøΩ\u0003ÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩRÔøΩ{3ÔøΩÔøΩsÔøΩ1\u0004\u001fCÔøΩÔøΩ\u0002kÔøΩcZÔøΩ\n","ÔøΩÔøΩÔøΩ+ÔøΩ\u0007u\u0011\u001eÔøΩ!LÔøΩ^ÔøΩtP\u000eÔøΩÔøΩMÔøΩÔøΩ_ÔøΩ$\u0015VÔøΩÔøΩ\u000fk&ÔøΩÔøΩÔøΩ}ÔøΩÔøΩ8ÔøΩœî\u000b\u0019\u0003ÔøΩÔøΩE\u0013ÔøΩ$ÔøΩG◊™j\b|cWÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩ\u0019FOÔøΩ„º¢z“∫ÔøΩÔøΩÔøΩ\u0007ÔøΩUXÔøΩ,P_vÔøΩÔøΩÔøΩ\u0018ÔøΩÔøΩ])x!ÔøΩsÔøΩC\u0018ﬂö.uÿõl\u001d;[ÔøΩmÔøΩ\\zÀõÔøΩ\u0010ÔøΩ=ÔøΩ,\u0001_ÔøΩ-QÔøΩAÔøΩ\u001fÔøΩ'ÔøΩ\u000buz^zÔøΩÔøΩ\u000fËà®.ÔøΩz¬ÇÔøΩÔøΩFÔøΩÔøΩq[ÔøΩ8ÔøΩccÔøΩK\n","…∂ÔøΩÔøΩÔøΩÔøΩ9ÔøΩ3uÔøΩQÔøΩ]'OvÔøΩÔøΩÔøΩ‹õ\u001cÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩWÕïÔøΩÔøΩ\u001aÔøΩ\u0013ÔøΩBMÔøΩÔøΩ%0\u0019<Jc„∏Ñ>\u0010ÔøΩÔøΩÔøΩ\u0004ÔøΩÔøΩ\u0017=wÔøΩÔøΩÔøΩÔøΩ&2ÔøΩÔøΩ7ÔøΩÔøΩ\u001a1ÔøΩÔøΩ'ÔøΩÔøΩ\"ÔøΩ\u0019ÔøΩemŒ£–èÔøΩ\u001fKÔøΩ\u000bvYÔøΩrXGI8ÔøΩ\u0005x>^ÔøΩÔøΩÔøΩ\u0011|?c]ÔøΩÔøΩÔøΩÔøΩÔøΩ›èÔøΩÔøΩ~0XÔøΩ8FÔøΩÔøΩ?ÔøΩÔøΩ3ÔøΩÔøΩÔøΩYBX!ÔøΩÔøΩEÔøΩFyÔøΩOC?}ÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩzo*ÔøΩ]wÔøΩ\u0019ÔøΩ\u0003ÔøΩÔøΩÔøΩÔøΩÔøΩ\u001c\u0005ÔøΩW\u000fÔøΩÔøΩÔøΩN8=dÔøΩHÔøΩ_\u0018ÔøΩÔøΩÔøΩÔøΩÔøΩ=*ÔøΩÔøΩÔøΩÔøΩhﬁÅÔøΩÔøΩ\u0011Q\u0011ÔøΩÔøΩÔøΩrÔøΩÔøΩ\u001dÔøΩÔøΩri\u0018xÔøΩÔøΩ#ÔøΩ\u0010ÔøΩ\u0016\u0019ÔøΩÔøΩ<GÔøΩÔøΩÔøΩL\u000bt V]ÔøΩ\u0001ÔøΩÔøΩ:%\n","ÔøΩZÔøΩiÔøΩ\u000f<.ÔøΩÔøΩËèº51tÔøΩ[\bÔøΩ=ÔøΩXÔøΩ\bÔøΩkM\u0014ÔøΩÔøΩÔøΩÔøΩs{ÔøΩyÔøΩy\\\u0000ÔøΩÔøΩpÔøΩŸ†ÔøΩÔøΩÔøΩÔøΩÔøΩaÔøΩwÔøΩPf\"nﬂ±&)ÔøΩ3WV\\ÔøΩ|ÔøΩ~!\u0005ÔøΩÔøΩ\rb(ÔøΩÔøΩÔøΩÔøΩ&ÔøΩÔøΩOW>\u000bG~ÔøΩ\u0010MÔøΩA]ÔøΩt\u0019\u0019ÔøΩÔøΩ:ÔøΩqÔøΩ\u0005q\u001eÔøΩ\u0012ÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩ@\u0013ÔøΩÔøΩ!ÔøΩ ÔøΩ:'quÔøΩBÔøΩ_ÔøΩ\u001dÔøΩ@ÔøΩT\u0015dÕÄÔøΩ:ÔøΩwÔøΩÔøΩ\bÔøΩÔøΩTOÔøΩ/;ÔøΩÔøΩÔøΩÔøΩ\u0003ÔøΩWyÔøΩ\t}ÔøΩ.ÔøΩÔøΩ\u0004|?ÔøΩÔøΩ^\u000bÔøΩÔøΩÔøΩ|ÔøΩp\u000f]?ÔøΩ\u0015\u0002ÔøΩÔøΩÔøΩxÔøΩ\u001fÔøΩÔøΩ\u0006ÔøΩÔøΩ!ÔøΩ\u0011ÔøΩ\\ÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩ#ÔøΩ-ÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩ◊º\u001b*XGÔøΩ2ÔøΩÔøΩÔøΩ\u001dÔøΩOW\u0004k\u0014ÔøΩh‘ºE_\t\u0004ÔøΩ[ÔøΩ<7CÔøΩÔøΩ<!ÔøΩ\u0014k\u0015ÔøΩCÔøΩÔøΩgoÔøΩÔøΩÔøΩ\rÔøΩVÔøΩÔøΩÔøΩÔøΩ\\ÔøΩÔøΩ5ÔøΩÔøΩÔøΩÔøΩÔøΩ\u001f]\u0010rÔøΩÔøΩ%ÔøΩÔøΩ1ÔøΩ:ÔøΩÔøΩÔøΩÔøΩzÔøΩÔøΩÔøΩ9BÔøΩz\n","ÔøΩB\u0010\u001fÔøΩ_ÔøΩ'xXÔøΩnÔøΩ8ÔøΩÔøΩÔøΩj\u0016AÔøΩÔøΩÔøΩ\u0004ÔøΩPÔøΩ\u0013kÔøΩÔøΩ\bÔøΩÔøΩ\u0018u+p-aeÔøΩ\u000eÔøΩÔøΩNÔøΩÔøΩ\u0018ÔøΩoÔøΩÔøΩÔøΩhCÔøΩOdjÔøΩÔøΩÔøΩ\u000eÔøΩ\u001bÔøΩÔøΩKÔøΩkjqSÔøΩÔøΩÔøΩÔøΩÔøΩ›ã<ÔøΩ\u0018uF>>ÔøΩÔøΩÔøΩÔøΩÔøΩ{ jÔøΩ\u001fÔøΩ1-\u000bg ^mÔøΩÔøΩtÔøΩÔøΩBÔøΩÔøΩﬂ°?9ÔøΩUiÔøΩ+}\u0001ÔøΩÔøΩÔøΩÔøΩ=ÔøΩ\u000bwÔøΩÔøΩiÔøΩÔøΩÔøΩ\u0005\u001fÔøΩÔøΩ\u000f+ /ÔøΩsÔøΩÔøΩÔøΩÔøΩÔøΩ\f\u0003yÔøΩÔøΩÔøΩ\u0012ÔøΩÔøΩÔøΩÔøΩ\r\u0005WÔøΩÔøΩpÔøΩÔøΩ\u0013|ÔøΩÔøΩ\u001eÔøΩ\u0004ÔøΩ\u0017O\u000eÔøΩAÔøΩÔøΩÔøΩ7$@\u0007\u0019ÔøΩJÔøΩ0/ÔøΩEÔøΩ\u000bÔøΩÔøΩbÔøΩ{^yÔøΩÔøΩ;{\u000eÔøΩoÔøΩlÔøΩÔøΩÔøΩ>ÔøΩÔøΩ>ÔøΩÔøΩ{FÔøΩ\u0001'ÔøΩ?Q\u0010cÔøΩÔøΩ\u0017ÔøΩ=wÔøΩ>ÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩCÔøΩ\n","ÔøΩÔøΩ€Ø>ÔøΩ\fÔøΩ∆èV}ÔøΩÔøΩÿ´ÔøΩ\u001eÔøΩÔøΩDÔøΩÔøΩVÔøΩKK\u001cÔøΩ\"ÔøΩZ\u001f\n","ÔøΩC\t_\tÔøΩÔøΩ\u0006ÔøΩfÔøΩB\u0017ÔøΩ\u000fÔøΩÔøΩ3ÔøΩÔøΩÔøΩÔøΩU{qoÔøΩÔøΩÔøΩ-ÔøΩ>I]\u0014<ÔøΩÔøΩÔøΩÃôÔøΩ\f$;(*ÔøΩ\u0018ÔøΩ2ÔøΩmc7AvUÔøΩL3ÔøΩ\u001fImÔøΩÔøΩ:\u001aÔøΩÔøΩÔøΩKdRÔøΩ\u0012‹è,^ÔøΩ\u0001ÔøΩKÔøΩÔøΩo\u0014uŸî{Q\u0002ÔøΩyÔøΩA\u0006ÔøΩ|<ÔøΩÔøΩÔøΩzMwÔøΩÔøΩ}ÔøΩÔøΩ\u0017‹ÄsÔøΩÔøΩKÔøΩ\u0002ÔøΩÔøΩÔøΩ:ÔøΩÔøΩÔøΩÔøΩ,47ÔøΩNÔøΩÃπL\u000eÔøΩ\u000fÔøΩ_ÔøΩ\u0005B\u000f|ÔøΩ\u0013ÔøΩÔøΩ\u000ej17ÔøΩ)ÔøΩ|ÔøΩ%ÔøΩC7\u001cÔøΩÔøΩÔøΩPÔøΩÔøΩÔøΩÔøΩ6.ÔøΩÔøΩ47ÔøΩ]ÔøΩ\n","ÔøΩ\u0010ÔøΩÔøΩœÉ\u0011–ΩK2ÔøΩÔøΩÔøΩCÔøΩYu\u001dÔøΩÔøΩB»≥ÔøΩÔøΩx/ÔøΩ6ÔøΩbÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩ7ÔøΩ\n","ÔøΩz8ÔøΩ\u001bÔøΩÔøΩÔøΩ6÷àÔøΩTÔøΩÔøΩÔøΩÔøΩÔøΩ\b(ÔøΩGÔøΩÔøΩ\\ÔøΩ/ÔøΩOÔøΩÔøΩÔøΩÔøΩ\u0013ﬂõ\u0002\u001e∆º&;ÔøΩTJ\u0001ÔøΩ^\u0015ÔøΩ#ÔøΩÔøΩ2NgG!ÔøΩJÔøΩ,ÔøΩ{dÔøΩŸº\u0016ÔøΩÔøΩ√®\u0015ÔøΩÔøΩÔøΩÔøΩ6\u001bÔøΩa=`ÔøΩC7\u0002ÔøΩ\u0012;ÔøΩ\u0017\u000b)\u0005iÔøΩ{ÔøΩbÔøΩ;tPÀé;\u001d}ÔøΩuqÔøΩQ\tÔøΩÔøΩÔøΩjÔøΩMiÔøΩ+ÔøΩÔøΩÔøΩN7xÔøΩÔøΩÔøΩÔøΩ\u0013ÔøΩÔøΩÔøΩ>}\u001cyÔøΩÔøΩÔøΩ1\u0015ÔøΩ2\u0019ÔøΩCÔøΩ#‰ãÖ1ÔøΩÔøΩfÔøΩ:bLxÔøΩcÔøΩ\u000eÔøΩ\rÔøΩÔøΩ‹ÄÔøΩÔøΩŒ©9@ÔøΩ$tÔøΩMQ\u0007k\u000b\u0017ÔøΩw{ÔøΩ\n"]}]},{"cell_type":"code","metadata":{"id":"oc-i-KbA_2ly","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656691727277,"user_tz":-120,"elapsed":66321,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"608cdfb0-3f4f-4b3c-c6ac-952003950e2a"},"source":["!rm -rf ./results\n","!nequip-train nequip/configs/example.yaml"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.20\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20220701_160744-2ufhehgv\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexample-run-toluene\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anony-moose-343135/toluene-example?apiKey=7e9f428d648cfb11d246e4596fa53fa734a198bb\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anony-moose-343135/toluene-example/runs/2ufhehgv?apiKey=7e9f428d648cfb11d246e4596fa53fa734a198bb\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Do NOT share these links with anyone. They can be used to claim your runs.\n","Torch device: cuda\n","Downloading http://quantum-machine.org/gdml/data/npz/toluene_ccsd_t.zip\n","Processing dataset...\n","Loaded data: Batch(batch=[15000], cell=[1000, 3, 3], edge_cell_shift=[154352, 3], edge_index=[2, 154352], forces=[15000, 3], pbc=[1000, 3], pos=[15000, 3], ptr=[1001], total_energy=[1000, 1])\n","Cached processed data to disk\n","Done!\n","Successfully loaded the data set of type NpzDataset(1000)...\n","Replace string dataset_forces_rms to 30.621034622192383\n","Replace string dataset_per_atom_total_energy_mean to -11319.556640625\n","Atomic outputs are scaled by: [H, C: 30.621035], shifted by [H, C: -11319.556641].\n","Replace string dataset_forces_rms to 30.621034622192383\n","Initially outputs are globally scaled by: 30.621034622192383, total_energy are globally shifted by None.\n","Successfully built the network...\n","Number of weights: 154200\n","! Starting training ...\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      0     5        0.989        0.976       0.0129         22.1         30.2         14.8         30.5         22.7         19.5         39.1         29.3         51.8         3.46\n","\n","\n","  Initialization     #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Initial Validation          0    3.360    0.005        0.993       0.0125         1.01         22.3         30.5         14.6           31         22.8         19.2         39.7         29.4           51          3.4\n","Wall time: 3.36027547599997\n","! Best model        0    1.006\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      1    10        0.433        0.421       0.0119         15.4         19.9         10.6         20.8         15.7         13.2         25.5         19.3           50         3.33\n","      1    20        0.229        0.214       0.0154         10.4         14.2            7         14.3         10.7         8.74         18.5         13.6         57.1          3.8\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      1     5        0.269        0.268      0.00101         11.7         15.9         7.37         16.7           12         9.07         21.1         15.1         13.5        0.902\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train               1   10.710    0.005        0.586       0.0181        0.604         16.4         23.4         10.4         23.2         16.8         14.4         30.6         22.5         54.7         3.65\n","! Validation          1   10.710    0.005        0.231       0.0012        0.232         10.8         14.7          6.9         15.2           11         8.68         19.4           14         15.3         1.02\n","Wall time: 10.71125456100026\n","! Best model        1    0.232\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      2    10        0.155        0.143       0.0116          9.1         11.6         7.39         11.1         9.22          8.8         14.1         11.5         49.3         3.29\n","      2    20        0.126        0.126     9.52e-05         8.25         10.9         6.08         10.7         8.41         7.64         13.7         10.7         4.15        0.276\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      2     5         0.14         0.14     8.95e-05         8.66         11.5          5.8         11.9         8.87          7.3         14.9         11.1         3.51        0.234\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train               2   12.457    0.005        0.162       0.0138        0.176         9.17         12.3         6.01         12.8         9.39         7.59         16.1         11.9           41         2.73\n","! Validation          2   12.457    0.005        0.122     5.95e-05        0.122         7.98         10.7         5.38         10.9         8.16         6.92         13.8         10.4         2.77        0.185\n","Wall time: 12.458084238000083\n","! Best model        2    0.122\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      3    10         0.13        0.128      0.00208         7.87           11         4.81         11.4         8.08         6.16         14.6         10.4         20.7         1.38\n","      3    20        0.116        0.112      0.00414         7.76         10.3         5.59         10.2         7.91         6.95           13           10         29.4         1.96\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      3     5       0.0979       0.0975     0.000388         7.21         9.56         4.78         9.99         7.39         5.88         12.5         9.19         8.54        0.569\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train               3   14.207    0.005       0.0986      0.00181          0.1         7.09         9.62         4.75         9.75         7.25         6.17         12.4          9.3         17.2         1.14\n","! Validation          3   14.207    0.005       0.0866      0.00031       0.0869          6.7         9.01         4.46         9.26         6.86         5.67         11.7         8.69         7.56        0.504\n","Wall time: 14.207510938000269\n","! Best model        3    0.087\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      4    10       0.0876        0.087     0.000538         6.62         9.03            5         8.46         6.73         6.34         11.4         8.85         10.3        0.685\n","      4    20       0.0761       0.0758     0.000357         6.26         8.43         5.17         7.52         6.34         6.76           10         8.38         8.48        0.565\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      4     5       0.0763       0.0762     8.64e-05         6.26         8.45         4.32         8.49          6.4         5.45         10.9         8.18         3.46         0.23\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train               4   15.954    0.005        0.078      0.00134       0.0793         6.31         8.55         4.43         8.46         6.45         5.71         10.9         8.32         13.2        0.877\n","! Validation          4   15.954    0.005       0.0701     6.48e-05       0.0702            6         8.11         4.18         8.09         6.14         5.35         10.4         7.88         3.01        0.201\n","Wall time: 15.954927776000204\n","! Best model        4    0.070\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      5    10       0.0692       0.0689     0.000316         5.58         8.04         3.85         7.56          5.7         5.79           10          7.9         7.93        0.529\n","      5    20       0.0605       0.0594      0.00106         5.85         7.46         4.88         6.96         5.92         5.95         8.88         7.42         14.9        0.991\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      5     5       0.0612       0.0611        3e-05         5.64         7.57         3.97         7.56         5.76         5.09         9.66         7.37          2.1         0.14\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train               5   17.673    0.005       0.0606     0.000925       0.0616         5.58         7.54         3.99         7.39         5.69         5.18         9.55         7.36         12.8        0.856\n","! Validation          5   17.673    0.005       0.0556     4.87e-05       0.0556         5.38         7.22         3.87          7.1         5.48         5.02          9.1         7.06         2.71         0.18\n","Wall time: 17.673653619000106\n","! Best model        5    0.056\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      6    10       0.0376       0.0374      0.00023         4.25         5.92         2.72            6         4.36         3.45         7.85         5.65         6.77        0.451\n","      6    20       0.0277       0.0273     0.000379         3.87         5.06         3.08         4.78         3.93         3.99         6.05         5.02         8.75        0.584\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      6     5       0.0434       0.0434     5.18e-05         4.78         6.38         3.61         6.11         4.86         4.73         7.85         6.29         2.71        0.181\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train               6   19.418    0.005       0.0409     0.000505       0.0414         4.61         6.19         3.49         5.88         4.69         4.55         7.65          6.1         9.27        0.618\n","! Validation          6   19.418    0.005       0.0412     4.29e-05       0.0412         4.68         6.22         3.57         5.94         4.76         4.71         7.58         6.14         2.44        0.163\n","Wall time: 19.41832584900021\n","! Best model        6    0.041\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      7    10       0.0293       0.0289     0.000354         3.99         5.21         3.45          4.6         4.03         4.52          5.9         5.21         8.34        0.556\n","      7    20       0.0222       0.0221     4.07e-05         3.35         4.56         2.57         4.25         3.41         3.52          5.5         4.51         2.83        0.189\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      7     5       0.0302       0.0302     1.25e-05         4.05         5.32         3.35         4.84          4.1         4.39         6.22          5.3         1.34       0.0894\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train               7   21.137    0.005       0.0271     0.000324       0.0274         3.82         5.04         3.18         4.56         3.87         4.16         5.89         5.03         7.21        0.481\n","! Validation          7   21.137    0.005        0.028     1.84e-05       0.0281         3.92         5.13         3.32          4.6         3.96         4.41         5.84         5.13         1.58        0.105\n","Wall time: 21.138279868000154\n","! Best model        7    0.028\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      8    10       0.0198       0.0197     8.95e-05         3.29          4.3         2.85          3.8         3.33         3.83         4.79         4.31         4.18        0.278\n","      8    20       0.0149       0.0148      0.00011         2.83         3.72         2.33          3.4         2.87         2.99         4.41          3.7         4.72        0.315\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      8     5       0.0243       0.0242     1.59e-05         3.62         4.77         3.14         4.18         3.66         4.16         5.38         4.77         1.39       0.0926\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train               8   23.002    0.005       0.0214     0.000201       0.0216         3.41         4.48         2.94         3.94         3.44         3.86         5.09         4.48         5.31        0.354\n","! Validation          8   23.002    0.005       0.0226     1.93e-05       0.0227         3.48         4.61         3.06         3.96         3.51         4.15         5.08         4.62         1.55        0.104\n","Wall time: 23.002434727000036\n","! Best model        8    0.023\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      9    10       0.0163       0.0163     9.33e-06            3         3.91         2.27         3.83         3.05         2.89         4.81         3.85          1.3       0.0865\n","      9    20       0.0149       0.0149     6.63e-06         2.85         3.74         2.73         2.98         2.86         3.59         3.89         3.74         1.01       0.0673\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      9     5       0.0213       0.0213     1.15e-05         3.39         4.47         2.98         3.85         3.42         3.97         4.98         4.47         1.21       0.0805\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train               9   24.734    0.005       0.0187     5.93e-05       0.0187         3.18         4.19         2.76         3.64          3.2         3.63         4.74         4.19         2.98        0.198\n","! Validation          9   24.734    0.005       0.0197     1.65e-05       0.0198         3.22          4.3         2.88         3.62         3.25         3.96         4.66         4.31         1.44       0.0963\n","Wall time: 24.73462885700019\n","! Best model        9    0.020\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     10    10       0.0188       0.0187     8.28e-05         3.09         4.19         2.41         3.85         3.13         3.34         4.98         4.16         3.94        0.262\n","     10    20       0.0155       0.0155      1.1e-05         2.82         3.81         2.44         3.26         2.85         3.31          4.3         3.81         1.13       0.0752\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     10     5       0.0193       0.0193     1.44e-05          3.2         4.26         2.83         3.63         3.23         3.81         4.72         4.26         1.33       0.0884\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              10   26.462    0.005       0.0169      4.2e-05        0.017         3.04         3.99          2.6         3.53         3.07         3.44         4.53         3.98          2.4         0.16\n","! Validation         10   26.462    0.005       0.0179      1.8e-05       0.0179         3.05          4.1         2.71         3.44         3.08         3.79         4.42         4.11         1.49       0.0991\n","Wall time: 26.462975816999915\n","! Best model       10    0.018\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     11    10       0.0229       0.0227     0.000156         3.22         4.62          2.7         3.82         3.26         3.86         5.36         4.61         5.68        0.379\n","     11    20       0.0123       0.0121      0.00018         2.61         3.37         2.36         2.91         2.63         3.09         3.67         3.38          6.1        0.407\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     11     5        0.018        0.018     9.53e-06         3.08          4.1         2.75         3.47         3.11         3.69         4.53         4.11          1.1        0.073\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              11   28.224    0.005       0.0145     7.08e-05       0.0146          2.8         3.69         2.43         3.23         2.83         3.22         4.17         3.69         3.28        0.219\n","! Validation         11   28.224    0.005       0.0166     1.43e-05       0.0166         2.94         3.94         2.63          3.3         2.96         3.68         4.22         3.95         1.36       0.0906\n","Wall time: 28.22472199899994\n","! Best model       11    0.017\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     12    10       0.0142       0.0142     4.35e-06         2.82         3.65          2.4          3.3         2.85         3.07         4.21         3.64        0.819       0.0546\n","     12    20       0.0213       0.0213     4.44e-05         3.19         4.47         2.81         3.62         3.22          3.9         5.04         4.47         2.58        0.172\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     12     5       0.0166       0.0166     9.63e-06         2.96         3.94         2.65         3.32         2.98         3.57         4.33         3.95         1.08       0.0722\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              12   29.968    0.005       0.0139     2.36e-05       0.0139         2.74          3.6         2.36         3.16         2.76         3.14         4.07         3.61         1.74        0.116\n","! Validation         12   29.968    0.005       0.0155     1.39e-05       0.0155         2.84         3.81         2.55         3.17         2.86         3.57         4.06         3.82         1.33       0.0886\n","Wall time: 29.968689062000067\n","! Best model       12    0.015\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     13    10       0.0116       0.0115     2.68e-05         2.58         3.29         2.23         2.97          2.6         2.85         3.72         3.29         2.32        0.155\n","     13    20       0.0102       0.0102     2.22e-06         2.34          3.1         2.16         2.55         2.36         2.86         3.35         3.11        0.616        0.041\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     13     5       0.0158       0.0158     1.07e-05         2.89         3.85          2.6         3.22         2.91          3.5         4.21         3.86         1.15       0.0765\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              13   31.691    0.005       0.0131     2.15e-05       0.0132         2.68         3.51         2.34         3.07         2.71         3.08         3.94         3.51         1.75        0.117\n","! Validation         13   31.691    0.005       0.0148     1.43e-05       0.0148         2.77         3.72         2.49         3.09         2.79          3.5         3.96         3.73         1.34       0.0891\n","Wall time: 31.692241564000142\n","! Best model       13    0.015\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     14    10       0.0126       0.0126     8.98e-06         2.61         3.44         2.18         3.09         2.64         2.85         4.01         3.43         1.22       0.0815\n","     14    20       0.0118       0.0118     3.69e-05         2.47         3.32         1.92          3.1         2.51         2.53         4.04         3.29         2.67        0.178\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     14     5       0.0149       0.0148     1.08e-05          2.8         3.73         2.52         3.12         2.82         3.41         4.06         3.74         1.16       0.0776\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              14   33.453    0.005        0.013     2.82e-05       0.0131         2.66         3.49         2.29          3.1         2.69         3.02         3.96         3.49            2        0.133\n","! Validation         14   33.453    0.005        0.014     1.41e-05        0.014          2.7         3.62         2.43         3.01         2.72         3.42         3.84         3.63         1.33       0.0886\n","Wall time: 33.453903536000325\n","! Best model       14    0.014\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     15    10       0.0116       0.0113     0.000308         2.61         3.26         2.34         2.91         2.63         2.99         3.54         3.27         8.02        0.535\n","     15    20      0.00961      0.00956     4.94e-05         2.26         2.99            2         2.55         2.27         2.67         3.33            3         2.93        0.195\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     15     5        0.014        0.014     1.04e-05         2.72         3.63         2.46         3.02         2.74         3.33         3.94         3.63         1.14       0.0757\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              15   35.183    0.005       0.0122     0.000109       0.0123         2.58         3.38         2.22         2.98          2.6         2.94         3.81         3.38         4.17        0.278\n","! Validation         15   35.183    0.005       0.0133     1.36e-05       0.0133         2.64         3.54         2.38         2.94         2.66         3.34         3.75         3.54          1.3       0.0865\n","Wall time: 35.184010683\n","! Best model       15    0.013\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     16    10       0.0121       0.0118     0.000301         2.47         3.32         2.29         2.67         2.48         3.07         3.58         3.33         7.78        0.519\n","     16    20      0.00897      0.00895     1.89e-05         2.24          2.9         1.92          2.6         2.26         2.49          3.3          2.9          1.8         0.12\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     16     5       0.0132       0.0132     6.83e-06         2.65         3.52         2.39         2.94         2.67         3.23         3.83         3.53        0.952       0.0634\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              16   36.936    0.005       0.0112     8.86e-05       0.0113         2.47         3.24         2.16         2.82         2.49         2.85         3.64         3.25         3.61        0.241\n","! Validation         16   36.936    0.005       0.0127     1.11e-05       0.0127         2.57         3.44         2.33         2.86         2.59         3.25         3.65         3.45         1.21       0.0805\n","Wall time: 36.9364450410003\n","! Best model       16    0.013\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     17    10       0.0102       0.0102     1.13e-05         2.42         3.09         2.24         2.63         2.44         2.88         3.31          3.1         1.26       0.0842\n","     17    20      0.00784      0.00782     1.88e-05            2         2.71         1.94         2.06            2         2.72         2.69         2.71         1.71        0.114\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     17     5       0.0125       0.0125     7.07e-06         2.57         3.42         2.33         2.85         2.59         3.15          3.7         3.43        0.958       0.0639\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              17   38.664    0.005       0.0101     2.93e-05       0.0102         2.35         3.08         2.09         2.65         2.37         2.76         3.41         3.09         1.93        0.129\n","! Validation         17   38.664    0.005        0.012     1.08e-05       0.0121         2.51         3.36         2.27         2.79         2.53         3.18         3.56         3.37         1.18       0.0784\n","Wall time: 38.66501886900005\n","! Best model       17    0.012\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     18    10       0.0129       0.0129      1.2e-05         2.63         3.47         2.39          2.9         2.64         3.21         3.75         3.48         1.48       0.0985\n","     18    20       0.0125       0.0125     1.37e-05         2.54         3.43         2.03         3.13         2.58         2.85         3.99         3.42         1.45       0.0969\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     18     5       0.0118       0.0118     7.61e-06          2.5         3.33         2.26         2.78         2.52         3.07         3.61         3.34         1.01       0.0671\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              18   40.405    0.005       0.0102     3.43e-05       0.0103         2.38          3.1         2.07         2.74          2.4         2.73         3.47          3.1         2.32        0.154\n","! Validation         18   40.405    0.005       0.0115     1.09e-05       0.0115         2.45         3.28         2.21         2.73         2.47          3.1         3.48         3.29         1.16       0.0775\n","Wall time: 40.405967585000326\n","! Best model       18    0.012\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/nequip-train\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.7/dist-packages/nequip/scripts/train.py\", line 78, in main\n","    trainer.train()\n","  File \"/usr/local/lib/python3.7/dist-packages/nequip/train/trainer.py\", line 775, in train\n","    self.epoch_step()\n","  File \"/usr/local/lib/python3.7/dist-packages/nequip/train/trainer.py\", line 915, in epoch_step\n","    validation=(category == VALIDATION),\n","  File \"/usr/local/lib/python3.7/dist-packages/nequip/train/trainer.py\", line 827, in batch_step\n","    loss.backward()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 363, in backward\n","    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 175, in backward\n","    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","KeyboardInterrupt\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 255).\u001b[0m Press Control-C to abort syncing.\n","/usr/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown\n","  len(cache))\n","^C\n"]}]},{"cell_type":"markdown","metadata":{"id":"5EwuQZLDO4Cr"},"source":["We see that the model has converged to an energy accuarcy < 1meV/atom and a force accuracy of approx. 40 meV/A within 5 minutes and trained on only 100 samples. That should give us a good first potential! Note that these numbers will decrease significantly if you increase the training set size and the number of epochs to train. "]},{"cell_type":"markdown","metadata":{"id":"kJitSZgLYNNF"},"source":["### Deploy the model"]},{"cell_type":"markdown","metadata":{"id":"Lo_kIpYV00as"},"source":["<img src=\"https://github.com/mir-group/nequip_mrs_tutorial/blob/master/deploy.png?raw=true\" width=\"60%\">"]},{"cell_type":"markdown","metadata":{"id":"7VoeGtlA02KQ"},"source":["We now convert the model to a potential file. This makes it independent of NequIP and we can use it any downstream application, such as LAMMPS. "]},{"cell_type":"code","metadata":{"id":"Y3NJJgtDIDNc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644071858191,"user_tz":300,"elapsed":6107,"user":{"displayName":"Simon Batzner","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01516403350906604395"}},"outputId":"b5d86b6b-c649-4d46-e1aa-457b2e7ceb13"},"source":["!nequip-deploy build results/toluene/example-run-toluene toluene-deployed.pth"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:root:Atomic outputs are scaled by: 1.0, shifted by 0.0.\n","INFO:root:Compiled & optimized model.\n"]}]},{"cell_type":"markdown","metadata":{"id":"UXpcE3oP0LyD"},"source":["## Evaluate Test Error on all remaining frames"]},{"cell_type":"markdown","metadata":{"id":"4wRKKCZ2PRl3"},"source":["Before running inference, we'd like to know how well the model is doing on a hold-out test set. We run the nequip-evaluate command to compute the test error on all data that we didn't use for training or validation. "]},{"cell_type":"code","metadata":{"id":"mB54WSrN0PaS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644071880764,"user_tz":300,"elapsed":14415,"user":{"displayName":"Simon Batzner","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01516403350906604395"}},"outputId":"96734101-62b1-4b9a-8c23-1c5c1387fbd5"},"source":["!nequip-evaluate --train-dir results/toluene/example-run-toluene --batch-size 50"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","WARNING: please note that models running on CUDA are usually nondeterministc and that this manifests in the final test errors; for a _more_ deterministic result, please use `--device cpu`\n","Loading model... \n","loaded model from training session\n","Loading original dataset...\n","Loaded dataset specified in config.yaml.\n","Using origial training dataset (1000 frames) minus training (100 frames) and validation frames (50 frames), yielding a test set size of 850 frames.\n","Starting...\n","  0% 0/850 [00:00<?, ?it/s]\n","\u001b[A\n","  6% 50/850 [00:00<00:04, 198.25it/s]\n"," 12% 100/850 [00:00<00:07, 95.56it/s]\n"," 18% 150/850 [00:02<00:14, 46.79it/s]\n"," 24% 200/850 [00:04<00:17, 37.76it/s]\n","\u001b[A\n"," 35% 300/850 [00:04<00:07, 76.45it/s]\n","\u001b[A\n"," 47% 400/850 [00:04<00:03, 125.72it/s]\n","\u001b[A\n","\u001b[A\n"," 65% 550/850 [00:04<00:01, 217.01it/s]\n","\u001b[A\n","\u001b[A\n"," 82% 700/850 [00:04<00:00, 319.80it/s]\n","\u001b[A\n","\u001b[A\n","100% 850/850 [00:05<00:00, 167.55it/s]\n","\n","\n","--- Final result: ---\n","             0_f_mae =  0.796981           \n","             1_f_mae =  1.318640           \n","           all_f_mae =  1.057810           \n","             e/N_mae =  0.022260           \n","             0_f_mae =  0.796981           \n","             1_f_mae =  1.318640           \n","           all_f_mae =  1.057810           \n","             e/N_mae =  0.022260           \n"]}]},{"cell_type":"markdown","metadata":{"id":"HQHrMMnsPaJO"},"source":["Again, energy errors of < 1meV/atom (converted from kcal/mol to eV), and force errors of ~45 meV/A üéâ"]},{"cell_type":"markdown","metadata":{"id":"H4r5FBXaum9n"},"source":["# LAMMPS"]},{"cell_type":"markdown","metadata":{"id":"0qIYIYyr1B4O"},"source":["We are now in a position to run MD with our potential. Here, we will minimize the geometry of the toluene molecule we trained on from a perturbed initial state. "]},{"cell_type":"markdown","metadata":{"id":"UirNBTlJ1BNZ"},"source":["<img src=\"https://github.com/mir-group/nequip_mrs_tutorial/blob/master/run.png?raw=true\" width=\"60%\">"]},{"cell_type":"markdown","metadata":{"id":"JQs0ijPhvAGb"},"source":["Set up a simple LAMMPS input file\n","\n","CAUTION: the reference data here are in kcal/mol for the energies and kcal/mol/A for the forces. The NequIP model will therefore also be predicting outputs in these units. We are therefore using `units real` in LAMMPS (see [docs](https://docs.lammps.org/units.html)). If your reference data are in other units, you should using the corresponding units command in LAMMPS (e.g. if you use eV, A then `units metal` would be appropriate, which would then also change time units from `fs` to `ps`)."]},{"cell_type":"code","source":["\n"],"metadata":{"id":"W090KfMsd2Do"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4tAHO8ODrpwG"},"source":["lammps_input_minimize = \"\"\"\n","units\treal\n","atom_style atomic\n","newton off\n","thermo 1\n","read_data structure.data\n","\n","pair_style\tnequip\n","pair_coeff\t* * ../toluene-deployed.pth C H \n","mass            1 15.9994\n","mass            2 1.00794\n","\n","neighbor 1.0 bin\n","neigh_modify delay 5 every 1\n","\n","minimize 0.0 1.0e-8 10000 1000000\n","write_dump all custom output.dump id type x y z fx fy fz\n","\"\"\"\n","!mkdir lammps_run\n","with open(\"lammps_run/toluene_minimize.in\", \"w\") as f:\n","    f.write(lammps_input_minimize)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AvWZCw1zvjRc"},"source":["Here's starting configuration for Toluene at CCSD(T) accuracy. We will strongly perturb the inital positions by sampling from a uniform distribution $\\mathcal{U}([0, 0.5])$"]},{"cell_type":"code","metadata":{"id":"JEPfMeGnJUVH"},"source":["toluene_example = \"\"\"15\n"," Lattice=\"100.0 0.0 0.0 0.0 100.0 0.0 0.0 0.0 100.0\" Properties=species:S:1:pos:R:3 -169777.5840406276=T pbc=\"F F F\"\n"," C       52.48936904      49.86911725      50.09520748\n"," C       51.01088202      49.89609925      50.17978049\n"," C       50.36647401      50.04650925      48.96054247\n"," C       48.95673398      50.29576626      48.71580846\n"," C       48.04533296      50.26023426      49.82589448\n"," C       48.70932398      49.85770925      51.01923950\n"," C       50.06326400      49.77782925      51.25691751\n"," H       52.94467905      50.48672926      50.86545150\n"," H       52.89060405      48.87175023      50.14480949\n"," H       53.02173405      50.05890725      49.03968247\n"," H       51.01439802      50.38234726      48.05314045\n"," H       48.80598498      50.64314926      47.68195744\n"," H       46.96754695      50.20586626      49.53998848\n"," H       48.16716997      49.75850325      51.88622952\n"," H       50.45791001      49.55387424      52.15303052\n"," \"\"\"\n","\n","with open('toluene.xyz', 'w') as f: \n","    f.write(toluene_example)\n","\n","# read as ASE objects\n","atoms = read('toluene.xyz', format='extxyz')\n","\n","# perturb positions\n","p = atoms.get_positions()\n","p += np.random.rand(15, 3) * 0.5\n","atoms.set_positions(p)\n","atoms.set_pbc(False)\n","\n","# write to a LAMMPS file\n","write(\"lammps_run/structure.data\", atoms, format=\"lammps-data\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QDuyueY11YBF"},"source":["### Run the LAMMPS command: "]},{"cell_type":"code","metadata":{"id":"gurLjNK5upvq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644071930560,"user_tz":300,"elapsed":18042,"user":{"displayName":"Simon Batzner","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01516403350906604395"}},"outputId":"13e735a0-ea9a-4108-c0a8-c5ea6bb1de6b"},"source":["!cd lammps_run/ && ../lammps/build/lmp -in toluene_minimize.in"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LAMMPS (29 Sep 2021 - Update 2)\n","OMP_NUM_THREADS environment is not set. Defaulting to 1 thread. (src/comm.cpp:98)\n","  using 1 OpenMP thread(s) per MPI task\n","Reading data file ...\n","  orthogonal box = (0.0000000 0.0000000 0.0000000) to (100.00000 100.00000 100.00000)\n","  1 by 1 by 1 MPI processor grid\n","  reading atoms ...\n","  15 atoms\n","  read_data CPU = 0.002 seconds\n","NEQUIP is using device cuda\n","NequIP Coeff: type 1 is element C\n","NequIP Coeff: type 2 is element H\n","Loading model from ../toluene-deployed.pth\n","Freezing TorchScript model...\n","WARNING: Using 'neigh_modify every 1 delay 0 check yes' setting during minimization (src/min.cpp:188)\n","Neighbor list info ...\n","  update every 1 steps, delay 0 steps, check yes\n","  max neighbors/atom: 2000, page size: 100000\n","  master list distance cutoff = 5\n","  ghost atom cutoff = 5\n","  binsize = 2.5, bins = 40 40 40\n","  1 neighbor lists, perpetual/occasional/extra = 1 0 0\n","  (1) pair nequip, perpetual\n","      attributes: full, newton off, ghost\n","      pair build: full/bin/ghost\n","      stencil: full/ghost/bin/3d\n","      bin: standard\n","Setting up cg style minimization ...\n","  Unit style    : real\n","  Current step  : 0\n","Per MPI rank memory allocation (min/avg/max) = 4.603 | 4.603 | 4.603 Mbytes\n","Step Temp E_pair E_mol TotEng Press \n","       0            0   -169569.11            0   -169569.11            0 \n","       1            0   -169648.28            0   -169648.28            0 \n","       2            0   -169719.86            0   -169719.86            0 \n","       3            0    -169769.8            0    -169769.8            0 \n","       4            0   -169792.31            0   -169792.31            0 \n","       5            0   -169803.03            0   -169803.03            0 \n","       6            0   -169806.83            0   -169806.83            0 \n","       7            0   -169810.16            0   -169810.16            0 \n","       8            0   -169812.75            0   -169812.75            0 \n","       9            0   -169813.66            0   -169813.66            0 \n","      10            0    -169814.3            0    -169814.3            0 \n","      11            0   -169814.77            0   -169814.77            0 \n","      12            0   -169815.05            0   -169815.05            0 \n","      13            0   -169815.28            0   -169815.28            0 \n","      14            0    -169815.7            0    -169815.7            0 \n","      15            0   -169815.88            0   -169815.88            0 \n","      16            0   -169816.05            0   -169816.05            0 \n","      17            0   -169816.23            0   -169816.23            0 \n","      18            0   -169816.31            0   -169816.31            0 \n","      19            0   -169816.36            0   -169816.36            0 \n","      20            0   -169816.42            0   -169816.42            0 \n","      21            0   -169816.44            0   -169816.44            0 \n","      22            0   -169816.47            0   -169816.47            0 \n","      23            0   -169816.52            0   -169816.52            0 \n","      24            0   -169816.52            0   -169816.52            0 \n","      25            0   -169816.52            0   -169816.52            0 \n","      26            0   -169816.52            0   -169816.52            0 \n","      27            0   -169816.52            0   -169816.52            0 \n","      28            0   -169816.52            0   -169816.52            0 \n","      29            0   -169816.53            0   -169816.53            0 \n","      30            0   -169816.55            0   -169816.55            0 \n","      31            0   -169816.55            0   -169816.55            0 \n","      32            0   -169816.56            0   -169816.56            0 \n","      33            0   -169816.56            0   -169816.56            0 \n","Loop time of 11.5642 on 1 procs for 33 steps with 15 atoms\n","\n","98.9% CPU use with 1 MPI tasks x 1 OpenMP threads\n","\n","Minimization stats:\n","  Stopping criterion = linesearch alpha is zero\n","  Energy initial, next-to-last, final = \n","        -169569.109375       -169816.5625       -169816.5625\n","  Force two-norm initial, final = 485.27448 2.6820958\n","  Force max component initial, final = 212.56668 1.0711311\n","  Final line search alpha, max atom move = 1.3603356e-09 1.4570978e-09\n","  Iterations, force evaluations = 33 119\n","\n","MPI task timing breakdown:\n","Section |  min time  |  avg time  |  max time  |%varavg| %total\n","---------------------------------------------------------------\n","Pair    | 11.562     | 11.562     | 11.562     |   0.0 | 99.98\n","Neigh   | 9.3531e-05 | 9.3531e-05 | 9.3531e-05 |   0.0 |  0.00\n","Comm    | 5.6191e-05 | 5.6191e-05 | 5.6191e-05 |   0.0 |  0.00\n","Output  | 0.00098602 | 0.00098602 | 0.00098602 |   0.0 |  0.01\n","Modify  | 0          | 0          | 0          |   0.0 |  0.00\n","Other   |            | 0.0006101  |            |       |  0.01\n","\n","Nlocal:        15.0000 ave          15 max          15 min\n","Histogram: 1 0 0 0 0 0 0 0 0 0\n","Nghost:         0.00000 ave           0 max           0 min\n","Histogram: 1 0 0 0 0 0 0 0 0 0\n","Neighs:         0.00000 ave           0 max           0 min\n","Histogram: 1 0 0 0 0 0 0 0 0 0\n","FullNghs:      190.000 ave         190 max         190 min\n","Histogram: 1 0 0 0 0 0 0 0 0 0\n","\n","Total # of neighbors = 190\n","Ave neighs/atom = 12.666667\n","Neighbor list builds = 1\n","Dangerous builds = 0\n","Total wall time: 0:00:16\n","[6bc2016184fb:03199] *** Process received signal ***\n","[6bc2016184fb:03199] Signal: Segmentation fault (11)\n","[6bc2016184fb:03199] Signal code: Address not mapped (1)\n","[6bc2016184fb:03199] Failing at address: 0x7f331cd2820d\n","[6bc2016184fb:03199] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980)[0x7f331f9d3980]\n","[6bc2016184fb:03199] [ 1] /lib/x86_64-linux-gnu/libc.so.6(getenv+0xa5)[0x7f331f6128a5]\n","[6bc2016184fb:03199] [ 2] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(_ZN13TCMallocGuardD1Ev+0x34)[0x7f331fe7de44]\n","[6bc2016184fb:03199] [ 3] /lib/x86_64-linux-gnu/libc.so.6(__cxa_finalize+0xf5)[0x7f331f613735]\n","[6bc2016184fb:03199] [ 4] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(+0x13cb3)[0x7f331fe7bcb3]\n","[6bc2016184fb:03199] *** End of error message ***\n"]}]},{"cell_type":"markdown","metadata":{"id":"BOKfQ83JQESc"},"source":["We see LAMMPS converges quickly to a minimum. Let's check how well we did. "]},{"cell_type":"code","metadata":{"id":"qPcQU9HbsaVl"},"source":["# read the final structure back in \n","minimized = read('./lammps_run/output.dump', format='lammps-dump-text')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"brqGqVtdWpCF"},"source":["### Compare optimized bond length to true coupled cluster reference from CCCBDB"]},{"cell_type":"code","metadata":{"id":"ltFlaHrTRn97","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644071930562,"user_tz":300,"elapsed":11,"user":{"displayName":"Simon Batzner","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01516403350906604395"}},"outputId":"1c6a131b-01a5-4b39-b972-945508bb7c6d"},"source":["# get distances of optimized geometry (reference data: CCSD(T) [Psi4, cc-pVDZ])\n","d_12 = minimized.get_distances(1, 2)\n","\n","# reference: https://cccbdb.nist.gov/geom3x.asp?method=6&basis=2, coupled cluster\n","d_12_ccd = 1.4086\n","\n","print('Relative Error in bond length w.r.t. Coupled Cluster from CCCBDB: {:.3f}%'.format((100 * np.abs(d_12 - d_12_ccd) / d_12_ccd)[0]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Relative Error in bond length w.r.t. Coupled Cluster from CCCBDB: 0.100%\n"]}]},{"cell_type":"markdown","metadata":{"id":"iT64gDUeQOvO"},"source":["We find a final relative error close to Coupled Cluster accuracy üéâ"]},{"cell_type":"markdown","metadata":{"id":"T4ZD6U0EkIp5"},"source":["## Next Steps\n","\n","This concludes our tutorial. A next step would be to head over to https://github.com/mir-group/nequip, install NequIP and get started with your own system. If you have questions, please don't hesitate to reach out to batzner@g.harvard.edu, we're happy to help! \n","\n"]}]}