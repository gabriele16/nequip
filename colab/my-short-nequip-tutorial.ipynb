{"cells":[{"cell_type":"markdown","metadata":{"id":"CFpAi8g9XmUU"},"source":["# Molecular Dynamics with NequIP \n","\n","### Authors: Simon Batzner, Albert Musaelian, Lixin Sun, Anders Johansson, Boris Kozinsky"]},{"cell_type":"code","source":["!pip install torch==1.10"],"metadata":{"id":"K7bW4JWmmuyD"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15321,"status":"ok","timestamp":1657045651014,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"},"user_tz":-120},"id":"ZOLIFOJZaeZ5","outputId":"7c012a32-e2df-4bd2-e2b4-0cc7217f7310"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import warnings\n","import os\n","\n","USE_COLAB = True\n","if USE_COLAB == True:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    work_dir = '/content/drive/MyDrive/Colab Notebooks/nequip/'\n","    data_dir = '/content/'\n","else:\n","    work_dir = '/Users/gabrieletocci/Google Drive/My Drive/Colab Notebooks/nequip/'\n","    data_dir = '/Users/gabrieletocci/Documents/projects/MD_DFT/'\n"]},{"cell_type":"code","source":["import torch\n","print(torch. __version__)\n","torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZpOvFtImsy2","executionInfo":{"status":"ok","timestamp":1657045651727,"user_tz":-120,"elapsed":717,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"04b43e79-0f38-41cb-b495-9da45aac771a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["1.10.0+cu102\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["!nvcc --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t7Uh7nyHnR-w","executionInfo":{"status":"ok","timestamp":1657045651728,"user_tz":-120,"elapsed":7,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"32003622-2aff-4f16-b690-6e9f022df6a6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Mon_Oct_12_20:09:46_PDT_2020\n","Cuda compilation tools, release 11.1, V11.1.105\n","Build cuda_11.1.TC455_06.29190527_0\n"]}]},{"cell_type":"code","source":["!rm -r lammps\n","!git clone -b \"stable_29Sep2021_update2\" --depth 1 \"https://github.com/lammps/lammps.git\"\n","!git clone https://github.com/mir-group/pair_nequip\n","!cd pair_nequip && ./patch_lammps.sh /content/lammps/\n","!cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uIMyrDOEm2IB","executionInfo":{"status":"ok","timestamp":1657045666794,"user_tz":-120,"elapsed":15069,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"f8d1baff-e422-4572-c4dd-72807b41933b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'lammps'...\n","remote: Enumerating objects: 11732, done.\u001b[K\n","remote: Counting objects: 100% (11732/11732), done.\u001b[K\n","remote: Compressing objects: 100% (8605/8605), done.\u001b[K\n","remote: Total 11732 (delta 3940), reused 6322 (delta 2928), pack-reused 0\n","Receiving objects: 100% (11732/11732), 110.00 MiB | 18.02 MiB/s, done.\n","Resolving deltas: 100% (3940/3940), done.\n","Note: checking out '7586adbb6a61254125992709ef2fda9134cfca6c'.\n","\n","You are in 'detached HEAD' state. You can look around, make experimental\n","changes and commit them, and you can discard any commits you make in this\n","state without impacting any branches by performing another checkout.\n","\n","If you want to create a new branch to retain commits you create, you may\n","do so (now or later) by using -b with the checkout command again. Example:\n","\n","  git checkout -b <new-branch-name>\n","\n","Checking out files: 100% (11058/11058), done.\n","fatal: destination path 'pair_nequip' already exists and is not an empty directory.\n","Copying files...\n","Updating CMakeLists.txt...\n","Done!\n"]}]},{"cell_type":"code","source":["!cp /content/pair_nequip/*.cpp /content/lammps/src/\n","!cp /content/pair_nequip/*.h /content/lammps/src/\n","! sed -i 's/CMAKE_CXX_STANDARD 11/CMAKE_CXX_STANDARD 14/g'  /content/lammps/cmake/CMakeLists.txt"],"metadata":{"id":"100Be8B6m5am","executionInfo":{"status":"ok","timestamp":1657045667133,"user_tz":-120,"elapsed":343,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!pip install mkl mkl-include"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KlgRSmyom9VQ","executionInfo":{"status":"ok","timestamp":1657045669495,"user_tz":-120,"elapsed":2365,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"66cc6ba9-1304-4bd6-e2d5-c706d2ffb043"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (2022.1.0)\n","Requirement already satisfied: mkl-include in /usr/local/lib/python3.7/dist-packages (2022.1.0)\n","Requirement already satisfied: tbb==2021.* in /usr/local/lib/python3.7/dist-packages (from mkl) (2021.6.0)\n","Requirement already satisfied: intel-openmp==2022.* in /usr/local/lib/python3.7/dist-packages (from mkl) (2022.1.0)\n"]}]},{"cell_type":"code","source":["!cd lammps && mkdir -p build && cd build && cmake ../cmake -DCMAKE_PREFIX_PATH=`python -c 'import torch;print(torch.utils.cmake_prefix_path)'` && make -j4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t8vY6rwbnEgK","executionInfo":{"status":"ok","timestamp":1657045826853,"user_tz":-120,"elapsed":157363,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"f7c2910d-eff0-489d-8354-a52a4adb367d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["-- The CXX compiler identification is GNU 7.5.0\n","-- Detecting CXX compiler ABI info\n","-- Detecting CXX compiler ABI info - done\n","-- Check for working CXX compiler: /usr/bin/c++ - skipped\n","-- Detecting CXX compile features\n","-- Detecting CXX compile features - done\n","-- Found Git: /usr/bin/git (found version \"2.17.1\") \n","-- Appending /usr/local/cuda/lib64/stubs to CMAKE_LIBRARY_PATH: /usr/local/cuda/lib64/stubs\n","-- Running check for auto-generated files from make-based build system\n","-- Found MPI_CXX: /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so (found version \"3.1\") \n","-- Found MPI: TRUE (found version \"3.1\")  \n","-- Looking for C++ include omp.h\n","-- Looking for C++ include omp.h - found\n","-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n","-- Found OpenMP: TRUE (found version \"4.5\")  \n","-- Found JPEG: /usr/lib/x86_64-linux-gnu/libjpeg.so (found version \"80\") \n","-- Found PNG: /usr/lib/x86_64-linux-gnu/libpng.so (found version \"1.6.34\") \n","-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n","-- Found GZIP: /bin/gzip  \n","-- Found FFMPEG: /usr/bin/ffmpeg  \n","-- Looking for C++ include cmath\n","-- Looking for C++ include cmath - found\n","-- Generating style headers...\n","-- Generating package headers...\n","-- Generating lmpinstalledpkgs.h...\n","-- Could NOT find ClangFormat (missing: ClangFormat_EXECUTABLE) (Required is at least version \"8.0\")\n","-- The following tools and libraries have been found and configured:\n"," * Git\n"," * MPI\n"," * OpenMP\n"," * JPEG\n"," * PNG\n"," * ZLIB\n","\n","-- <<< Build configuration >>>\n","   Operating System: Linux Ubuntu 18.04\n","   Build type:       RelWithDebInfo\n","   Install path:     /root/.local\n","   Generator:        Unix Makefiles using /usr/bin/make\n","-- Enabled packages: <None>\n","-- <<< Compilers and Flags: >>>\n","-- C++ Compiler:     /usr/bin/c++\n","      Type:          GNU\n","      Version:       7.5.0\n","      C++ Flags:     -O2 -g -DNDEBUG\n","      Defines:       LAMMPS_SMALLBIG;LAMMPS_MEMALIGN=64;LAMMPS_OMP_COMPAT=3;LAMMPS_JPEG;LAMMPS_PNG;LAMMPS_GZIP;LAMMPS_FFMPEG\n","-- <<< Linker flags: >>>\n","-- Executable name:  lmp\n","-- Static library flags:    \n","-- <<< MPI flags >>>\n","-- MPI_defines:      MPICH_SKIP_MPICXX;OMPI_SKIP_MPICXX;_MPICC_H\n","-- MPI includes:     /usr/lib/x86_64-linux-gnu/openmpi/include/openmpi;/usr/lib/x86_64-linux-gnu/openmpi/include/openmpi/opal/mca/event/libevent2022/libevent;/usr/lib/x86_64-linux-gnu/openmpi/include/openmpi/opal/mca/event/libevent2022/libevent/include;/usr/lib/x86_64-linux-gnu/openmpi/include\n","-- MPI libraries:    /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so;/usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so;\n","-- Looking for C++ include pthread.h\n","-- Looking for C++ include pthread.h - found\n","-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n","-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed\n","-- Looking for pthread_create in pthreads\n","-- Looking for pthread_create in pthreads - not found\n","-- Looking for pthread_create in pthread\n","-- Looking for pthread_create in pthread - found\n","-- Found Threads: TRUE  \n","-- Found CUDA: /usr/local/cuda (found version \"11.1\") \n","-- Caffe2: CUDA detected: 11.1\n","-- Caffe2: CUDA nvcc is: /usr/local/cuda/bin/nvcc\n","-- Caffe2: CUDA toolkit directory: /usr/local/cuda\n","-- Caffe2: Header version is: 11.1\n","-- Found CUDNN: /usr/lib/x86_64-linux-gnu/libcudnn.so  \n","-- Found cuDNN: v7.6.5  (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libcudnn.so)\n","-- /usr/local/cuda/lib64/libnvrtc.so shorthash is 3a20f2b6\n","-- Autodetected CUDA architecture(s):  6.0\n","-- Added CUDA NVCC flags for: -gencode;arch=compute_60,code=sm_60\n","\u001b[33mCMake Warning at /usr/local/lib/python3.7/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:22 (message):\n","  static library kineto_LIBRARY-NOTFOUND not found.\n","Call Stack (most recent call first):\n","  /usr/local/lib/python3.7/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:127 (append_torchlib_if_found)\n","  CMakeLists.txt:922 (find_package)\n","\n","\u001b[0m\n","-- Found Torch: /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so  \n","-- Configuring done\n","-- Generating done\n","-- Build files have been written to: /content/lammps/build\n","[  1%] \u001b[34m\u001b[1mGenerating includes/lammps/variable.h\u001b[0m\n","[  1%] \u001b[34m\u001b[1mGenerating includes/lammps/angle.h\u001b[0m\n","[  1%] \u001b[34m\u001b[1mGenerating includes/lammps/atom.h\u001b[0m\n","-- Git Directory: /content/lammps/.git\n","[  1%] Built target variable.h\n","[  1%] Built target angle.h\n","[  1%] Built target atom.h\n","[  1%] \u001b[34m\u001b[1mGenerating includes/lammps/bond.h\u001b[0m\n","[  1%] \u001b[34m\u001b[1mGenerating includes/lammps/comm.h\u001b[0m\n","[  1%] \u001b[34m\u001b[1mGenerating includes/lammps/citeme.h\u001b[0m\n","[  1%] Built target bond.h\n","[  1%] Built target comm.h\n","[  1%] Built target citeme.h\n","[  2%] \u001b[34m\u001b[1mGenerating includes/lammps/compute.h\u001b[0m\n","[  2%] \u001b[34m\u001b[1mGenerating includes/lammps/dihedral.h\u001b[0m\n","[  2%] \u001b[34m\u001b[1mGenerating includes/lammps/domain.h\u001b[0m\n","[  2%] Built target compute.h\n","[  2%] Built target dihedral.h\n","[  2%] Built target domain.h\n","[  2%] \u001b[34m\u001b[1mGenerating includes/lammps/error.h\u001b[0m\n","[  2%] \u001b[34m\u001b[1mGenerating includes/lammps/fix.h\u001b[0m\n","[  2%] \u001b[34m\u001b[1mGenerating includes/lammps/force.h\u001b[0m\n","[  2%] Built target error.h\n","[  2%] Built target fix.h\n","[  2%] Built target force.h\n","[  3%] \u001b[34m\u001b[1mGenerating includes/lammps/group.h\u001b[0m\n","[  3%] \u001b[34m\u001b[1mGenerating includes/lammps/improper.h\u001b[0m\n","[  3%] \u001b[34m\u001b[1mGenerating includes/lammps/input.h\u001b[0m\n","[  3%] Built target group.h\n","[  3%] Built target improper.h\n","[  3%] Built target input.h\n","[  3%] \u001b[34m\u001b[1mGenerating includes/lammps/info.h\u001b[0m\n","[  4%] \u001b[34m\u001b[1mGenerating includes/lammps/kspace.h\u001b[0m\n","[  4%] \u001b[34m\u001b[1mGenerating includes/lammps/lammps.h\u001b[0m\n","[  4%] Built target info.h\n","[  4%] Built target lammps.h\n","[  4%] Built target kspace.h\n","[  4%] \u001b[34m\u001b[1mGenerating includes/lammps/lattice.h\u001b[0m\n","[  4%] \u001b[34m\u001b[1mGenerating includes/lammps/lmppython.h\u001b[0m\n","[  5%] \u001b[34m\u001b[1mGenerating includes/lammps/library.h\u001b[0m\n","[  5%] Built target lattice.h\n","[  5%] Built target lmppython.h\n","[  5%] Built target library.h\n","[  5%] \u001b[34m\u001b[1mGenerating includes/lammps/lmptype.h\u001b[0m\n","[  6%] \u001b[34m\u001b[1mGenerating includes/lammps/memory.h\u001b[0m\n","[  6%] \u001b[34m\u001b[1mGenerating includes/lammps/modify.h\u001b[0m\n","[  6%] Built target lmptype.h\n","[  6%] Built target memory.h\n","[  6%] Built target modify.h\n","[  6%] \u001b[34m\u001b[1mGenerating includes/lammps/neighbor.h\u001b[0m\n","[  6%] \u001b[34m\u001b[1mGenerating includes/lammps/neigh_list.h\u001b[0m\n","[  7%] \u001b[34m\u001b[1mGenerating includes/lammps/output.h\u001b[0m\n","[  7%] Built target neighbor.h\n","[  7%] Built target neigh_list.h\n","[  7%] Built target output.h\n","[  7%] \u001b[34m\u001b[1mGenerating includes/lammps/pair.h\u001b[0m\n","[  7%] \u001b[34m\u001b[1mGenerating includes/lammps/pointers.h\u001b[0m\n","[  7%] \u001b[34m\u001b[1mGenerating includes/lammps/region.h\u001b[0m\n","[  7%] Built target pair.h\n","[  7%] Built target pointers.h\n","[  7%] Built target region.h\n","[  8%] \u001b[34m\u001b[1mGenerating includes/lammps/timer.h\u001b[0m\n","[  8%] \u001b[34m\u001b[1mGenerating includes/lammps/update.h\u001b[0m\n","[  8%] Built target timer.h\n","[  8%] \u001b[34m\u001b[1mGenerating includes/lammps/universe.h\u001b[0m\n","[  8%] Built target update.h\n","[  8%] Built target universe.h\n","[  8%] \u001b[34m\u001b[1mGenerating includes/lammps/utils.h\u001b[0m\n","-- Generating lmpgitversion.h...\n","[  8%] Built target utils.h\n","[  8%] Built target gitversion\n","[  8%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/angle.cpp.o\u001b[0m\n","[  8%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/angle_deprecated.cpp.o\u001b[0m\n","[  9%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/angle_zero.cpp.o\u001b[0m\n","[  9%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/angle_hybrid.cpp.o\u001b[0m\n","[  9%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/arg_info.cpp.o\u001b[0m\n","[  9%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/atom.cpp.o\u001b[0m\n","[  9%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/atom_map.cpp.o\u001b[0m\n","[  9%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/atom_vec.cpp.o\u001b[0m\n","[ 10%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/atom_vec_atomic.cpp.o\u001b[0m\n","[ 10%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/atom_vec_body.cpp.o\u001b[0m\n","[ 10%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/atom_vec_charge.cpp.o\u001b[0m\n","[ 10%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/atom_vec_ellipsoid.cpp.o\u001b[0m\n","[ 11%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/atom_vec_hybrid.cpp.o\u001b[0m\n","[ 11%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/atom_vec_line.cpp.o\u001b[0m\n","[ 11%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/atom_vec_sphere.cpp.o\u001b[0m\n","[ 11%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/atom_vec_tri.cpp.o\u001b[0m\n","[ 12%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/balance.cpp.o\u001b[0m\n","[ 12%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/body.cpp.o\u001b[0m\n","[ 12%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/bond.cpp.o\u001b[0m\n","[ 12%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/bond_deprecated.cpp.o\u001b[0m\n","[ 13%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/bond_hybrid.cpp.o\u001b[0m\n","[ 13%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/bond_zero.cpp.o\u001b[0m\n","[ 13%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/change_box.cpp.o\u001b[0m\n","[ 13%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/citeme.cpp.o\u001b[0m\n","[ 13%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/comm.cpp.o\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/comm_brick.cpp.o\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/comm_tiled.cpp.o\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute.cpp.o\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_aggregate_atom.cpp.o\u001b[0m\n","[ 15%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_angle.cpp.o\u001b[0m\n","[ 15%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_angle_local.cpp.o\u001b[0m\n","[ 15%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_angmom_chunk.cpp.o\u001b[0m\n","[ 15%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_bond.cpp.o\u001b[0m\n","[ 16%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_bond_local.cpp.o\u001b[0m\n","[ 16%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_centro_atom.cpp.o\u001b[0m\n","[ 16%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_centroid_stress_atom.cpp.o\u001b[0m\n","[ 16%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_chunk_atom.cpp.o\u001b[0m\n","[ 16%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_chunk_spread_atom.cpp.o\u001b[0m\n","[ 17%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_cluster_atom.cpp.o\u001b[0m\n","[ 17%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_cna_atom.cpp.o\u001b[0m\n","[ 17%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_com.cpp.o\u001b[0m\n","[ 17%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_com_chunk.cpp.o\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_coord_atom.cpp.o\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_deprecated.cpp.o\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_dihedral.cpp.o\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_dihedral_local.cpp.o\u001b[0m\n","[ 19%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_dipole.cpp.o\u001b[0m\n","[ 19%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_dipole_chunk.cpp.o\u001b[0m\n","[ 19%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_displace_atom.cpp.o\u001b[0m\n","[ 19%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_erotate_sphere.cpp.o\u001b[0m\n","[ 20%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_erotate_sphere_atom.cpp.o\u001b[0m\n","[ 20%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_fragment_atom.cpp.o\u001b[0m\n","[ 20%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_global_atom.cpp.o\u001b[0m\n","[ 20%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_group_group.cpp.o\u001b[0m\n","[ 20%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_gyration.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_gyration_chunk.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_heat_flux.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_improper.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_improper_local.cpp.o\u001b[0m\n","[ 22%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_inertia_chunk.cpp.o\u001b[0m\n","[ 22%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_ke.cpp.o\u001b[0m\n","[ 22%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_ke_atom.cpp.o\u001b[0m\n","[ 22%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_msd.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_msd_chunk.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_omega_chunk.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_orientorder_atom.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_pair.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_pair_local.cpp.o\u001b[0m\n","[ 24%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_pe.cpp.o\u001b[0m\n","[ 24%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_pe_atom.cpp.o\u001b[0m\n","[ 24%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_pressure.cpp.o\u001b[0m\n","[ 24%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_property_atom.cpp.o\u001b[0m\n","[ 25%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_property_chunk.cpp.o\u001b[0m\n","[ 25%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_property_local.cpp.o\u001b[0m\n","[ 25%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_rdf.cpp.o\u001b[0m\n","[ 25%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_reduce.cpp.o\u001b[0m\n","[ 26%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_reduce_chunk.cpp.o\u001b[0m\n","[ 26%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_reduce_region.cpp.o\u001b[0m\n","[ 26%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_slice.cpp.o\u001b[0m\n","[ 26%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_stress_atom.cpp.o\u001b[0m\n","[ 27%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_temp.cpp.o\u001b[0m\n","[ 27%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_temp_chunk.cpp.o\u001b[0m\n","[ 27%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_temp_com.cpp.o\u001b[0m\n","[ 27%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_temp_deform.cpp.o\u001b[0m\n","[ 27%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_temp_partial.cpp.o\u001b[0m\n","[ 28%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_temp_profile.cpp.o\u001b[0m\n","[ 28%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_temp_ramp.cpp.o\u001b[0m\n","[ 28%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_temp_region.cpp.o\u001b[0m\n","[ 28%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_temp_sphere.cpp.o\u001b[0m\n","[ 29%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_torque_chunk.cpp.o\u001b[0m\n","[ 29%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_vacf.cpp.o\u001b[0m\n","[ 29%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/compute_vcm_chunk.cpp.o\u001b[0m\n","[ 29%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/create_atoms.cpp.o\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/create_bonds.cpp.o\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/create_box.cpp.o\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/delete_atoms.cpp.o\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/delete_bonds.cpp.o\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/deprecated.cpp.o\u001b[0m\n","[ 31%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/dihedral.cpp.o\u001b[0m\n","[ 31%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/dihedral_deprecated.cpp.o\u001b[0m\n","[ 31%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/dihedral_hybrid.cpp.o\u001b[0m\n","[ 31%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/dihedral_zero.cpp.o\u001b[0m\n","[ 32%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/displace_atoms.cpp.o\u001b[0m\n","[ 32%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/domain.cpp.o\u001b[0m\n","[ 32%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/dump.cpp.o\u001b[0m\n","[ 32%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/dump_atom.cpp.o\u001b[0m\n","[ 33%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/dump_cfg.cpp.o\u001b[0m\n","[ 33%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/dump_custom.cpp.o\u001b[0m\n","[ 33%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/dump_deprecated.cpp.o\u001b[0m\n","[ 33%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/dump_image.cpp.o\u001b[0m\n","[ 34%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/dump_local.cpp.o\u001b[0m\n","[ 34%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/dump_movie.cpp.o\u001b[0m\n","[ 34%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/dump_xyz.cpp.o\u001b[0m\n","[ 34%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/error.cpp.o\u001b[0m\n","[ 34%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/finish.cpp.o\u001b[0m\n","[ 35%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix.cpp.o\u001b[0m\n","[ 35%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_adapt.cpp.o\u001b[0m\n","[ 35%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_addforce.cpp.o\u001b[0m\n","[ 35%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_ave_atom.cpp.o\u001b[0m\n","[ 36%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_ave_chunk.cpp.o\u001b[0m\n","[ 36%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_ave_correlate.cpp.o\u001b[0m\n","[ 36%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_ave_histo.cpp.o\u001b[0m\n","[ 36%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_ave_histo_weight.cpp.o\u001b[0m\n","[ 37%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_ave_time.cpp.o\u001b[0m\n","[ 37%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_aveforce.cpp.o\u001b[0m\n","[ 37%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_balance.cpp.o\u001b[0m\n","[ 37%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_box_relax.cpp.o\u001b[0m\n","[ 37%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_deform.cpp.o\u001b[0m\n","[ 38%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_deposit.cpp.o\u001b[0m\n","[ 38%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_deprecated.cpp.o\u001b[0m\n","[ 38%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_dt_reset.cpp.o\u001b[0m\n","[ 38%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_dummy.cpp.o\u001b[0m\n","[ 39%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_efield.cpp.o\u001b[0m\n","[ 39%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_enforce2d.cpp.o\u001b[0m\n","[ 39%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_evaporate.cpp.o\u001b[0m\n","[ 39%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_external.cpp.o\u001b[0m\n","[ 40%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_gravity.cpp.o\u001b[0m\n","[ 40%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_group.cpp.o\u001b[0m\n","[ 40%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_halt.cpp.o\u001b[0m\n","[ 40%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_heat.cpp.o\u001b[0m\n","[ 40%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_indent.cpp.o\u001b[0m\n","[ 41%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_langevin.cpp.o\u001b[0m\n","[ 41%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_lineforce.cpp.o\u001b[0m\n","[ 41%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_minimize.cpp.o\u001b[0m\n","[ 41%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_momentum.cpp.o\u001b[0m\n","[ 42%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_move.cpp.o\u001b[0m\n","[ 42%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_neigh_history.cpp.o\u001b[0m\n","[ 42%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_nh.cpp.o\u001b[0m\n","[ 42%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_nh_sphere.cpp.o\u001b[0m\n","[ 43%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_nph.cpp.o\u001b[0m\n","[ 43%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_nph_sphere.cpp.o\u001b[0m\n","[ 43%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_npt.cpp.o\u001b[0m\n","[ 43%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_npt_sphere.cpp.o\u001b[0m\n","[ 44%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_nve.cpp.o\u001b[0m\n","[ 44%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_nve_limit.cpp.o\u001b[0m\n","[ 44%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_nve_noforce.cpp.o\u001b[0m\n","[ 44%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_nve_sphere.cpp.o\u001b[0m\n","[ 44%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_nvt.cpp.o\u001b[0m\n","[ 45%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_nvt_sllod.cpp.o\u001b[0m\n","[ 45%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_nvt_sphere.cpp.o\u001b[0m\n","[ 45%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_planeforce.cpp.o\u001b[0m\n","[ 45%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_press_berendsen.cpp.o\u001b[0m\n","[ 46%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_print.cpp.o\u001b[0m\n","[ 46%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_property_atom.cpp.o\u001b[0m\n","[ 46%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_read_restart.cpp.o\u001b[0m\n","[ 46%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_recenter.cpp.o\u001b[0m\n","[ 47%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_respa.cpp.o\u001b[0m\n","[ 47%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_restrain.cpp.o\u001b[0m\n","[ 47%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_setforce.cpp.o\u001b[0m\n","[ 47%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_spring.cpp.o\u001b[0m\n","[ 47%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_spring_chunk.cpp.o\u001b[0m\n","[ 48%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_spring_self.cpp.o\u001b[0m\n","[ 48%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_store.cpp.o\u001b[0m\n","[ 48%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_store_force.cpp.o\u001b[0m\n","[ 48%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_store_state.cpp.o\u001b[0m\n","[ 50%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_temp_berendsen.cpp.o\u001b[0m\n","[ 50%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_temp_rescale.cpp.o\u001b[0m\n","[ 50%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_thermal_conductivity.cpp.o\u001b[0m\n","[ 50%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_vector.cpp.o\u001b[0m\n","[ 51%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_viscous.cpp.o\u001b[0m\n","[ 51%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_wall.cpp.o\u001b[0m\n","[ 51%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_wall_harmonic.cpp.o\u001b[0m\n","[ 51%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_wall_lj1043.cpp.o\u001b[0m\n","[ 52%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_wall_lj126.cpp.o\u001b[0m\n","[ 52%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_wall_lj93.cpp.o\u001b[0m\n","[ 52%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_wall_morse.cpp.o\u001b[0m\n","[ 52%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_wall_reflect.cpp.o\u001b[0m\n","[ 52%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fix_wall_region.cpp.o\u001b[0m\n","[ 53%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fmtlib_format.cpp.o\u001b[0m\n","[ 53%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/fmtlib_os.cpp.o\u001b[0m\n","[ 53%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/force.cpp.o\u001b[0m\n","[ 53%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/gridcomm.cpp.o\u001b[0m\n","[ 54%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/group.cpp.o\u001b[0m\n","[ 54%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/hashlittle.cpp.o\u001b[0m\n","[ 54%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/image.cpp.o\u001b[0m\n","[ 54%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/imbalance.cpp.o\u001b[0m\n","[ 55%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/imbalance_group.cpp.o\u001b[0m\n","[ 55%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/imbalance_neigh.cpp.o\u001b[0m\n","[ 55%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/imbalance_store.cpp.o\u001b[0m\n","[ 55%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/imbalance_time.cpp.o\u001b[0m\n","[ 55%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/imbalance_var.cpp.o\u001b[0m\n","[ 56%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/improper.cpp.o\u001b[0m\n","[ 56%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/improper_deprecated.cpp.o\u001b[0m\n","[ 56%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/improper_hybrid.cpp.o\u001b[0m\n","[ 56%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/improper_zero.cpp.o\u001b[0m\n","[ 57%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/info.cpp.o\u001b[0m\n","[ 57%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/input.cpp.o\u001b[0m\n","[ 57%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/integrate.cpp.o\u001b[0m\n","[ 57%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/irregular.cpp.o\u001b[0m\n","[ 58%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/kspace.cpp.o\u001b[0m\n","[ 58%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/kspace_deprecated.cpp.o\u001b[0m\n","[ 58%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/lammps.cpp.o\u001b[0m\n","[ 58%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/lattice.cpp.o\u001b[0m\n","[ 59%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/library.cpp.o\u001b[0m\n","[ 59%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/lmppython.cpp.o\u001b[0m\n","[ 59%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/math_eigen.cpp.o\u001b[0m\n","[ 59%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/math_extra.cpp.o\u001b[0m\n","[ 59%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/math_special.cpp.o\u001b[0m\n","[ 60%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/memory.cpp.o\u001b[0m\n","[ 60%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/min.cpp.o\u001b[0m\n","[ 60%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/min_cg.cpp.o\u001b[0m\n","[ 60%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/min_fire.cpp.o\u001b[0m\n","[ 61%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/min_fire_old.cpp.o\u001b[0m\n","[ 61%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/min_hftn.cpp.o\u001b[0m\n","[ 61%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/min_linesearch.cpp.o\u001b[0m\n","[ 61%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/min_quickmin.cpp.o\u001b[0m\n","[ 62%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/min_sd.cpp.o\u001b[0m\n","[ 62%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/minimize.cpp.o\u001b[0m\n","[ 62%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/modify.cpp.o\u001b[0m\n","[ 62%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/molecule.cpp.o\u001b[0m\n","[ 62%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/my_page.cpp.o\u001b[0m\n","[ 63%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/my_pool_chunk.cpp.o\u001b[0m\n","[ 63%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nbin.cpp.o\u001b[0m\n","[ 63%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nbin_multi.cpp.o\u001b[0m\n","[ 63%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nbin_standard.cpp.o\u001b[0m\n","[ 64%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/neigh_list.cpp.o\u001b[0m\n","[ 64%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/neighbor.cpp.o\u001b[0m\n","[ 64%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/neigh_request.cpp.o\u001b[0m\n","[ 64%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair.cpp.o\u001b[0m\n","[ 65%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_copy.cpp.o\u001b[0m\n","[ 65%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_full_bin.cpp.o\u001b[0m\n","[ 65%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_full_bin_atomonly.cpp.o\u001b[0m\n","[ 65%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_full_bin_ghost.cpp.o\u001b[0m\n","[ 66%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_full_multi.cpp.o\u001b[0m\n","[ 66%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_full_multi_old.cpp.o\u001b[0m\n","[ 66%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_full_nsq.cpp.o\u001b[0m\n","[ 66%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_full_nsq_ghost.cpp.o\u001b[0m\n","[ 66%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_bin_atomonly_newton.cpp.o\u001b[0m\n","[ 67%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_bin_newtoff.cpp.o\u001b[0m\n","[ 67%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_bin_newtoff_ghost.cpp.o\u001b[0m\n","[ 67%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_bin_newton.cpp.o\u001b[0m\n","[ 67%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_bin_newton_tri.cpp.o\u001b[0m\n","[ 68%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_multi_newtoff.cpp.o\u001b[0m\n","[ 68%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_multi_newton.cpp.o\u001b[0m\n","[ 68%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_multi_newton_tri.cpp.o\u001b[0m\n","[ 68%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_multi_old_newtoff.cpp.o\u001b[0m\n","[ 69%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_multi_old_newton.cpp.o\u001b[0m\n","[ 69%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_multi_old_newton_tri.cpp.o\u001b[0m\n","[ 69%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_nsq_newtoff.cpp.o\u001b[0m\n","[ 69%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_nsq_newtoff_ghost.cpp.o\u001b[0m\n","[ 69%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_nsq_newton.cpp.o\u001b[0m\n","[ 70%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_respa_bin_newtoff.cpp.o\u001b[0m\n","[ 70%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_respa_bin_newton.cpp.o\u001b[0m\n","[ 70%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_respa_bin_newton_tri.cpp.o\u001b[0m\n","[ 70%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_respa_nsq_newtoff.cpp.o\u001b[0m\n","[ 71%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_respa_nsq_newton.cpp.o\u001b[0m\n","[ 71%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_size_bin_newtoff.cpp.o\u001b[0m\n","[ 71%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_size_bin_newton.cpp.o\u001b[0m\n","[ 71%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_size_bin_newton_tri.cpp.o\u001b[0m\n","[ 72%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_size_multi_newtoff.cpp.o\u001b[0m\n","[ 72%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_size_multi_newton.cpp.o\u001b[0m\n","[ 72%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_size_multi_newton_tri.cpp.o\u001b[0m\n","[ 72%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_size_multi_old_newtoff.cpp.o\u001b[0m\n","[ 72%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_size_multi_old_newton.cpp.o\u001b[0m\n","[ 73%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_size_multi_old_newton_tri.cpp.o\u001b[0m\n","[ 73%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_size_nsq_newtoff.cpp.o\u001b[0m\n","[ 73%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_half_size_nsq_newton.cpp.o\u001b[0m\n","[ 73%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_halffull_newtoff.cpp.o\u001b[0m\n","[ 74%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_halffull_newton.cpp.o\u001b[0m\n","[ 74%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_skip.cpp.o\u001b[0m\n","[ 74%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_skip_respa.cpp.o\u001b[0m\n","[ 74%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_skip_size.cpp.o\u001b[0m\n","[ 75%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_skip_size_off2on.cpp.o\u001b[0m\n","[ 75%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/npair_skip_size_off2on_oneside.cpp.o\u001b[0m\n","[ 75%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil.cpp.o\u001b[0m\n","[ 75%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_full_bin_2d.cpp.o\u001b[0m\n","[ 76%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_full_bin_3d.cpp.o\u001b[0m\n","[ 76%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_full_ghost_bin_2d.cpp.o\u001b[0m\n","[ 76%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_full_ghost_bin_3d.cpp.o\u001b[0m\n","[ 76%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_full_multi_2d.cpp.o\u001b[0m\n","[ 76%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_full_multi_3d.cpp.o\u001b[0m\n","[ 77%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_full_multi_old_2d.cpp.o\u001b[0m\n","[ 77%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_full_multi_old_3d.cpp.o\u001b[0m\n","[ 77%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_half_bin_2d.cpp.o\u001b[0m\n","[ 77%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_half_bin_2d_tri.cpp.o\u001b[0m\n","[ 78%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_half_bin_3d.cpp.o\u001b[0m\n","[ 78%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_half_bin_3d_tri.cpp.o\u001b[0m\n","[ 78%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_half_multi_2d.cpp.o\u001b[0m\n","[ 78%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_half_multi_2d_tri.cpp.o\u001b[0m\n","[ 79%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_half_multi_3d.cpp.o\u001b[0m\n","[ 79%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_half_multi_3d_tri.cpp.o\u001b[0m\n","[ 79%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_half_multi_old_2d.cpp.o\u001b[0m\n","[ 79%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_half_multi_old_2d_tri.cpp.o\u001b[0m\n","[ 79%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_half_multi_old_3d.cpp.o\u001b[0m\n","[ 80%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/nstencil_half_multi_old_3d_tri.cpp.o\u001b[0m\n","[ 80%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/ntopo.cpp.o\u001b[0m\n","[ 80%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/ntopo_angle_all.cpp.o\u001b[0m\n","[ 80%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/ntopo_angle_partial.cpp.o\u001b[0m\n","[ 81%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/ntopo_angle_template.cpp.o\u001b[0m\n","[ 81%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/ntopo_bond_all.cpp.o\u001b[0m\n","[ 81%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/ntopo_bond_partial.cpp.o\u001b[0m\n","[ 81%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/ntopo_bond_template.cpp.o\u001b[0m\n","[ 82%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/ntopo_dihedral_all.cpp.o\u001b[0m\n","[ 82%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/ntopo_dihedral_partial.cpp.o\u001b[0m\n","[ 82%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/ntopo_dihedral_template.cpp.o\u001b[0m\n","[ 82%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/ntopo_improper_all.cpp.o\u001b[0m\n","[ 83%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/ntopo_improper_partial.cpp.o\u001b[0m\n","[ 83%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/ntopo_improper_template.cpp.o\u001b[0m\n","[ 83%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/output.cpp.o\u001b[0m\n","[ 83%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair.cpp.o\u001b[0m\n","[ 83%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_born.cpp.o\u001b[0m\n","[ 84%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_buck.cpp.o\u001b[0m\n","[ 84%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_buck_coul_cut.cpp.o\u001b[0m\n","[ 84%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_coul_cut.cpp.o\u001b[0m\n","[ 84%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_coul_debye.cpp.o\u001b[0m\n","[ 85%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_coul_dsf.cpp.o\u001b[0m\n","[ 85%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_coul_wolf.cpp.o\u001b[0m\n","[ 85%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_deprecated.cpp.o\u001b[0m\n","[ 85%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_hybrid.cpp.o\u001b[0m\n","[ 86%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_hybrid_overlay.cpp.o\u001b[0m\n","[ 86%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_hybrid_scaled.cpp.o\u001b[0m\n","[ 86%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_lj_cut.cpp.o\u001b[0m\n","[ 86%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_lj_cut_coul_cut.cpp.o\u001b[0m\n","[ 86%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_lj_expand.cpp.o\u001b[0m\n","[ 87%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_morse.cpp.o\u001b[0m\n","[ 87%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_nequip.cpp.o\u001b[0m\n","[ 87%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_soft.cpp.o\u001b[0m\n","[ 87%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_table.cpp.o\u001b[0m\n","[ 88%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_yukawa.cpp.o\u001b[0m\n","[ 88%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_zbl.cpp.o\u001b[0m\n","[ 88%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/pair_zero.cpp.o\u001b[0m\n","[ 88%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/potential_file_reader.cpp.o\u001b[0m\n","[ 89%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/procmap.cpp.o\u001b[0m\n","[ 89%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/random_mars.cpp.o\u001b[0m\n","[ 89%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/random_park.cpp.o\u001b[0m\n","[ 89%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/rcb.cpp.o\u001b[0m\n","[ 90%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/read_data.cpp.o\u001b[0m\n","[ 90%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/read_dump.cpp.o\u001b[0m\n","[ 90%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/read_restart.cpp.o\u001b[0m\n","[ 90%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/reader.cpp.o\u001b[0m\n","[ 90%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/reader_native.cpp.o\u001b[0m\n","[ 91%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/reader_xyz.cpp.o\u001b[0m\n","[ 91%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/region.cpp.o\u001b[0m\n","[ 91%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/region_block.cpp.o\u001b[0m\n","[ 91%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/region_cone.cpp.o\u001b[0m\n","[ 92%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/region_cylinder.cpp.o\u001b[0m\n","[ 92%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/region_deprecated.cpp.o\u001b[0m\n","[ 92%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/region_intersect.cpp.o\u001b[0m\n","[ 92%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/region_plane.cpp.o\u001b[0m\n","[ 93%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/region_prism.cpp.o\u001b[0m\n","[ 93%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/region_sphere.cpp.o\u001b[0m\n","[ 93%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/region_union.cpp.o\u001b[0m\n","[ 93%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/replicate.cpp.o\u001b[0m\n","[ 93%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/rerun.cpp.o\u001b[0m\n","[ 94%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/reset_atom_ids.cpp.o\u001b[0m\n","[ 94%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/reset_mol_ids.cpp.o\u001b[0m\n","[ 94%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/respa.cpp.o\u001b[0m\n","[ 94%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/run.cpp.o\u001b[0m\n","[ 95%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/set.cpp.o\u001b[0m\n","[ 95%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/special.cpp.o\u001b[0m\n","[ 95%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/table_file_reader.cpp.o\u001b[0m\n","[ 95%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/tabular_function.cpp.o\u001b[0m\n","[ 96%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/text_file_reader.cpp.o\u001b[0m\n","[ 96%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/thermo.cpp.o\u001b[0m\n","[ 96%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/timer.cpp.o\u001b[0m\n","[ 96%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/tokenizer.cpp.o\u001b[0m\n","[ 97%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/universe.cpp.o\u001b[0m\n","[ 97%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/update.cpp.o\u001b[0m\n","[ 97%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/utils.cpp.o\u001b[0m\n","[ 97%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/variable.cpp.o\u001b[0m\n","\u001b[01m\u001b[K/content/lammps/src/variable.cpp:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kint LAMMPS_NS::Variable::next(int, char**)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K/content/lammps/src/variable.cpp:714:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ksize_t fread(void*, size_t, size_t, FILE*)\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n","         \u001b[01;35m\u001b[Kfread(buf,1,64,fp)\u001b[m\u001b[K;\n","         \u001b[01;35m\u001b[K~~~~~^~~~~~~~~~~~~\u001b[m\u001b[K\n","[ 97%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/velocity.cpp.o\u001b[0m\n","[ 98%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/verlet.cpp.o\u001b[0m\n","[ 98%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/write_coeff.cpp.o\u001b[0m\n","[ 98%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/write_data.cpp.o\u001b[0m\n","[ 98%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/write_dump.cpp.o\u001b[0m\n","[100%] \u001b[32mBuilding CXX object CMakeFiles/lammps.dir/content/lammps/src/write_restart.cpp.o\u001b[0m\n","[100%] \u001b[32m\u001b[1mLinking CXX static library liblammps.a\u001b[0m\n","[100%] Built target lammps\n","[100%] \u001b[32mBuilding CXX object CMakeFiles/lmp.dir/content/lammps/src/main.cpp.o\u001b[0m\n","[100%] \u001b[32m\u001b[1mLinking CXX executable lmp\u001b[0m\n","[100%] Built target lmp\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PHCh2aC7WfKj","executionInfo":{"status":"ok","timestamp":1657045828832,"user_tz":-120,"elapsed":1984,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"7dc07d18-0da5-4476-b783-9db8ab64f853"},"outputs":[{"output_type":"stream","name":"stdout","text":["._AIMD_data\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.google.drivefs.item-id#S'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.lastuseddate#PS'\n","AIMD_data/\n","AIMD_data/._WATER-frc-10k-1.xyz\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.google.drivefs.item-id#S'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.lastuseddate#PS'\n","AIMD_data/WATER-frc-10k-1.xyz\n","AIMD_data/._celldata.dat\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.google.drivefs.item-id#S'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.lastuseddate#PS'\n","AIMD_data/celldata.dat\n","AIMD_data/._WATER-pos-10k-1.xyz\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.google.drivefs.item-id#S'\n","tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.lastuseddate#PS'\n","AIMD_data/WATER-pos-10k-1.xyz\n"]}],"source":["# Uncomment if running on google colab\n","! tar -xzvf  /content/drive/MyDrive/Colab\\ Notebooks/MD_DFT/AIMD_data.tar.gz"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":20593,"status":"ok","timestamp":1657045849422,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"},"user_tz":-120},"id":"J51CA0Bod1Jv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bc6b207c-ca1b-418c-c122-0d77b9469979"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.12.20-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 7.1 MB/s \n","\u001b[?25hCollecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 56.2 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.6.0-py2.py3-none-any.whl (145 kB)\n","\u001b[K     |████████████████████████████████| 145 kB 50.8 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting setproctitle\n","  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=352574ac23c6e032d0aa9c9b0afd65b27f1b0ae51fd98e5f6b5e0e8f4c448c54\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.6.0 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.20\n","Cloning into 'nequip'...\n","remote: Enumerating objects: 183, done.\u001b[K\n","remote: Counting objects: 100% (183/183), done.\u001b[K\n","remote: Compressing objects: 100% (178/178), done.\u001b[K\n","remote: Total 183 (delta 8), reused 87 (delta 0), pack-reused 0\n","Receiving objects: 100% (183/183), 333.98 KiB | 15.18 MiB/s, done.\n","Resolving deltas: 100% (8/8), done.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing ./nequip\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nequip==0.5.5) (1.21.6)\n","Collecting ase\n","  Downloading ase-3.22.1-py3-none-any.whl (2.2 MB)\n","\u001b[K     |████████████████████████████████| 2.2 MB 7.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nequip==0.5.5) (4.64.0)\n","Requirement already satisfied: torch!=1.9.0,<=1.12,>=1.8 in /usr/local/lib/python3.7/dist-packages (from nequip==0.5.5) (1.10.0)\n","Collecting e3nn<0.6.0,>=0.3.5\n","  Downloading e3nn-0.5.0-py3-none-any.whl (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 74.9 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from nequip==0.5.5) (3.13)\n","Collecting torch-runstats>=0.2.0\n","  Downloading torch_runstats-0.2.0-py3-none-any.whl (8.1 kB)\n","Collecting torch-ema>=0.3.0\n","  Downloading torch_ema-0.3-py3-none-any.whl (5.5 kB)\n","Collecting scikit_learn<=1.0.1\n","  Downloading scikit_learn-1.0.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.2 MB)\n","\u001b[K     |████████████████████████████████| 23.2 MB 1.1 MB/s \n","\u001b[?25hRequirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from nequip==0.5.5) (4.1.1)\n","Collecting opt-einsum-fx>=0.1.4\n","  Downloading opt_einsum_fx-0.1.4-py3-none-any.whl (13 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from e3nn<0.6.0,>=0.3.5->nequip==0.5.5) (1.4.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from e3nn<0.6.0,>=0.3.5->nequip==0.5.5) (1.7.1)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from opt-einsum-fx>=0.1.4->e3nn<0.6.0,>=0.3.5->nequip==0.5.5) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from opt-einsum-fx>=0.1.4->e3nn<0.6.0,>=0.3.5->nequip==0.5.5) (21.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn<=1.0.1->nequip==0.5.5) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn<=1.0.1->nequip==0.5.5) (3.1.0)\n","Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from ase->nequip==0.5.5) (3.2.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->ase->nequip==0.5.5) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->ase->nequip==0.5.5) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->ase->nequip==0.5.5) (1.4.3)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->ase->nequip==0.5.5) (3.0.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.1.0->ase->nequip==0.5.5) (1.15.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->e3nn<0.6.0,>=0.3.5->nequip==0.5.5) (1.2.1)\n","Building wheels for collected packages: nequip\n","  Building wheel for nequip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nequip: filename=nequip-0.5.5-py3-none-any.whl size=138681 sha256=6c4b35ddb1448825672d7e0b2e46827d24f3738ef982939151560b2ced5a9d23\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-snt5l6zc/wheels/a8/8f/18/b30c4402c2d6ab52853310650b85822afe26aaae5f6d00356b\n","Successfully built nequip\n","Installing collected packages: opt-einsum-fx, torch-runstats, torch-ema, scikit-learn, e3nn, ase, nequip\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.0.2\n","    Uninstalling scikit-learn-1.0.2:\n","      Successfully uninstalled scikit-learn-1.0.2\n","Successfully installed ase-3.22.1 e3nn-0.5.0 nequip-0.5.5 opt-einsum-fx-0.1.4 scikit-learn-1.0.1 torch-ema-0.3 torch-runstats-0.2.0\n"]},{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fd2b6eb8130>"]},"metadata":{},"execution_count":9}],"source":["import numpy as np\n","import pandas as pd\n","# install wandb\n","!pip install wandb\n","# install nequip\n","#uncomment if running on google colab\n","!git clone --depth 1 \"https://github.com/gabriele16/nequip.git\"\n","!pip install nequip/\n","# fix colab imports\n","import site\n","site.main()\n","# set to allow anonymous WandB\n","import os\n","os.environ[\"WANDB_ANONYMOUS\"] = \"must\"\n","import numpy as np\n","from ase.io import read, write\n","np.random.seed(0)\n","torch.manual_seed(0)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1657045849423,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"},"user_tz":-120},"id":"jDJ9Re0arOb0"},"outputs":[],"source":["def MD_reader_xyz(f, data_dir, no_skip = 0):\n","  filename = os.path.join(data_dir, f)\n","  fo = open(filename, 'r')\n","  natoms_str = fo.read().rsplit(' i = ')[0]\n","  natoms = int(natoms_str.split('\\n')[0])\n","  fo.close()  \n","  fo = open(filename, 'r')\n","  samples = fo.read().split(natoms_str)[1:]\n","  steps = []\n","  xyz = []\n","  temperatures = []\n","  energies = []\n","  for sample in samples[::no_skip]:\n","     entries = sample.split('\\n')[:-1]\n","     energies.append(float(entries[0].split(\"=\")[-1]))\n","     temp = np.array([list(map(float, lv.split()[1:])) for lv in entries[1:]])\n","     xyz.append(temp[:,:])\n","  return natoms_str, np.array(xyz), np.array(energies)     "]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":219,"status":"ok","timestamp":1657048778258,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"},"user_tz":-120},"id":"DziQT_zjMKS4"},"outputs":[],"source":["def MD_writer_xyz(positions,forces,cell_vec_abc,energies,\n","                  data_dir,f,  conv_frc = 1.0 , conv_ener = 1.0 ):\n","\n","  filename = os.path.join(data_dir, f)\n","  fo = open(filename, 'w')\n","\n","  for it, frame in enumerate(positions):\n","    natoms = len(frame)\n","    fo.write(\"{:5d}\\n\".format(natoms))\n","    fo.write('Lattice=\"{:.5f} 0.0 0.0 0.0 {:.5f} 0.0 0.0 0.0 {:.5f}\" \\\n","    Properties=\"species:S:1:pos:R:3:forces:R:3\" \\\n","    energy={:.10f} pbc=\"T T T\"\\n'.format(cell_vec_abc[0],cell_vec_abc[1],cell_vec_abc[2],energies[it]*conv_ener)    \n","    )\n","    if it%100 == 0.0:\n","      print(it)\n","    force_frame = forces[it]\n","\n","    fo.write(\"\".join(\"{:8s} {:.8f} {:16.8f} {:16.8f}\\\n","     {:16.8f} {:16.8f} {:16.8f}\\n\".format(frame[iat].symbol,\n","                                          frame[iat].position[0],\n","                                          frame[iat].position[1],\n","                                          frame[iat].position[2],\n","                                          force_frame[iat].position[0]*conv_frc,\n","                                          force_frame[iat].position[1]*conv_frc,\n","                                          force_frame[iat].position[2]*conv_frc)\n","                                          for iat in range(len(frame))))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":213,"status":"ok","timestamp":1657045971473,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"},"user_tz":-120},"id":"Z2U5i3IZqLBI","outputId":"564483e6-ab34-4b97-c53a-4916345bc8d7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([9.85, 9.85, 9.85])"]},"metadata":{},"execution_count":12}],"source":["def read_cell(f,data_dir):\n","  filename = os.path.join(data_dir,f)\n","  fo = open(filename,'r')\n","  cell_list_abc = fo.read().split('\\n')[:-1]\n","  cell_vec_abc = np.array([list(map(float, lv.split())) for lv in cell_list_abc]).squeeze()\n","  return(cell_vec_abc)\n","\n","cell_vec_abc = read_cell('celldata.dat',data_dir + '/AIMD_data')\n","cell_vec_abc"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":8731,"status":"ok","timestamp":1657045981274,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"},"user_tz":-120},"id":"X9fcRMYnu5-V"},"outputs":[],"source":["wat_traj = read(data_dir +'AIMD_data/WATER-pos-10k-1.xyz',index=':')\n","wat_frc = read(data_dir + 'AIMD_data/WATER-frc-10k-1.xyz', index=':')"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":1760,"status":"ok","timestamp":1657045983030,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"},"user_tz":-120},"id":"jT7B4ryYu82t"},"outputs":[],"source":["natoms, positions, energies = MD_reader_xyz('WATER-pos-10k-1.xyz', data_dir + '/AIMD_data/', no_skip=1)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23136,"status":"ok","timestamp":1657046006161,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"},"user_tz":-120},"id":"xgmmJAU5l5F2","outputId":"416f5032-6dd4-4ef9-80c8-4d1d57d46666"},"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n"]}],"source":["MD_writer_xyz(wat_traj, wat_frc, cell_vec_abc, energies, data_dir + '/AIMD_data/', 'wat_pos_frc-10k.extxyz',conv_frc = 1.0, conv_ener = 27.211399)\n"]},{"cell_type":"markdown","metadata":{"id":"ZPqnt-SAXyvL"},"source":["### Turn on GPU\n","\n","Make sure Runtime --> Change runtime type is set to GPU"]},{"cell_type":"markdown","metadata":{"id":"-HDmxkn3z8_m"},"source":["## 3 Steps: \n","* Train: using a data set, train the neural network 🧠 \n","* Deploy: convert the Python-based model into a stand-alone potential file for fast execution ⚡\n","* Run: run Molecular Dynamics, Monte Carlo, Structural Minimization, ...  with it in LAMMPS 🏃"]},{"cell_type":"markdown","metadata":{"id":"6OD71eeDz7dA"},"source":["<img src=\"https://github.com/mir-group/nequip_mrs_tutorial/blob/master/all.png?raw=true\" width=\"60%\">"]},{"cell_type":"markdown","metadata":{"id":"62aEgq6QYFIn"},"source":["### Train a model"]},{"cell_type":"markdown","metadata":{"id":"ELdBzH_8z4_2"},"source":["<img src=\"https://github.com/mir-group/nequip_mrs_tutorial/blob/master/train.png?raw=true\" width=\"60%\">"]},{"cell_type":"markdown","metadata":{"id":"qX0QKkAauSZO"},"source":["This tutorial is set up to use `wandb` in anonymous mode; when you use NequIP yourself you will be presented with a login prompt."]},{"cell_type":"markdown","metadata":{"id":"1KuOIippfVfd"},"source":["Here, we will train a NequIP potential on the following system\n","\n","* Toluene\n","* sampled at T=500K from AIMD\n","* at CCSD(T) accuracy (gold standard of quantum chemistry)\n","* Using 100 training configurations\n","* The units of the reference data are in kcal/mol and A. If you're more familiar with eV, remember 1 kcal/mol is chemical accuracy and is approximately 43 meV"]},{"cell_type":"markdown","metadata":{"id":"2q_GyQfC0npt"},"source":["Start a training run: this will print output to our console, but it is usually more convenient to view the results in a web interface called Weights and Biases. Click the link next to the rocket emoji to watch the run in the WandB interface 🚀 \n","\n","In WandB, watch the followingkeys:\n","\n","* Plot 1: validation_all_f_mae, training_all_f_mae\n","* Plot 2: validation_e/N_mae, training_e/N_mae\n","\n","These are the validation/training error in all force components and the validation/training error in the potential energy, normalized by the number of atoms, respectively. "]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":984,"status":"ok","timestamp":1657046007141,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"},"user_tz":-120},"id":"fFCszShRk2RP","outputId":"439ed50c-a969-43ec-ba93-e0ff87747aa6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'root': 'results/water', 'run_name': 'example-run-water', 'seed': 123, 'dataset_seed': 456, 'append': True, 'default_dtype': 'float32', 'allow_tf32': False, 'r_max': 4.0, 'num_layers': 4, 'l_max': 1, 'parity': True, 'num_features': 32, 'nonlinearity_type': 'gate', 'resnet': False, 'nonlinearity_scalars': {'e': 'silu', 'o': 'tanh'}, 'nonlinearity_gates': {'e': 'silu', 'o': 'tanh'}, 'num_basis': 8, 'BesselBasis_trainable': True, 'PolynomialCutoff_p': 6, 'invariant_layers': 2, 'invariant_neurons': 64, 'avg_num_neighbors': 'auto', 'use_sc': True, 'dataset': 'ase', 'dataset_file_name': './AIMD_data/wat_pos_frc-10k.extxyz', 'ase_args': {'format': 'extxyz'}, 'include_keys': ['user_label'], 'key_mapping': {'user_label': 'label0'}, 'chemical_symbols': ['H', 'O'], 'verbose': 'info', 'log_batch_freq': 1, 'log_epoch_freq': 1, 'save_checkpoint_freq': -1, 'save_ema_checkpoint_freq': -1, 'n_train': 100, 'n_val': 50, 'learning_rate': 0.005, 'batch_size': 5, 'validation_batch_size': 10, 'max_epochs': 100000, 'train_val_split': 'random', 'shuffle': True, 'metrics_key': 'validation_loss', 'use_ema': True, 'ema_decay': 0.99, 'ema_use_num_updates': True, 'report_init_validation': True, 'early_stopping_patiences': {'validation_loss': 50}, 'early_stopping_delta': {'validation_loss': 0.005}, 'early_stopping_cumulative_delta': False, 'early_stopping_lower_bounds': {'LR': 1e-05}, 'early_stopping_upper_bounds': {'cumulative_wall': 1e+100}, 'loss_coeffs': {'forces': 1, 'total_energy': [1, 'PerAtomMSELoss']}, 'metrics_components': [['forces', 'mae'], ['forces', 'rmse'], ['forces', 'mae', {'PerSpecies': True, 'report_per_component': False}], ['forces', 'rmse', {'PerSpecies': True, 'report_per_component': False}], ['total_energy', 'mae'], ['total_energy', 'mae', {'PerAtom': True}]], 'optimizer_name': 'Adam', 'optimizer_amsgrad': False, 'optimizer_betas': (0.9, 0.999), 'optimizer_eps': 1e-08, 'optimizer_weight_decay': 0, 'max_gradient_norm': None, 'lr_scheduler_name': 'ReduceLROnPlateau', 'lr_scheduler_patience': 100, 'lr_scheduler_factor': 0.5, 'per_species_rescale_scales_trainable': False, 'per_species_rescale_shifts_trainable': False, 'per_species_rescale_shifts': 'dataset_per_atom_total_energy_mean', 'per_species_rescale_scales': 'dataset_forces_rms', 'global_rescale_shift': None, 'global_rescale_scale': 'dataset_forces_rms', 'global_rescale_shift_trainable': False, 'global_rescale_scale_trainable': False}"]},"metadata":{},"execution_count":16}],"source":["from nequip.utils import Config\n","config = Config.from_file(work_dir + 'configs/my-full-example.yaml')\n","config"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":611979,"status":"ok","timestamp":1657046619115,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"},"user_tz":-120},"id":"ukSnt_QD5avu","outputId":"31ee249d-ad84-4999-f34c-c69416de4e87"},"outputs":[{"output_type":"stream","name":"stdout","text":["'/content/drive/MyDrive/Colab Notebooks/nequip/configs/my-full-example.yaml'\n","Torch device: cuda\n","Processing dataset...\n","Loaded data: Batch(atomic_numbers=[960000, 1], batch=[960000], cell=[10000, 3, 3], edge_cell_shift=[25556838, 3], edge_index=[2, 25556838], forces=[960000, 3], pbc=[10000, 3], pos=[960000, 3], ptr=[10001], total_energy=[10000, 1])\n","Cached processed data to disk\n","Done!\n","Successfully loaded the data set of type ASEDataset(10000)...\n","Replace string dataset_forces_rms to 0.7736424803733826\n","Replace string dataset_per_atom_total_energy_mean to -5.736269474029541\n","Atomic outputs are scaled by: [H, O: 0.773642], shifted by [H, O: -5.736269].\n","Replace string dataset_forces_rms to 0.7736424803733826\n","Initially outputs are globally scaled by: 0.7736424803733826, total_energy are globally shifted by None.\n","Successfully built the network...\n","Number of weights: 154200\n","! Starting training ...\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      0     1          1.1         1.09       0.0137        0.606        0.807        0.515        0.787        0.651        0.688            1        0.846         8.69       0.0905\n","      0     2         1.02         1.01       0.0136        0.577        0.776        0.491        0.749         0.62        0.662        0.965        0.813         8.67       0.0904\n","      0     3        0.993        0.979       0.0136        0.574        0.765        0.494        0.734        0.614        0.659        0.943        0.801         8.66       0.0902\n","      0     4        0.973         0.96       0.0136        0.564        0.758         0.48        0.733        0.606        0.653        0.933        0.793         8.66       0.0902\n","      0     5         0.97        0.956       0.0136        0.571        0.756        0.491        0.732        0.612         0.65        0.934        0.792         8.67       0.0903\n","\n","\n","  Initialization     #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Initial Validation          0    4.099    0.005        0.998       0.0136         1.01        0.578        0.773        0.494        0.747        0.621        0.663        0.956        0.809         8.67       0.0903\n","Wall time: 4.0994240869999885\n","! Best model        0    1.012\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      1     1        0.886        0.873       0.0136         0.55        0.723        0.481        0.687        0.584        0.633        0.875        0.754         8.67       0.0904\n","      1     2         1.02         1.01      0.00602        0.576        0.778        0.498        0.733        0.616        0.664        0.968        0.816         5.76         0.06\n","      1     3         1.05         1.05      0.00202        0.586        0.792        0.499        0.759        0.629        0.675        0.986         0.83         3.34       0.0348\n","      1     4         1.01         1.01     0.000398        0.573        0.777        0.492        0.735        0.613        0.672        0.954        0.813         1.48       0.0154\n","      1     5        0.962        0.962      1.1e-05        0.576        0.759        0.499         0.73        0.615        0.655        0.933        0.794        0.245      0.00255\n","      1     6        0.956        0.956     1.51e-05        0.573        0.756        0.491        0.737        0.614        0.647        0.938        0.792        0.281      0.00293\n","      1     7        0.904        0.904     1.25e-05        0.553        0.736        0.472        0.715        0.594        0.632        0.908         0.77         0.26      0.00271\n","      1     8         0.89         0.89     1.98e-06         0.53         0.73        0.457        0.677        0.567        0.626        0.903        0.764       0.0919     0.000958\n","      1     9        0.826        0.826     0.000134        0.533        0.703        0.457        0.685        0.571        0.597        0.878        0.737         0.85      0.00886\n","      1    10        0.893        0.892     0.000483        0.558        0.731        0.474        0.726          0.6        0.627        0.903        0.765         1.63        0.017\n","      1    11        0.769        0.767      0.00151        0.505        0.678        0.435        0.646         0.54        0.581        0.838         0.71         2.89       0.0301\n","      1    12        0.654        0.651      0.00336        0.474        0.624        0.403        0.615        0.509        0.525        0.785        0.655          4.3       0.0448\n","      1    13        0.596         0.59      0.00568        0.458        0.594        0.394        0.586         0.49        0.509        0.735        0.622          5.6       0.0583\n","      1    14         0.59        0.581      0.00889        0.445         0.59        0.381        0.574        0.477          0.5        0.737        0.618            7       0.0729\n","      1    15        0.528        0.516       0.0123         0.41        0.556        0.343        0.544        0.443        0.463        0.705        0.584         8.24       0.0858\n","      1    16         0.46        0.445       0.0149        0.394        0.516        0.331         0.52        0.425        0.434         0.65        0.542         9.06       0.0943\n","      1    17        0.346        0.333       0.0135        0.345        0.446        0.303        0.427        0.365        0.388        0.545        0.466         8.63       0.0898\n","      1    18        0.335        0.325      0.00958         0.34        0.441        0.302        0.415        0.359        0.386        0.535         0.46         7.26       0.0756\n","      1    19        0.295        0.292      0.00273         0.33        0.418        0.286        0.416        0.351         0.36        0.515        0.438         3.86       0.0402\n","      1    20        0.273        0.272     0.000258        0.313        0.404        0.279        0.381         0.33        0.355        0.487        0.421         1.05       0.0109\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      1     1        0.298        0.298     0.000459        0.326        0.422        0.281        0.415        0.348        0.357        0.529        0.443         1.54       0.0161\n","      1     2        0.272        0.272     0.000466        0.312        0.403        0.272        0.391        0.332        0.348        0.497        0.422         1.55       0.0161\n","      1     3        0.253        0.253     0.000478        0.303        0.389        0.271        0.368         0.32        0.343        0.467        0.405          1.6       0.0166\n","      1     4        0.264        0.263     0.000554        0.311        0.397        0.274        0.385        0.329        0.343        0.486        0.415         1.71       0.0178\n","      1     5        0.265        0.264     0.000584        0.308        0.398        0.266        0.392        0.329        0.338        0.496        0.417         1.77       0.0185\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train               1    7.904    0.005        0.707      0.00477        0.712        0.481        0.651        0.414        0.615        0.515        0.557        0.805        0.681         4.02       0.0419\n","! Validation          1    7.904    0.005         0.27     0.000508         0.27        0.312        0.402        0.273         0.39        0.332        0.346        0.495        0.421         1.63        0.017\n","Wall time: 7.904909229000168\n","! Best model        1    0.270\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      2     1        0.271        0.266      0.00506        0.312        0.399        0.277        0.382         0.33         0.35        0.482        0.416         5.26       0.0548\n","      2     2        0.264        0.254         0.01        0.299         0.39        0.269        0.358        0.314        0.352        0.457        0.404          7.4       0.0771\n","      2     3        0.212          0.2       0.0121        0.266        0.346        0.231        0.335        0.283        0.298        0.426        0.362         8.14       0.0848\n","      2     4        0.208        0.199      0.00843        0.267        0.345        0.233        0.333        0.283        0.298        0.424        0.361          6.8       0.0709\n","      2     5        0.204        0.202       0.0017        0.268        0.348        0.233        0.339        0.286          0.3        0.428        0.364         3.05       0.0318\n","      2     6        0.161        0.161     5.64e-05         0.24         0.31         0.21        0.299        0.254        0.269        0.379        0.324        0.416      0.00433\n","      2     7        0.166        0.166     0.000211        0.246        0.315        0.213        0.312        0.262        0.271        0.389         0.33         1.01       0.0106\n","      2     8        0.152        0.151      0.00047         0.23        0.301        0.197        0.295        0.246        0.253         0.38        0.316         1.51       0.0157\n","      2     9        0.174        0.174     0.000555        0.247        0.322        0.211        0.318        0.264        0.272        0.405        0.338         1.74       0.0181\n","      2    10        0.154        0.154     0.000608        0.236        0.303        0.204        0.301        0.253         0.26        0.375        0.318          1.8       0.0187\n","      2    11        0.146        0.145     0.000921        0.231        0.295        0.205        0.284        0.244        0.256         0.36        0.308         2.24       0.0234\n","      2    12        0.163        0.162     0.000519        0.246        0.312        0.215        0.309        0.262        0.271         0.38        0.325         1.68       0.0175\n","      2    13        0.142        0.141      0.00095        0.226         0.29        0.195        0.289        0.242        0.245        0.364        0.305         2.28       0.0237\n","      2    14         0.13        0.128      0.00189        0.214        0.277        0.184        0.274        0.229        0.233        0.349        0.291         3.22       0.0335\n","      2    15        0.138        0.136      0.00232         0.22        0.285        0.193        0.273        0.233        0.246         0.35        0.298         3.58       0.0373\n","      2    16        0.147        0.146      0.00106        0.224        0.295        0.189        0.292        0.241        0.242         0.38        0.311         2.41       0.0251\n","      2    17        0.137        0.136     0.000125        0.222        0.286        0.194        0.279        0.236        0.244        0.355        0.299        0.797       0.0083\n","      2    18        0.137        0.137     2.39e-05         0.22        0.286         0.19        0.278        0.234        0.244        0.356          0.3        0.293      0.00306\n","      2    19        0.122        0.122     1.72e-05        0.208         0.27        0.182        0.262        0.222        0.233        0.332        0.282        0.261      0.00272\n","      2    20        0.126        0.126     0.000207        0.211        0.275        0.179        0.274        0.227        0.231        0.347        0.289         1.03       0.0107\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      2     1        0.128        0.128     2.56e-05        0.211        0.277        0.181        0.272        0.226        0.229        0.353        0.291        0.301      0.00313\n","      2     2        0.132        0.132     2.72e-05        0.215        0.281        0.186        0.275         0.23        0.239         0.35        0.294        0.334      0.00348\n","      2     3        0.114        0.114     2.28e-05        0.203        0.261        0.178        0.253        0.216        0.226        0.319        0.272        0.297       0.0031\n","      2     4         0.12         0.12     5.14e-05        0.205        0.268        0.179        0.257        0.218        0.229        0.333        0.281         0.48        0.005\n","      2     5        0.128        0.127     3.69e-05        0.211        0.276        0.179        0.274        0.227        0.229        0.353        0.291        0.412      0.00429\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train               2   10.981    0.005        0.165      0.00236        0.168        0.242        0.315         0.21        0.304        0.257        0.271        0.388        0.329         2.75       0.0286\n","! Validation          2   10.981    0.005        0.124     3.27e-05        0.124        0.209        0.273        0.181        0.266        0.223        0.231        0.342        0.286        0.365       0.0038\n","Wall time: 10.982024308000291\n","! Best model        2    0.124\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      3     1        0.123        0.122     0.000808        0.205         0.27        0.169        0.278        0.223        0.221        0.349        0.285         2.09       0.0218\n","      3     2        0.126        0.124       0.0011        0.209        0.273        0.181        0.265        0.223        0.231        0.341        0.286         2.45       0.0255\n","      3     3        0.127        0.126     0.000985        0.212        0.275        0.186        0.264        0.225        0.239        0.336        0.287         2.28       0.0237\n","      3     4        0.104        0.104     0.000141        0.192        0.249        0.165        0.245        0.205        0.212        0.311        0.261        0.858      0.00894\n","      3     5        0.122        0.122     0.000143        0.204         0.27        0.176        0.261        0.218        0.233        0.332        0.283        0.879      0.00916\n","      3     6        0.096       0.0958     0.000175        0.184         0.24        0.157        0.238        0.198        0.199        0.305        0.252        0.916      0.00954\n","      3     7        0.104        0.103     8.31e-05        0.193        0.249        0.166        0.246        0.206        0.211        0.311        0.261         0.59      0.00615\n","      3     8        0.114        0.114      7.5e-05        0.199        0.261        0.171        0.256        0.214        0.221        0.325        0.273        0.599      0.00624\n","      3     9        0.109        0.109     5.11e-05        0.196        0.255        0.169        0.251         0.21         0.22        0.313        0.267         0.46      0.00479\n","      3    10       0.0942       0.0939     0.000314        0.184        0.237        0.162        0.228        0.195        0.205         0.29        0.248         1.29       0.0135\n","      3    11        0.106        0.105     0.000213        0.189        0.251        0.163        0.239        0.201        0.213        0.314        0.263         1.01       0.0105\n","      3    12        0.091        0.091     8.79e-05        0.181        0.233        0.157        0.229        0.193        0.199         0.29        0.244        0.636      0.00663\n","      3    13        0.102        0.102     1.01e-05        0.193        0.247        0.169         0.24        0.204        0.214        0.302        0.258        0.212      0.00221\n","      3    14       0.0898       0.0897      8.1e-05         0.18        0.232         0.16        0.221        0.191        0.205        0.277        0.241        0.549      0.00572\n","      3    15       0.0934       0.0934      3.9e-05        0.185        0.236        0.159        0.236        0.198        0.201        0.294        0.248        0.401      0.00417\n","      3    16       0.0853       0.0852     0.000143        0.174        0.226        0.146         0.23        0.188        0.188        0.287        0.237        0.797       0.0083\n","      3    17       0.0797       0.0793     0.000375         0.17        0.218        0.149         0.21         0.18        0.194        0.259        0.227         1.43       0.0149\n","      3    18       0.0845       0.0843     0.000235        0.174        0.225        0.149        0.226        0.187        0.191         0.28        0.236         1.09       0.0114\n","      3    19       0.0986       0.0986      5.3e-05        0.187        0.243        0.162        0.239          0.2        0.206        0.303        0.255        0.472      0.00492\n","      3    20        0.086       0.0859     8.15e-05        0.175        0.227         0.15        0.226        0.188        0.194        0.282        0.238        0.543      0.00565\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      3     1       0.0955       0.0955     4.16e-05        0.182        0.239        0.155        0.234        0.195        0.199        0.304        0.251        0.397      0.00413\n","      3     2       0.0993       0.0992     1.05e-05        0.186        0.244        0.161        0.238        0.199         0.21          0.3        0.255        0.207      0.00216\n","      3     3       0.0819       0.0819     1.72e-05        0.171        0.221        0.151        0.212        0.182        0.194        0.268        0.231         0.26      0.00271\n","      3     4       0.0905       0.0904     3.05e-05        0.177        0.233        0.154        0.224        0.189        0.199        0.289        0.244        0.349      0.00364\n","      3     5       0.0939       0.0939     3.01e-05        0.181        0.237        0.154        0.235        0.195        0.198        0.301        0.249         0.36      0.00374\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train               3   14.070    0.005        0.101     0.000259        0.102        0.189        0.246        0.163        0.241        0.202         0.21        0.306        0.258        0.978       0.0102\n","! Validation          3   14.070    0.005       0.0922      2.6e-05       0.0922         0.18        0.235        0.155        0.228        0.192          0.2        0.292        0.246        0.314      0.00328\n","Wall time: 14.070420139000362\n","! Best model        3    0.092\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      4     1       0.0771        0.077     4.19e-05        0.165        0.215        0.142        0.211        0.177        0.183        0.268        0.225        0.433      0.00451\n","      4     2       0.0841       0.0841     7.49e-05        0.176        0.224         0.15        0.227        0.189        0.188        0.283        0.236        0.528       0.0055\n","      4     3       0.0764       0.0763     8.51e-05        0.169        0.214        0.146        0.216        0.181        0.183        0.265        0.224         0.58      0.00604\n","      4     4       0.0783       0.0781     0.000181        0.167        0.216        0.149        0.203        0.176        0.195        0.253        0.224        0.962         0.01\n","      4     5       0.0778       0.0776     0.000182        0.166        0.215        0.145        0.208        0.176        0.184        0.267        0.226        0.995       0.0104\n","      4     6       0.0773       0.0764     0.000954        0.164        0.214        0.143        0.206        0.174        0.184        0.264        0.224         2.27       0.0237\n","      4     7        0.079       0.0784     0.000582        0.167        0.217        0.144        0.211        0.178        0.186        0.268        0.227         1.78       0.0186\n","      4     8       0.0756       0.0756     1.68e-05        0.165        0.213        0.143        0.209        0.176        0.183        0.262        0.223        0.273      0.00284\n","      4     9       0.0743        0.074     0.000254        0.161         0.21        0.138        0.207        0.172        0.177        0.265        0.221         1.16        0.012\n","      4    10       0.0781       0.0775     0.000626        0.166        0.215        0.142        0.215        0.179        0.185        0.265        0.225         1.85       0.0192\n","      4    11       0.0728       0.0727     0.000119        0.159        0.209        0.135        0.207        0.171        0.175        0.263        0.219        0.802      0.00836\n","      4    12       0.0614       0.0613     7.83e-05        0.149        0.192        0.128        0.189        0.159        0.165        0.236          0.2        0.645      0.00672\n","      4    13       0.0592       0.0591     0.000127        0.146        0.188        0.126        0.185        0.156        0.162        0.231        0.197        0.772      0.00804\n","      4    14        0.076       0.0759     0.000102        0.164        0.213        0.142        0.208        0.175        0.183        0.263        0.223        0.695      0.00724\n","      4    15       0.0638       0.0634     0.000437        0.153        0.195        0.131        0.195        0.163        0.168        0.239        0.204         1.53       0.0159\n","      4    16       0.0782       0.0779     0.000291        0.164        0.216        0.142        0.207        0.174        0.185        0.267        0.226         1.25        0.013\n","      4    17       0.0531       0.0531     2.19e-05        0.137        0.178        0.121         0.17        0.145        0.158        0.213        0.185         0.31      0.00323\n","      4    18       0.0652       0.0647      0.00049        0.151        0.197        0.129        0.195        0.162        0.168        0.244        0.206         1.59       0.0165\n","      4    19       0.0546       0.0543     0.000306         0.14         0.18        0.124        0.172        0.148        0.158        0.219        0.188         1.26       0.0131\n","      4    20       0.0701       0.0701     2.87e-05         0.16        0.205         0.14          0.2         0.17         0.18        0.248        0.214        0.317       0.0033\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      4     1       0.0705       0.0704     3.88e-05        0.156        0.205        0.135          0.2        0.167        0.174        0.257        0.215        0.353      0.00368\n","      4     2       0.0728       0.0728     1.52e-05         0.16        0.209         0.14        0.199         0.17        0.184        0.251        0.217        0.246      0.00256\n","      4     3       0.0592       0.0592     1.65e-05        0.146        0.188         0.13        0.178        0.154        0.166        0.225        0.196        0.214      0.00222\n","      4     4       0.0646       0.0646      4.6e-05        0.151        0.197        0.131        0.192        0.161        0.168        0.243        0.206        0.424      0.00442\n","      4     5       0.0639       0.0638     3.91e-05        0.149        0.195        0.127        0.193         0.16        0.167        0.243        0.205        0.416      0.00433\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train               4   17.156    0.005       0.0714      0.00025       0.0716        0.159        0.207        0.138        0.202         0.17        0.178        0.255        0.216            1       0.0104\n","! Validation          4   17.156    0.005       0.0662     3.11e-05       0.0662        0.153        0.199        0.133        0.192        0.162        0.172        0.244        0.208        0.331      0.00344\n","Wall time: 17.156746571999975\n","! Best model        4    0.066\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      5     1       0.0655       0.0654     0.000103         0.15        0.198        0.132        0.186        0.159        0.173         0.24        0.206         0.62      0.00646\n","      5     2       0.0681       0.0681     1.48e-05        0.155        0.202        0.136        0.193        0.165        0.175        0.247        0.211        0.231       0.0024\n","      5     3       0.0581       0.0579     0.000272        0.142        0.186        0.123         0.18        0.151         0.16        0.229        0.195         1.22       0.0127\n","      5     4       0.0548       0.0544     0.000457        0.139         0.18         0.12        0.177        0.148        0.154        0.224        0.189         1.55       0.0161\n","      5     5       0.0492       0.0492      2.3e-05        0.134        0.172        0.118        0.165        0.141         0.15        0.208        0.179        0.237      0.00247\n","      5     6       0.0518       0.0516     0.000216        0.137        0.176        0.119        0.173        0.146        0.153        0.214        0.184         1.09       0.0113\n","      5     7       0.0521       0.0519     0.000204        0.138        0.176        0.119        0.177        0.148        0.149        0.221        0.185         1.02       0.0107\n","      5     8       0.0561       0.0558     0.000307        0.142        0.183        0.125        0.175         0.15        0.161         0.22         0.19         1.26       0.0132\n","      5     9       0.0494       0.0494     2.25e-05        0.132        0.172        0.115        0.167        0.141        0.151        0.208        0.179        0.305      0.00318\n","      5    10       0.0549       0.0544     0.000547         0.14         0.18        0.125        0.172        0.148         0.16        0.216        0.188         1.68       0.0175\n","      5    11       0.0634       0.0632     0.000278        0.149        0.194        0.129        0.189        0.159        0.168        0.239        0.203          1.2       0.0125\n","      5    12       0.0523       0.0523     4.62e-05        0.137        0.177        0.121        0.171        0.146        0.156        0.212        0.184        0.372      0.00388\n","      5    13       0.0529       0.0524     0.000496        0.136        0.177        0.121        0.166        0.144        0.158         0.21        0.184         1.65       0.0172\n","      5    14       0.0448       0.0441     0.000639        0.128        0.163        0.112        0.159        0.135        0.142        0.197         0.17         1.86       0.0193\n","      5    15       0.0455        0.045     0.000451        0.127        0.164        0.111        0.159        0.135        0.142        0.201        0.172         1.52       0.0159\n","      5    16       0.0498       0.0497     4.93e-05        0.134        0.173        0.122        0.158         0.14        0.159        0.197        0.178        0.485      0.00506\n","      5    17       0.0467       0.0456      0.00112        0.126        0.165        0.108        0.162        0.135        0.137        0.211        0.174         2.48       0.0258\n","      5    18       0.0435       0.0421      0.00141        0.122        0.159        0.108        0.149        0.129        0.142        0.189        0.165         2.78        0.029\n","      5    19       0.0499       0.0496     0.000354        0.134        0.172        0.117        0.169        0.143        0.151        0.208         0.18         1.37       0.0142\n","      5    20       0.0523       0.0523     2.07e-05        0.135        0.177        0.121        0.163        0.142        0.157         0.21        0.184         0.28      0.00291\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      5     1        0.057       0.0569     7.59e-05        0.141        0.185        0.123        0.177         0.15        0.159        0.228        0.193        0.609      0.00634\n","      5     2       0.0581        0.058     2.68e-05        0.143        0.186        0.127        0.175        0.151        0.167         0.22        0.194        0.343      0.00358\n","      5     3       0.0472       0.0472     3.81e-05         0.13        0.168        0.117        0.156        0.137        0.151        0.198        0.174        0.411      0.00428\n","      5     4       0.0511        0.051     6.41e-05        0.135        0.175        0.117         0.17        0.144        0.151        0.214        0.183        0.512      0.00533\n","      5     5       0.0495       0.0494     5.53e-05        0.132        0.172        0.114        0.168        0.141        0.149         0.21         0.18        0.465      0.00485\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train               5   20.239    0.005       0.0527     0.000352       0.0531        0.137        0.178         0.12         0.17        0.145        0.155        0.216        0.185         1.16       0.0121\n","! Validation          5   20.239    0.005       0.0525      5.2e-05       0.0526        0.136        0.177         0.12        0.169        0.144        0.155        0.214        0.185        0.468      0.00488\n","Wall time: 20.24006836300032\n","! Best model        5    0.053\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      6     1       0.0453       0.0448     0.000445        0.126        0.164        0.109        0.161        0.135        0.141        0.202        0.171         1.55       0.0161\n","      6     2       0.0424        0.042     0.000383        0.124        0.159        0.109        0.153        0.131        0.138        0.193        0.166         1.44        0.015\n","      6     3       0.0456       0.0455      7.2e-05        0.128        0.165        0.114        0.156        0.135        0.149        0.193        0.171        0.546      0.00568\n","      6     4       0.0527       0.0526      0.00014        0.136        0.177        0.122        0.164        0.143        0.158         0.21        0.184        0.856      0.00892\n","      6     5       0.0449       0.0449     4.64e-05        0.127        0.164        0.113        0.157        0.135        0.145        0.197        0.171        0.455      0.00474\n","      6     6       0.0495       0.0494     2.64e-05         0.13        0.172        0.115         0.16        0.137        0.154        0.203        0.179        0.327      0.00341\n","      6     7       0.0434       0.0433     8.42e-05        0.126        0.161        0.113        0.152        0.132        0.143        0.192        0.168        0.612      0.00637\n","      6     8       0.0442       0.0438     0.000379        0.124        0.162        0.109        0.156        0.132         0.14        0.199         0.17         1.42       0.0148\n","      6     9       0.0379       0.0377     0.000176        0.118         0.15        0.103        0.148        0.126        0.132        0.181        0.157        0.948      0.00987\n","      6    10       0.0474       0.0474     3.31e-05        0.129        0.168        0.112        0.162        0.137        0.147        0.205        0.176        0.404      0.00421\n","      6    11       0.0528       0.0528     7.14e-05        0.136        0.178        0.119        0.169        0.144        0.156        0.215        0.185        0.602      0.00627\n","      6    12       0.0461       0.0458     0.000275        0.129        0.166        0.115        0.157        0.136        0.146        0.198        0.172         1.17       0.0122\n","      6    13       0.0471       0.0466     0.000523        0.129        0.167        0.115        0.158        0.137        0.148          0.2        0.174         1.67       0.0174\n","      6    14       0.0448       0.0448     2.81e-05        0.128        0.164        0.114        0.155        0.134        0.147        0.192         0.17        0.355      0.00369\n","      6    15       0.0396       0.0396     6.03e-05        0.118        0.154        0.104        0.146        0.125        0.133        0.189        0.161        0.441       0.0046\n","      6    16       0.0442       0.0441     0.000122        0.126        0.163        0.111        0.156        0.134        0.142        0.197         0.17        0.722      0.00752\n","      6    17       0.0422       0.0421     9.92e-05        0.122        0.159        0.111        0.143        0.127        0.146        0.181        0.164        0.709      0.00738\n","      6    18        0.036        0.036     1.88e-05        0.115        0.147        0.102        0.142        0.122        0.129        0.176        0.153        0.292      0.00304\n","      6    19       0.0491       0.0487     0.000432        0.131        0.171        0.116        0.161        0.139        0.151        0.204        0.178         1.53       0.0159\n","      6    20       0.0427       0.0426     4.25e-05        0.124         0.16         0.11        0.152        0.131        0.143        0.189        0.166        0.393      0.00409\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      6     1       0.0489       0.0488     4.61e-05        0.131        0.171        0.115        0.163        0.139        0.149        0.208        0.179         0.47      0.00489\n","      6     2        0.049        0.049     1.28e-05        0.132        0.171        0.118        0.161        0.139        0.154        0.202        0.178        0.221      0.00231\n","      6     3       0.0405       0.0404     1.79e-05        0.121        0.156        0.109        0.144        0.127         0.14        0.182        0.161        0.269      0.00281\n","      6     4       0.0433       0.0433      5.3e-05        0.125        0.161        0.108        0.157        0.133         0.14        0.197        0.168        0.441      0.00459\n","      6     5        0.042        0.042     4.32e-05        0.121        0.159        0.106        0.152        0.129        0.139        0.191        0.165        0.442      0.00461\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train               6   23.334    0.005       0.0447     0.000173       0.0449        0.126        0.164        0.112        0.155        0.134        0.145        0.196         0.17        0.822      0.00856\n","! Validation          6   23.334    0.005       0.0447     3.46e-05       0.0448        0.126        0.164        0.111        0.155        0.133        0.144        0.196         0.17        0.369      0.00384\n","Wall time: 23.334450378000383\n","! Best model        6    0.045\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      7     1       0.0446       0.0441     0.000478        0.125        0.163        0.112        0.151        0.132        0.146        0.191        0.169         1.59       0.0165\n","      7     2       0.0433       0.0431     0.000225        0.124        0.161        0.107        0.156        0.132        0.139        0.197        0.168          1.1       0.0115\n","      7     3       0.0452       0.0451     0.000118        0.127        0.164         0.11        0.161        0.135        0.141        0.203        0.172        0.759       0.0079\n","      7     4       0.0437       0.0437     3.33e-05        0.125        0.162        0.114        0.147        0.131        0.147        0.188        0.167         0.37      0.00385\n","      7     5       0.0422       0.0415     0.000725        0.121        0.158        0.108        0.145        0.127        0.144        0.182        0.163         1.97       0.0205\n","      7     6       0.0384       0.0379      0.00051        0.118        0.151        0.106        0.142        0.124        0.136        0.176        0.156         1.63        0.017\n","      7     7       0.0405       0.0405     4.53e-05        0.121        0.156        0.109        0.144        0.127        0.138        0.185        0.162        0.414      0.00431\n","      7     8       0.0393       0.0393     4.58e-05        0.117        0.153        0.105        0.142        0.124        0.137        0.182        0.159        0.404      0.00421\n","      7     9       0.0416       0.0416     3.52e-05        0.121        0.158        0.109        0.144        0.126        0.139        0.189        0.164        0.342      0.00356\n","      7    10       0.0414       0.0414     5.21e-05        0.122        0.157        0.106        0.154         0.13        0.135        0.195        0.165        0.531      0.00553\n","      7    11       0.0485       0.0485     3.46e-05        0.131         0.17         0.12        0.154        0.137        0.158        0.192        0.175        0.352      0.00367\n","      7    12       0.0405       0.0404     0.000138         0.12        0.155        0.107        0.146        0.127        0.139        0.183        0.161        0.845       0.0088\n","      7    13       0.0411        0.041     0.000157         0.12        0.157        0.109        0.143        0.126        0.142        0.182        0.162        0.764      0.00796\n","      7    14       0.0439       0.0438     0.000112        0.126        0.162        0.113        0.153        0.133        0.145        0.191        0.168        0.774      0.00807\n","      7    15       0.0353        0.035     0.000323        0.112        0.145       0.0982         0.14        0.119        0.126        0.176        0.151         1.31       0.0136\n","      7    16       0.0433       0.0433     8.89e-07        0.124        0.161        0.114        0.143        0.129         0.15         0.18        0.165        0.054     0.000563\n","      7    17       0.0332       0.0331     4.84e-05        0.109        0.141       0.0961        0.135        0.115        0.122        0.172        0.147        0.407      0.00424\n","      7    18       0.0402       0.0402     3.99e-05         0.12        0.155        0.109        0.143        0.126         0.14        0.181        0.161        0.394       0.0041\n","      7    19       0.0375       0.0373     0.000107        0.115         0.15          0.1        0.144        0.122         0.13        0.182        0.156        0.621      0.00646\n","      7    20         0.04       0.0399     0.000125        0.119        0.154        0.105        0.146        0.126        0.135        0.187        0.161        0.814      0.00848\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      7     1       0.0438       0.0437     4.17e-05        0.124        0.162        0.109        0.155        0.132        0.141        0.197        0.169        0.434      0.00452\n","      7     2        0.043        0.043      1.2e-05        0.124         0.16         0.11        0.151        0.131        0.143         0.19        0.167        0.216      0.00225\n","      7     3       0.0362       0.0362     1.68e-05        0.115        0.147        0.103        0.138         0.12        0.132        0.174        0.153        0.248      0.00258\n","      7     4       0.0385       0.0385     5.29e-05        0.117        0.152        0.102        0.148        0.125        0.132        0.185        0.159        0.446      0.00465\n","      7     5       0.0376       0.0376      4.3e-05        0.115         0.15        0.101        0.143        0.122        0.132         0.18        0.156        0.439      0.00458\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train               7   26.418    0.005        0.041     0.000168       0.0412        0.121        0.157        0.108        0.147        0.127         0.14        0.186        0.163        0.772      0.00804\n","! Validation          7   26.418    0.005       0.0398     3.33e-05       0.0398        0.119        0.154        0.105        0.147        0.126        0.136        0.185        0.161        0.357      0.00372\n","Wall time: 26.418453201000375\n","! Best model        7    0.040\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      8     1       0.0299       0.0299     4.43e-05        0.103        0.134       0.0917        0.126        0.109        0.118        0.161        0.139        0.445      0.00464\n","      8     2       0.0362       0.0361     9.67e-05        0.112        0.147        0.101        0.134        0.117        0.133        0.172        0.152        0.588      0.00612\n","      8     3       0.0387       0.0387     4.94e-06        0.119        0.152        0.108         0.14        0.124         0.14        0.174        0.157       0.0966      0.00101\n","      8     4       0.0396       0.0396     1.95e-05         0.12        0.154        0.107        0.147        0.127        0.137        0.183         0.16        0.293      0.00305\n","      8     5       0.0411        0.041     6.88e-05         0.12        0.157        0.105         0.15        0.127        0.137         0.19        0.163        0.506      0.00527\n","      8     6       0.0396       0.0396     3.35e-05        0.117        0.154        0.104        0.141        0.123        0.136        0.184         0.16        0.362      0.00377\n","      8     7       0.0333       0.0332     0.000128         0.11        0.141       0.0948        0.139        0.117        0.121        0.174        0.147         0.74      0.00771\n","      8     8       0.0384       0.0384     1.92e-05        0.115        0.152        0.102        0.141        0.121        0.133        0.183        0.158        0.277      0.00288\n","      8     9       0.0291        0.029     2.93e-05        0.103        0.132       0.0927        0.125        0.109        0.117        0.158        0.137        0.333      0.00347\n","      8    10       0.0376       0.0376     8.63e-05        0.116         0.15        0.104        0.141        0.122        0.134        0.178        0.156        0.678      0.00706\n","      8    11       0.0377       0.0377     4.45e-05        0.117         0.15        0.103        0.144        0.124        0.132        0.181        0.157         0.47       0.0049\n","      8    12       0.0328       0.0324     0.000407        0.108        0.139       0.0939        0.135        0.114         0.12        0.171        0.146         1.42       0.0147\n","      8    13       0.0299       0.0296     0.000261        0.104        0.133       0.0935        0.125        0.109        0.122        0.153        0.138         1.16       0.0121\n","      8    14       0.0334       0.0333     5.39e-05        0.109        0.141       0.0955        0.135        0.115        0.124         0.17        0.147        0.513      0.00534\n","      8    15       0.0361       0.0359      0.00024        0.111        0.146       0.0993        0.136        0.117        0.131        0.173        0.152         1.11       0.0115\n","      8    16       0.0342       0.0337      0.00044        0.111        0.142       0.0989        0.134        0.116        0.129        0.166        0.147         1.55       0.0161\n","      8    17       0.0308       0.0307     0.000105        0.106        0.136       0.0922        0.133        0.113        0.117        0.166        0.142        0.643       0.0067\n","      8    18       0.0374       0.0373     9.25e-05        0.115         0.15       0.0993        0.145        0.122        0.129        0.184        0.156         0.68      0.00709\n","      8    19       0.0359       0.0357     0.000273        0.113        0.146        0.099         0.14         0.12        0.129        0.176        0.152         1.19       0.0124\n","      8    20       0.0296       0.0294     0.000229        0.104        0.133       0.0905        0.131        0.111        0.115        0.162        0.139          1.1       0.0115\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      8     1       0.0394       0.0394     3.76e-05        0.118        0.154        0.104        0.147        0.125        0.134        0.186         0.16        0.379      0.00395\n","      8     2       0.0382       0.0382     1.38e-05        0.117        0.151        0.104        0.144        0.124        0.135         0.18        0.157        0.207      0.00216\n","      8     3       0.0328       0.0327     1.83e-05        0.109         0.14       0.0976        0.132        0.115        0.125        0.166        0.146        0.251      0.00261\n","      8     4       0.0347       0.0347     5.41e-05        0.111        0.144       0.0969        0.139        0.118        0.126        0.175         0.15        0.465      0.00485\n","      8     5        0.034        0.034     4.44e-05         0.11        0.143       0.0964        0.136        0.116        0.126        0.171        0.149        0.422      0.00439\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train               8   29.505    0.005       0.0349     0.000134       0.0351        0.112        0.145       0.0988        0.137        0.118        0.128        0.173        0.151        0.708      0.00737\n","! Validation          8   29.505    0.005       0.0358     3.36e-05       0.0358        0.113        0.146       0.0997         0.14         0.12        0.129        0.176        0.153        0.345      0.00359\n","Wall time: 29.505406829000094\n","! Best model        8    0.036\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      9     1       0.0374       0.0371     0.000358        0.114        0.149          0.1         0.14         0.12        0.131         0.18        0.155         1.38       0.0144\n","      9     2       0.0341       0.0333     0.000787        0.109        0.141       0.0967        0.135        0.116        0.124        0.171        0.147         2.02       0.0211\n","      9     3        0.031       0.0308     0.000168        0.106        0.136        0.095        0.129        0.112        0.121        0.161        0.141        0.905      0.00943\n","      9     4       0.0339       0.0338     0.000121        0.109        0.142          0.1        0.127        0.114        0.132        0.161        0.146        0.769      0.00801\n","      9     5       0.0258       0.0254     0.000422       0.0969        0.123       0.0863        0.118        0.102        0.111        0.145        0.128         1.48       0.0154\n","      9     6       0.0361        0.036     0.000135        0.114        0.147        0.103        0.138         0.12        0.132        0.173        0.152        0.793      0.00826\n","      9     7       0.0318       0.0317     0.000103        0.107        0.138       0.0942        0.133        0.113        0.121        0.166        0.144        0.722      0.00752\n","      9     8       0.0346       0.0345     3.68e-05        0.112        0.144       0.0971        0.141        0.119        0.125        0.175         0.15        0.321      0.00335\n","      9     9       0.0313       0.0312     9.52e-05        0.105        0.137       0.0934        0.128        0.111        0.122        0.162        0.142         0.71      0.00739\n","      9    10       0.0319       0.0319     2.97e-05        0.107        0.138       0.0933        0.135        0.114        0.119        0.171        0.145        0.328      0.00341\n","      9    11       0.0327       0.0327     2.59e-05        0.109         0.14       0.0973        0.131        0.114        0.123        0.168        0.146        0.307       0.0032\n","      9    12       0.0355       0.0353      0.00017        0.113        0.145          0.1        0.138        0.119        0.129        0.174        0.151        0.934      0.00973\n","      9    13         0.03       0.0299     0.000172        0.103        0.134       0.0905        0.127        0.109        0.116        0.163         0.14        0.956      0.00996\n","      9    14       0.0346       0.0346     4.01e-05        0.113        0.144        0.104        0.131        0.118        0.132        0.166        0.149         0.37      0.00386\n","      9    15       0.0305       0.0304      9.8e-05        0.104        0.135       0.0933        0.127         0.11        0.119        0.161         0.14        0.619      0.00645\n","      9    16       0.0366       0.0366     4.08e-05        0.113        0.148       0.0992        0.141         0.12        0.129         0.18        0.154        0.446      0.00464\n","      9    17       0.0304       0.0303     0.000139        0.105        0.135       0.0947        0.125         0.11        0.122        0.157         0.14        0.828      0.00862\n","      9    18       0.0335       0.0335     1.86e-05        0.109        0.142       0.0964        0.134        0.115        0.125         0.17        0.148        0.269       0.0028\n","      9    19       0.0324       0.0324     4.56e-05        0.106        0.139       0.0953        0.127        0.111        0.127        0.161        0.144        0.472      0.00492\n","      9    20       0.0244       0.0244     1.93e-05       0.0943        0.121       0.0812        0.121        0.101        0.103         0.15        0.127        0.281      0.00293\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","      9     1       0.0358       0.0357     3.66e-05        0.112        0.146       0.0985         0.14        0.119        0.128        0.178        0.153        0.368      0.00383\n","      9     2       0.0344       0.0343     1.48e-05        0.111        0.143       0.0985        0.137        0.118        0.127        0.171        0.149        0.213      0.00222\n","      9     3       0.0296       0.0296     1.89e-05        0.104        0.133       0.0925        0.126        0.109        0.118        0.159        0.139        0.263      0.00273\n","      9     4       0.0313       0.0313     5.28e-05        0.105        0.137       0.0922        0.132        0.112         0.12        0.166        0.143        0.459      0.00478\n","      9     5       0.0309       0.0308     4.41e-05        0.105        0.136       0.0916        0.131        0.111         0.12        0.164        0.142        0.413       0.0043\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train               9   32.581    0.005       0.0323     0.000151       0.0324        0.107        0.139       0.0955        0.131        0.113        0.123        0.166        0.145        0.746      0.00777\n","! Validation          9   32.581    0.005       0.0324     3.34e-05       0.0324        0.107        0.139       0.0947        0.133        0.114        0.123        0.168        0.145        0.343      0.00357\n","Wall time: 32.582151529000384\n","! Best model        9    0.032\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     10     1         0.03         0.03     2.87e-05        0.103        0.134        0.091        0.128        0.109        0.121        0.157        0.139        0.363      0.00378\n","     10     2       0.0304       0.0304     1.03e-05        0.105        0.135       0.0934        0.128        0.111         0.12         0.16         0.14        0.198      0.00206\n","     10     3        0.031       0.0309     4.88e-05        0.103        0.136       0.0902        0.128        0.109        0.119        0.164        0.142        0.407      0.00424\n","     10     4       0.0312       0.0312     2.95e-05        0.105        0.137       0.0921         0.13        0.111        0.121        0.164        0.142        0.384        0.004\n","     10     5       0.0289       0.0288     9.89e-05        0.103        0.131       0.0908        0.129         0.11        0.116        0.157        0.137         0.63      0.00656\n","     10     6       0.0283       0.0282      9.6e-05          0.1         0.13       0.0909        0.119        0.105        0.117        0.152        0.135        0.631      0.00658\n","     10     7       0.0253       0.0253     3.68e-05       0.0951        0.123       0.0854        0.114          0.1         0.11        0.146        0.128        0.421      0.00439\n","     10     8       0.0292       0.0291     4.73e-05        0.101        0.132       0.0851        0.133        0.109        0.108         0.17        0.139        0.343      0.00357\n","     10     9       0.0262       0.0262     2.26e-05       0.0957        0.125       0.0837         0.12        0.102        0.108        0.153        0.131        0.301      0.00314\n","     10    10         0.03       0.0299     3.48e-05        0.102        0.134       0.0901        0.127        0.108        0.119         0.16        0.139         0.34      0.00354\n","     10    11       0.0286       0.0286     1.86e-05       0.0996        0.131       0.0865        0.126        0.106        0.113         0.16        0.137        0.278      0.00289\n","     10    12       0.0253       0.0252     5.16e-05       0.0949        0.123       0.0827        0.119        0.101        0.106        0.151        0.129        0.446      0.00465\n","     10    13       0.0269       0.0268     4.83e-05       0.0987        0.127       0.0876        0.121        0.104        0.112        0.152        0.132        0.454      0.00473\n","     10    14       0.0289       0.0289     2.59e-05        0.102        0.132       0.0883        0.129        0.109        0.113        0.162        0.138        0.333      0.00347\n","     10    15       0.0252       0.0252      3.5e-05       0.0962        0.123       0.0825        0.124        0.103        0.104        0.153        0.129        0.419      0.00437\n","     10    16       0.0325       0.0325      2.9e-05        0.107        0.139       0.0927        0.135        0.114        0.122        0.169        0.146        0.329      0.00343\n","     10    17        0.024       0.0239     5.44e-05       0.0931         0.12       0.0815        0.116       0.0989        0.103        0.148        0.125        0.464      0.00484\n","     10    18       0.0242       0.0241     0.000154       0.0951         0.12       0.0874        0.111        0.099        0.111        0.136        0.124        0.876      0.00912\n","     10    19       0.0262       0.0259     0.000314       0.0955        0.124       0.0859        0.115          0.1         0.11         0.15         0.13         1.16       0.0121\n","     10    20       0.0261        0.026     0.000104       0.0953        0.125       0.0842        0.118        0.101        0.109        0.151         0.13        0.732      0.00762\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     10     1       0.0324       0.0323     3.73e-05        0.107        0.139       0.0934        0.133        0.113        0.121         0.17        0.145        0.388      0.00405\n","     10     2       0.0309       0.0309     1.49e-05        0.105        0.136       0.0928        0.131        0.112         0.12        0.163        0.142        0.223      0.00232\n","     10     3       0.0268       0.0268     1.78e-05       0.0985        0.127       0.0873        0.121        0.104        0.112        0.152        0.132        0.253      0.00264\n","     10     4       0.0283       0.0283     5.04e-05          0.1         0.13       0.0875        0.125        0.106        0.114        0.158        0.136        0.442      0.00461\n","     10     5       0.0279       0.0279     4.26e-05       0.0995        0.129       0.0868        0.125        0.106        0.113        0.156        0.135        0.411      0.00428\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              10   35.673    0.005       0.0279     6.44e-05       0.0279       0.0995        0.129       0.0876        0.123        0.105        0.113        0.156        0.135        0.476      0.00496\n","! Validation         10   35.673    0.005       0.0292     3.26e-05       0.0293        0.102        0.132       0.0896        0.127        0.108        0.116         0.16        0.138        0.343      0.00358\n","Wall time: 35.67391571799999\n","! Best model       10    0.029\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     11     1       0.0269       0.0267     0.000163       0.0955        0.126       0.0819        0.123        0.102        0.107        0.159        0.133         0.87      0.00906\n","     11     2       0.0264       0.0262     0.000152       0.0976        0.125       0.0851        0.123        0.104        0.108        0.154        0.131        0.857      0.00893\n","     11     3       0.0247       0.0247     3.62e-05       0.0941        0.121       0.0823        0.118          0.1        0.106        0.148        0.127        0.372      0.00387\n","     11     4       0.0265       0.0264      6.2e-05       0.0974        0.126       0.0875        0.117        0.102        0.113        0.148        0.131        0.448      0.00467\n","     11     5       0.0234       0.0234     2.56e-05       0.0917        0.118       0.0812        0.113        0.097        0.105        0.142        0.123        0.302      0.00314\n","     11     6       0.0257       0.0256     6.21e-05       0.0959        0.124        0.083        0.122        0.102        0.107        0.152        0.129         0.48      0.00499\n","     11     7       0.0253       0.0253     1.45e-05       0.0958        0.123       0.0847        0.118        0.101        0.109        0.147        0.128        0.258      0.00268\n","     11     8        0.022        0.022     4.45e-05       0.0869        0.115       0.0766        0.108       0.0921          0.1        0.139         0.12        0.375      0.00391\n","     11     9       0.0241       0.0238     0.000277       0.0919        0.119       0.0799        0.116       0.0979        0.103        0.147        0.125         1.21       0.0126\n","     11    10       0.0252       0.0248     0.000366       0.0933        0.122       0.0813        0.117       0.0993        0.106        0.148        0.127         1.29       0.0134\n","     11    11       0.0231        0.023     0.000127       0.0919        0.117       0.0819        0.112       0.0968        0.105        0.139        0.122         0.74      0.00771\n","     11    12       0.0223       0.0223     4.55e-05       0.0896        0.115       0.0776        0.114       0.0956       0.0992        0.142        0.121        0.421      0.00438\n","     11    13       0.0254       0.0249     0.000522       0.0955        0.122       0.0838        0.119        0.101        0.108        0.147        0.127         1.68       0.0175\n","     11    14       0.0276       0.0276     2.69e-05        0.098        0.128       0.0847        0.125        0.105        0.112        0.157        0.134        0.273      0.00284\n","     11    15        0.023        0.023     1.28e-05       0.0896        0.117       0.0805        0.108       0.0941        0.105        0.139        0.122        0.243      0.00254\n","     11    16       0.0275       0.0275     4.65e-05       0.0966        0.128       0.0848         0.12        0.103        0.112        0.155        0.134         0.41      0.00427\n","     11    17        0.028       0.0279     4.16e-05       0.0974        0.129       0.0858        0.121        0.103        0.114        0.156        0.135        0.464      0.00483\n","     11    18       0.0268       0.0268     3.73e-05       0.0968        0.127       0.0833        0.124        0.104        0.109        0.156        0.132        0.401      0.00418\n","     11    19       0.0235       0.0234     0.000102       0.0913        0.118        0.079        0.116       0.0975        0.101        0.147        0.124        0.621      0.00647\n","     11    20        0.021        0.021     2.06e-05       0.0866        0.112       0.0744        0.111       0.0926       0.0963        0.138        0.117        0.297      0.00309\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     11     1       0.0292       0.0291     3.52e-05        0.101        0.132       0.0883        0.127        0.108        0.115        0.162        0.138        0.338      0.00352\n","     11     2       0.0278       0.0278     1.84e-05       0.0996        0.129       0.0871        0.125        0.106        0.113        0.156        0.135        0.244      0.00254\n","     11     3       0.0242       0.0242     2.13e-05       0.0934         0.12       0.0822        0.116       0.0991        0.105        0.146        0.126        0.291      0.00303\n","     11     4       0.0255       0.0255      5.2e-05        0.095        0.123       0.0828        0.119        0.101        0.108         0.15        0.129        0.469      0.00489\n","     11     5       0.0253       0.0253     4.51e-05       0.0949        0.123       0.0824         0.12        0.101        0.107         0.15        0.128        0.405      0.00422\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              11   38.766    0.005       0.0248     0.000109       0.0249       0.0937        0.122        0.082        0.117       0.0995        0.106        0.148        0.127          0.6      0.00625\n","! Validation         11   38.766    0.005       0.0264     3.44e-05       0.0264       0.0968        0.126       0.0845        0.121        0.103         0.11        0.153        0.131        0.349      0.00364\n","Wall time: 38.76694273500016\n","! Best model       11    0.026\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     12     1       0.0248       0.0245     0.000321       0.0949        0.121       0.0812        0.122        0.102        0.103        0.151        0.127         1.25        0.013\n","     12     2       0.0353       0.0344     0.000921        0.113        0.143        0.104        0.131        0.117        0.132        0.164        0.148         2.23       0.0233\n","     12     3       0.0293       0.0293     3.82e-05        0.103        0.132        0.092        0.124        0.108        0.119        0.156        0.137        0.402      0.00419\n","     12     4       0.0201         0.02     0.000127        0.085        0.109       0.0749        0.105       0.0901       0.0951        0.133        0.114        0.763      0.00795\n","     12     5       0.0289       0.0286     0.000296          0.1        0.131       0.0865        0.128        0.107        0.111        0.163        0.137         1.27       0.0133\n","     12     6        0.035       0.0347     0.000324        0.113        0.144        0.106        0.127        0.116        0.134        0.163        0.148         1.32       0.0137\n","     12     7         0.03       0.0299     9.37e-05        0.105        0.134       0.0946        0.125         0.11         0.12        0.158        0.139        0.696      0.00725\n","     12     8       0.0224       0.0221     0.000296       0.0894        0.115        0.078        0.112       0.0951       0.0993        0.141         0.12          1.2       0.0125\n","     12     9       0.0337       0.0336     2.58e-05        0.112        0.142        0.106        0.123        0.114        0.135        0.155        0.145        0.289      0.00301\n","     12    10       0.0284       0.0283     6.72e-05        0.101         0.13       0.0865         0.13        0.108         0.11        0.163        0.137        0.565      0.00588\n","     12    11       0.0209       0.0206      0.00025       0.0855        0.111       0.0748        0.107       0.0909       0.0956        0.137        0.116         1.14       0.0119\n","     12    12       0.0282       0.0282     2.18e-05        0.102         0.13       0.0886        0.129        0.109        0.113        0.159        0.136        0.248      0.00258\n","     12    13       0.0275       0.0272     0.000339       0.0966        0.128       0.0823        0.125        0.104        0.107        0.161        0.134         1.36       0.0142\n","     12    14       0.0214       0.0212     0.000195       0.0855        0.113       0.0752        0.106       0.0907       0.0989        0.136        0.118        0.918      0.00956\n","     12    15        0.022        0.022     3.64e-05       0.0891        0.115       0.0771        0.113       0.0951       0.0996         0.14         0.12        0.331      0.00345\n","     12    16       0.0208       0.0207     2.96e-05       0.0868        0.111       0.0789        0.103       0.0907        0.101        0.129        0.115        0.347      0.00361\n","     12    17       0.0227       0.0226     5.01e-05       0.0895        0.116       0.0777        0.113       0.0954          0.1        0.143        0.122        0.456      0.00475\n","     12    18       0.0251        0.025     0.000161       0.0931        0.122       0.0818        0.116       0.0987        0.109        0.145        0.127        0.861      0.00897\n","     12    19       0.0213       0.0213     1.25e-05       0.0872        0.113       0.0753        0.111       0.0932       0.0975        0.139        0.118         0.24       0.0025\n","     12    20       0.0242       0.0241     8.54e-05       0.0914         0.12       0.0806        0.113       0.0969        0.106        0.144        0.125        0.545      0.00568\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     12     1       0.0266       0.0266     3.43e-05       0.0963        0.126       0.0836        0.122        0.103        0.109        0.155        0.132        0.331      0.00345\n","     12     2       0.0254       0.0254        2e-05       0.0947        0.123       0.0821         0.12        0.101        0.107        0.151        0.129         0.26      0.00271\n","     12     3       0.0222       0.0221      2.3e-05       0.0891        0.115       0.0777        0.112       0.0948       0.0997        0.141         0.12        0.308      0.00321\n","     12     4       0.0234       0.0233     5.15e-05       0.0907        0.118       0.0788        0.115       0.0967        0.103        0.144        0.123        0.472      0.00491\n","     12     5       0.0232       0.0231     4.56e-05       0.0907        0.118       0.0783        0.116        0.097        0.102        0.145        0.123        0.403       0.0042\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              12   41.873    0.005       0.0259     0.000185       0.0261       0.0961        0.125       0.0851        0.118        0.102         0.11        0.149         0.13        0.822      0.00856\n","! Validation         12   41.873    0.005       0.0241     3.49e-05       0.0241       0.0923         0.12       0.0801        0.117       0.0984        0.104        0.147        0.126        0.355       0.0037\n","Wall time: 41.87422916300011\n","! Best model       12    0.024\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     13     1       0.0241       0.0241      1.8e-05       0.0921         0.12       0.0793        0.118       0.0986        0.104        0.147        0.126        0.225      0.00235\n","     13     2       0.0207       0.0207     5.33e-05       0.0868        0.111       0.0746        0.111       0.0929       0.0962        0.136        0.116        0.522      0.00544\n","     13     3       0.0243       0.0242     7.22e-05        0.092         0.12       0.0777        0.121       0.0992        0.102         0.15        0.126        0.595       0.0062\n","     13     4       0.0198       0.0196     0.000177       0.0847        0.108       0.0742        0.106       0.0899       0.0939        0.132        0.113        0.907      0.00945\n","     13     5       0.0205       0.0205     8.03e-05       0.0859        0.111       0.0741        0.109       0.0918       0.0943        0.138        0.116        0.576        0.006\n","     13     6       0.0278       0.0271      0.00064          0.1        0.127       0.0918        0.117        0.104        0.117        0.147        0.132         1.86       0.0194\n","     13     7       0.0228       0.0226     0.000254       0.0914        0.116       0.0785        0.117       0.0979       0.0992        0.144        0.122          1.1       0.0115\n","     13     8       0.0209       0.0208     9.35e-05       0.0851        0.111        0.075        0.105       0.0902       0.0983        0.134        0.116        0.599      0.00624\n","     13     9       0.0251        0.025     0.000109       0.0942        0.122       0.0808        0.121        0.101        0.105        0.151        0.128        0.733      0.00764\n","     13    10       0.0208       0.0205      0.00035       0.0842        0.111       0.0754        0.102       0.0886       0.0986        0.132        0.115         1.36       0.0142\n","     13    11       0.0243       0.0243     6.03e-05       0.0933        0.121       0.0807        0.119       0.0996        0.104        0.148        0.126        0.499       0.0052\n","     13    12       0.0257       0.0253     0.000398       0.0958        0.123       0.0854        0.117        0.101         0.11        0.146        0.128         1.45       0.0151\n","     13    13       0.0197       0.0196     5.55e-05       0.0833        0.108       0.0721        0.106       0.0889       0.0928        0.134        0.114        0.417      0.00434\n","     13    14       0.0255       0.0255      9.9e-06       0.0936        0.123       0.0807        0.119          0.1        0.109        0.149        0.129        0.216      0.00225\n","     13    15       0.0225       0.0224     6.58e-05       0.0883        0.116       0.0773         0.11       0.0938       0.0999        0.142        0.121        0.401      0.00418\n","     13    16       0.0183       0.0182     0.000151       0.0806        0.104        0.069        0.104       0.0865       0.0885         0.13        0.109        0.866      0.00902\n","     13    17       0.0225       0.0225     1.15e-05       0.0885        0.116       0.0758        0.114       0.0948       0.0999        0.143        0.122        0.213      0.00222\n","     13    18        0.022       0.0219     0.000127       0.0867        0.114       0.0769        0.106       0.0916       0.0996        0.139        0.119        0.696      0.00725\n","     13    19       0.0206       0.0205     7.97e-05       0.0856        0.111       0.0743        0.108       0.0913        0.095        0.137        0.116        0.624       0.0065\n","     13    20       0.0247       0.0247     1.02e-05       0.0946        0.121       0.0845        0.115       0.0997        0.109        0.143        0.126        0.164       0.0017\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     13     1       0.0245       0.0244     3.47e-05       0.0923        0.121       0.0798        0.117       0.0986        0.104         0.15        0.127        0.326       0.0034\n","     13     2       0.0236       0.0236      2.2e-05       0.0908        0.119       0.0781        0.116       0.0971        0.102        0.146        0.124        0.276      0.00287\n","     13     3       0.0205       0.0205     2.51e-05       0.0855        0.111       0.0739        0.109       0.0913       0.0951        0.137        0.116        0.325      0.00338\n","     13     4       0.0216       0.0216     5.29e-05       0.0872        0.114       0.0755         0.11        0.093       0.0987        0.139        0.119        0.479      0.00499\n","     13     5       0.0214       0.0214     4.74e-05       0.0872        0.113       0.0747        0.112       0.0934       0.0967         0.14        0.118        0.414      0.00431\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              13   44.978    0.005       0.0225     0.000141       0.0226       0.0893        0.116       0.0779        0.112       0.0951        0.101        0.141        0.121        0.701      0.00731\n","! Validation         13   44.978    0.005       0.0223     3.64e-05       0.0223       0.0886        0.115       0.0764        0.113       0.0947       0.0993        0.142        0.121        0.364      0.00379\n","Wall time: 44.978665666000325\n","! Best model       13    0.022\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     14     1       0.0212        0.021     0.000206       0.0859        0.112       0.0743        0.109       0.0917       0.0952         0.14        0.117            1       0.0105\n","     14     2         0.02       0.0195     0.000489       0.0842        0.108       0.0742        0.104       0.0891       0.0942        0.131        0.113         1.57       0.0164\n","     14     3       0.0196       0.0195     8.67e-05       0.0839        0.108       0.0729        0.106       0.0895       0.0921        0.135        0.113        0.555      0.00579\n","     14     4        0.024       0.0238     0.000245       0.0923        0.119       0.0802        0.117       0.0984        0.104        0.146        0.125          1.1       0.0115\n","     14     5       0.0235       0.0226     0.000873       0.0906        0.116        0.077        0.118       0.0974        0.099        0.145        0.122         2.17       0.0227\n","     14     6       0.0216       0.0214     0.000177       0.0892        0.113       0.0818        0.104       0.0929        0.103        0.131        0.117          0.9      0.00937\n","     14     7       0.0188       0.0188     4.71e-05       0.0819        0.106       0.0696        0.107        0.088       0.0895        0.133        0.111         0.45      0.00469\n","     14     8       0.0239       0.0236     0.000213       0.0919        0.119       0.0835        0.109       0.0962        0.108        0.139        0.123         1.06        0.011\n","     14     9       0.0256       0.0253     0.000297       0.0938        0.123       0.0789        0.123        0.101          0.1        0.159         0.13         1.26       0.0131\n","     14    10       0.0194       0.0194     3.82e-05       0.0805        0.108       0.0691        0.103       0.0863       0.0937        0.131        0.113         0.43      0.00448\n","     14    11       0.0197       0.0197     1.28e-05       0.0835        0.108       0.0706        0.109         0.09       0.0904        0.138        0.114        0.219      0.00228\n","     14    12       0.0177       0.0177     3.91e-05         0.08        0.103       0.0701       0.0997       0.0849       0.0904        0.124        0.107        0.428      0.00446\n","     14    13       0.0167       0.0167     1.63e-05       0.0756       0.0999       0.0643       0.0983       0.0813       0.0855        0.124        0.105        0.239      0.00249\n","     14    14       0.0241        0.024     6.23e-05       0.0909         0.12       0.0781        0.117       0.0973        0.103        0.148        0.125        0.553      0.00576\n","     14    15       0.0205       0.0204     6.58e-05       0.0842         0.11       0.0727        0.107         0.09       0.0946        0.137        0.116        0.522      0.00544\n","     14    16        0.018        0.018     1.95e-05       0.0798        0.104       0.0696          0.1       0.0849       0.0909        0.126        0.108        0.261      0.00271\n","     14    17       0.0226       0.0226     1.63e-05       0.0896        0.116       0.0766        0.115        0.096       0.0988        0.145        0.122        0.224      0.00233\n","     14    18       0.0196       0.0196     1.86e-05       0.0835        0.108       0.0728        0.105       0.0889       0.0937        0.133        0.113        0.255      0.00265\n","     14    19       0.0203       0.0202     9.21e-05       0.0836         0.11       0.0728        0.105        0.089       0.0949        0.135        0.115        0.603      0.00628\n","     14    20       0.0187       0.0187     3.81e-05       0.0832        0.106        0.074        0.102       0.0878       0.0935        0.127         0.11        0.423       0.0044\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     14     1       0.0228       0.0228     3.48e-05        0.089        0.117       0.0765        0.114       0.0952       0.0993        0.146        0.122        0.335      0.00349\n","     14     2        0.022        0.022     2.19e-05       0.0876        0.115       0.0748        0.113        0.094       0.0982        0.142         0.12        0.281      0.00293\n","     14     3       0.0191       0.0191     2.45e-05       0.0826        0.107       0.0708        0.106       0.0884       0.0912        0.133        0.112        0.318      0.00331\n","     14     4       0.0202       0.0202     5.18e-05       0.0841         0.11       0.0726        0.107       0.0898       0.0949        0.135        0.115        0.474      0.00494\n","     14     5         0.02         0.02     4.64e-05       0.0842        0.109       0.0717        0.109       0.0904       0.0925        0.137        0.115        0.409      0.00426\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              14   48.100    0.005       0.0206     0.000153       0.0208       0.0854        0.111       0.0742        0.108        0.091       0.0959        0.137        0.116        0.712      0.00741\n","! Validation         14   48.100    0.005       0.0208     3.59e-05       0.0208       0.0855        0.112       0.0733         0.11       0.0916       0.0953        0.139        0.117        0.363      0.00379\n","Wall time: 48.10056006600007\n","! Best model       14    0.021\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     15     1       0.0194       0.0193     4.75e-05       0.0819        0.108       0.0699        0.106       0.0879        0.092        0.133        0.113        0.442       0.0046\n","     15     2       0.0179       0.0178     7.34e-05       0.0793        0.103       0.0688          0.1       0.0845       0.0898        0.126        0.108        0.431      0.00449\n","     15     3       0.0173       0.0172     4.41e-05       0.0783        0.101       0.0661        0.103       0.0844       0.0845        0.129        0.107        0.422       0.0044\n","     15     4         0.02       0.0199     3.41e-05        0.084        0.109       0.0731        0.106       0.0894       0.0941        0.134        0.114        0.346       0.0036\n","     15     5       0.0194       0.0194      6.2e-05       0.0826        0.108       0.0703        0.107       0.0888       0.0911        0.135        0.113        0.477      0.00497\n","     15     6       0.0164       0.0164     4.74e-05       0.0773        0.099       0.0669       0.0982       0.0826       0.0849        0.122        0.104        0.463      0.00483\n","     15     7       0.0194       0.0193     5.96e-05       0.0815        0.108       0.0699        0.105       0.0872       0.0913        0.134        0.113        0.517      0.00539\n","     15     8       0.0196       0.0195     0.000104       0.0834        0.108       0.0715        0.107       0.0894       0.0916        0.135        0.113        0.667      0.00695\n","     15     9       0.0189       0.0189     9.55e-06       0.0822        0.106       0.0716        0.103       0.0874       0.0933        0.128        0.111        0.209      0.00217\n","     15    10       0.0186       0.0183     0.000334       0.0796        0.105       0.0693          0.1       0.0848       0.0904        0.128        0.109         1.31       0.0136\n","     15    11       0.0197       0.0197     3.98e-05       0.0846        0.109       0.0725        0.109       0.0906       0.0921        0.136        0.114        0.366      0.00381\n","     15    12       0.0208       0.0208     5.16e-05       0.0848        0.112       0.0732        0.108       0.0907       0.0959        0.138        0.117        0.474      0.00493\n","     15    13       0.0224       0.0221     0.000251       0.0875        0.115       0.0767        0.109       0.0929       0.0998        0.141         0.12         1.16       0.0121\n","     15    14       0.0178       0.0176     0.000194       0.0785        0.103       0.0672        0.101       0.0842       0.0863        0.129        0.108         1.01       0.0105\n","     15    15       0.0207       0.0206     3.25e-05       0.0846        0.111       0.0718         0.11       0.0909       0.0954        0.137        0.116        0.388      0.00404\n","     15    16        0.019       0.0189     6.59e-05       0.0842        0.106       0.0747        0.103        0.089       0.0934        0.129        0.111        0.515      0.00537\n","     15    17       0.0161        0.016     8.74e-05       0.0758        0.098       0.0635          0.1       0.0819       0.0817        0.124        0.103         0.68      0.00709\n","     15    18       0.0221        0.022     8.67e-05       0.0864        0.115       0.0734        0.112       0.0929       0.0975        0.143         0.12        0.669      0.00697\n","     15    19       0.0176       0.0175     7.59e-05       0.0796        0.102         0.07       0.0988       0.0844       0.0893        0.124        0.107         0.61      0.00635\n","     15    20       0.0198       0.0197     9.75e-05       0.0812        0.108       0.0668         0.11       0.0884       0.0879        0.141        0.114        0.671      0.00699\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     15     1       0.0214       0.0213      3.5e-05       0.0861        0.113       0.0736        0.111       0.0923       0.0955        0.142        0.119        0.333      0.00347\n","     15     2       0.0208       0.0207     2.33e-05       0.0847        0.111       0.0718         0.11       0.0911       0.0946        0.139        0.117         0.29      0.00302\n","     15     3        0.018        0.018     2.58e-05       0.0799        0.104       0.0681        0.104       0.0859       0.0877         0.13        0.109        0.327       0.0034\n","     15     4       0.0191        0.019     5.29e-05       0.0815        0.107       0.0701        0.104       0.0872       0.0917        0.132        0.112        0.479      0.00499\n","     15     5       0.0188       0.0188     4.76e-05       0.0816        0.106        0.069        0.107       0.0878       0.0889        0.134        0.111        0.415      0.00432\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              15   51.199    0.005       0.0191     8.99e-05       0.0191       0.0819        0.107       0.0704        0.105       0.0876       0.0912        0.133        0.112        0.591      0.00616\n","! Validation         15   51.199    0.005       0.0196     3.69e-05       0.0196       0.0827        0.108       0.0705        0.107       0.0889       0.0917        0.135        0.113        0.369      0.00384\n","Wall time: 51.19944459300041\n","! Best model       15    0.020\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     16     1       0.0181       0.0181     2.12e-05       0.0819        0.104       0.0727          0.1       0.0866       0.0921        0.124        0.108        0.286      0.00298\n","     16     2       0.0205       0.0204     0.000119       0.0845         0.11       0.0712        0.111       0.0911       0.0924         0.14        0.116        0.801      0.00835\n","     16     3       0.0211       0.0211     3.51e-05        0.085        0.112       0.0704        0.114       0.0923       0.0934        0.143        0.118        0.397      0.00413\n","     16     4       0.0181        0.018     0.000126       0.0803        0.104       0.0676        0.106       0.0866        0.086        0.133        0.109        0.726      0.00757\n","     16     5       0.0179       0.0177     0.000168       0.0788        0.103       0.0681          0.1       0.0841       0.0875        0.128        0.108        0.894      0.00931\n","     16     6       0.0177       0.0177     6.05e-05       0.0791        0.103        0.068        0.101       0.0847       0.0873        0.128        0.108        0.508      0.00529\n","     16     7       0.0176       0.0174     0.000205       0.0788        0.102       0.0691       0.0982       0.0837       0.0898        0.123        0.106            1       0.0104\n","     16     8       0.0203       0.0202     7.41e-05       0.0849         0.11       0.0732        0.108       0.0908       0.0933        0.137        0.115        0.505      0.00527\n","     16     9       0.0221       0.0221     1.04e-05       0.0868        0.115       0.0749        0.111       0.0927       0.0997        0.141         0.12        0.225      0.00234\n","     16    10       0.0178       0.0177     5.45e-05       0.0782        0.103       0.0665        0.101        0.084       0.0879        0.128        0.108         0.42      0.00437\n","     16    11        0.023        0.023     3.16e-05       0.0894        0.117       0.0753        0.118       0.0965       0.0972         0.15        0.123        0.342      0.00357\n","     16    12       0.0185       0.0183     0.000107       0.0808        0.105       0.0725       0.0976        0.085       0.0932        0.125        0.109        0.712      0.00742\n","     16    13       0.0175       0.0175     4.91e-05       0.0775        0.102       0.0654        0.102       0.0836       0.0865        0.128        0.107        0.364      0.00379\n","     16    14       0.0175       0.0175     1.84e-05       0.0769        0.102       0.0653          0.1       0.0827       0.0859        0.129        0.107        0.255      0.00265\n","     16    15        0.016       0.0159     1.47e-05       0.0753       0.0977       0.0639       0.0981        0.081       0.0834        0.121        0.102        0.247      0.00257\n","     16    16       0.0172       0.0172     5.76e-05       0.0789        0.101       0.0685       0.0996       0.0841       0.0878        0.124        0.106        0.405      0.00421\n","     16    17       0.0175       0.0174     8.81e-05       0.0781        0.102       0.0643        0.106        0.085       0.0832        0.132        0.108        0.665      0.00692\n","     16    18       0.0159       0.0159      3.4e-05       0.0747       0.0976       0.0628       0.0985       0.0807       0.0818        0.123        0.103        0.392      0.00408\n","     16    19       0.0147       0.0147     2.62e-05       0.0731       0.0937       0.0632       0.0928        0.078       0.0791        0.118       0.0984        0.285      0.00297\n","     16    20       0.0172       0.0172     1.76e-05       0.0778        0.101       0.0669       0.0995       0.0832       0.0865        0.126        0.106        0.271      0.00282\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     16     1       0.0202       0.0202     3.54e-05       0.0836         0.11       0.0711        0.109       0.0899       0.0924        0.138        0.115        0.356      0.00371\n","     16     2       0.0196       0.0196     2.16e-05       0.0821        0.108       0.0691        0.108       0.0886       0.0913        0.136        0.114        0.284      0.00296\n","     16     3        0.017        0.017     2.28e-05       0.0776        0.101       0.0658        0.101       0.0836       0.0848        0.127        0.106        0.301      0.00314\n","     16     4       0.0181        0.018     4.95e-05       0.0793        0.104        0.068        0.102       0.0849       0.0888        0.129        0.109        0.461       0.0048\n","     16     5       0.0178       0.0178     4.39e-05       0.0791        0.103       0.0665        0.104       0.0854       0.0858        0.131        0.108        0.396      0.00413\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              16   54.281    0.005       0.0182     6.59e-05       0.0183         0.08        0.104       0.0685        0.103       0.0858       0.0888         0.13         0.11        0.485      0.00505\n","! Validation         16   54.281    0.005       0.0185     3.47e-05       0.0185       0.0803        0.105       0.0681        0.105       0.0865       0.0887        0.132         0.11         0.36      0.00375\n","Wall time: 54.28171310400012\n","! Best model       16    0.019\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     17     1        0.016       0.0159     0.000103       0.0749       0.0974       0.0628       0.0991        0.081       0.0809        0.124        0.102        0.702      0.00732\n","     17     2       0.0149       0.0149     2.42e-05       0.0729       0.0943       0.0621       0.0944       0.0783       0.0791        0.119        0.099        0.302      0.00314\n","     17     3       0.0163       0.0161     0.000158       0.0761       0.0982       0.0651       0.0982       0.0817       0.0827        0.124        0.103        0.851      0.00887\n","     17     4       0.0184       0.0184     7.04e-05       0.0791        0.105       0.0677        0.102       0.0848       0.0897         0.13         0.11        0.533      0.00555\n","     17     5       0.0162       0.0161     0.000128       0.0747        0.098       0.0647       0.0945       0.0796       0.0849         0.12        0.102        0.779      0.00811\n","     17     6       0.0157       0.0157     3.27e-05        0.074       0.0968       0.0625       0.0969       0.0797       0.0804        0.123        0.102        0.373      0.00388\n","     17     7       0.0165        0.016     0.000585       0.0751       0.0977       0.0624        0.101       0.0815       0.0807        0.125        0.103         1.71       0.0178\n","     17     8       0.0192       0.0191     0.000105       0.0801        0.107       0.0662        0.108       0.0871       0.0883        0.137        0.113        0.733      0.00764\n","     17     9        0.015       0.0148     0.000146       0.0717       0.0942       0.0598       0.0957       0.0777       0.0791        0.119       0.0989        0.841      0.00876\n","     17    10       0.0158       0.0151     0.000686       0.0735       0.0951       0.0622       0.0961       0.0791       0.0798         0.12       0.0999          1.9       0.0198\n","     17    11       0.0176       0.0175     7.55e-05       0.0769        0.102       0.0637        0.103       0.0835        0.084        0.132        0.108        0.598      0.00623\n","     17    12       0.0162       0.0161     9.14e-05       0.0762       0.0981       0.0644       0.0997        0.082       0.0819        0.124        0.103        0.631      0.00657\n","     17    13       0.0177       0.0168      0.00089       0.0756          0.1        0.065       0.0969        0.081       0.0863        0.123        0.105         2.19       0.0228\n","     17    14       0.0155       0.0153     0.000175       0.0742       0.0957       0.0631       0.0962       0.0797       0.0792        0.122        0.101        0.874       0.0091\n","     17    15       0.0171       0.0168     0.000394       0.0758          0.1       0.0648       0.0978       0.0813        0.085        0.125        0.105         1.46       0.0152\n","     17    16       0.0163       0.0152      0.00111       0.0737       0.0953       0.0603          0.1       0.0803       0.0759        0.125        0.101         2.46       0.0256\n","     17    17       0.0164       0.0163     4.82e-05       0.0758       0.0989       0.0646       0.0981       0.0814       0.0833        0.124        0.104        0.466      0.00486\n","     17    18       0.0171       0.0164     0.000734       0.0756       0.0991       0.0643       0.0982       0.0812       0.0845        0.123        0.104         1.97       0.0206\n","     17    19       0.0191       0.0182     0.000976       0.0788        0.104        0.065        0.106       0.0857       0.0874        0.132         0.11         2.31        0.024\n","     17    20       0.0156       0.0155     6.58e-05       0.0741       0.0964       0.0633       0.0958       0.0795       0.0814        0.121        0.101        0.562      0.00586\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     17     1       0.0191       0.0191     3.58e-05       0.0813        0.107       0.0687        0.106       0.0875       0.0895        0.135        0.112        0.352      0.00366\n","     17     2       0.0185       0.0185      2.3e-05       0.0797        0.105       0.0668        0.106       0.0862       0.0882        0.133        0.111        0.291      0.00303\n","     17     3       0.0161       0.0161     2.51e-05       0.0754       0.0982       0.0635       0.0993       0.0814        0.082        0.124        0.103        0.318      0.00331\n","     17     4       0.0172       0.0171     5.19e-05       0.0772        0.101        0.066       0.0996       0.0828       0.0861        0.126        0.106        0.472      0.00491\n","     17     5       0.0169       0.0169      4.6e-05       0.0769          0.1       0.0643        0.102       0.0832       0.0831        0.128        0.106        0.407      0.00424\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              17   57.369    0.005       0.0163      0.00033       0.0166       0.0754       0.0988       0.0637       0.0989       0.0813       0.0828        0.125        0.104         1.11       0.0116\n","! Validation         17   57.369    0.005       0.0176     3.64e-05       0.0176       0.0781        0.102       0.0659        0.103       0.0842       0.0858         0.13        0.108        0.368      0.00383\n","Wall time: 57.37019439900041\n","! Best model       17    0.018\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     18     1       0.0172       0.0169     0.000264       0.0754        0.101       0.0652       0.0957       0.0805       0.0864        0.124        0.105         1.13       0.0118\n","     18     2       0.0153       0.0149     0.000446       0.0731       0.0943       0.0616       0.0959       0.0788       0.0774        0.121       0.0994         1.51       0.0157\n","     18     3       0.0188       0.0188     9.38e-06       0.0807        0.106        0.067        0.108       0.0875       0.0881        0.135        0.112         0.19      0.00198\n","     18     4        0.017       0.0168     0.000192       0.0766          0.1       0.0635        0.103       0.0832       0.0817        0.129        0.106        0.961         0.01\n","     18     5       0.0157       0.0156     9.13e-05       0.0726       0.0966       0.0602       0.0975       0.0788       0.0806        0.123        0.102        0.683      0.00712\n","     18     6       0.0152       0.0152     2.07e-05        0.072       0.0954       0.0609       0.0941       0.0775       0.0803         0.12          0.1          0.3      0.00313\n","     18     7       0.0164       0.0163     8.66e-05       0.0753       0.0988       0.0628          0.1       0.0816       0.0818        0.126        0.104        0.564      0.00588\n","     18     8        0.017        0.017     6.62e-06       0.0787        0.101       0.0685       0.0991       0.0838       0.0868        0.124        0.106         0.17      0.00177\n","     18     9        0.016        0.016     5.24e-05       0.0761       0.0978       0.0663       0.0959       0.0811        0.084        0.121        0.102        0.486      0.00507\n","     18    10       0.0168       0.0168     1.44e-05        0.077          0.1        0.066       0.0992       0.0826        0.086        0.124        0.105        0.223      0.00233\n","     18    11       0.0148       0.0147     2.83e-05       0.0731       0.0939       0.0639       0.0917       0.0778       0.0809        0.116       0.0982        0.296      0.00308\n","     18    12       0.0148       0.0147     5.42e-05       0.0726        0.094       0.0613       0.0953       0.0783       0.0771        0.121        0.099        0.451      0.00469\n","     18    13       0.0161        0.016     0.000139       0.0762       0.0978        0.066       0.0966       0.0813       0.0855        0.119        0.102        0.738      0.00768\n","     18    14       0.0172       0.0171     4.55e-05       0.0789        0.101       0.0689        0.099        0.084       0.0865        0.126        0.106        0.441       0.0046\n","     18    15       0.0184       0.0184     3.36e-05       0.0807        0.105       0.0679        0.106       0.0872       0.0862        0.135         0.11        0.354      0.00369\n","     18    16       0.0159       0.0158     0.000158       0.0759       0.0972        0.067       0.0938       0.0804       0.0848        0.118        0.101        0.851      0.00887\n","     18    17       0.0143       0.0142     6.68e-05       0.0699       0.0922       0.0585       0.0928       0.0756       0.0758        0.118       0.0971        0.502      0.00523\n","     18    18       0.0147       0.0146     8.73e-05       0.0709       0.0935       0.0613         0.09       0.0757       0.0801        0.116       0.0979        0.673      0.00701\n","     18    19       0.0188       0.0187     9.63e-06       0.0818        0.106       0.0688        0.108       0.0883       0.0878        0.135        0.111        0.205      0.00213\n","     18    20       0.0188       0.0187     4.15e-05       0.0819        0.106        0.072        0.102       0.0869       0.0931        0.128         0.11         0.45      0.00469\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     18     1       0.0182       0.0181     3.62e-05        0.079        0.104       0.0665        0.104       0.0853       0.0867        0.132         0.11        0.347      0.00362\n","     18     2       0.0176       0.0176     2.41e-05       0.0776        0.103       0.0647        0.103        0.084       0.0855         0.13        0.108        0.295      0.00308\n","     18     3       0.0153       0.0153     2.74e-05       0.0734       0.0958       0.0614       0.0973       0.0794       0.0794        0.122        0.101        0.331      0.00345\n","     18     4       0.0164       0.0164     5.38e-05       0.0754       0.0989       0.0642       0.0977       0.0809       0.0837        0.124        0.104        0.479      0.00499\n","     18     5       0.0161       0.0161     4.81e-05       0.0748        0.098       0.0623       0.0999       0.0811       0.0806        0.126        0.103        0.416      0.00434\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              18   60.463    0.005       0.0164     9.23e-05       0.0165        0.076        0.099       0.0649       0.0982       0.0815       0.0837        0.124        0.104        0.559      0.00582\n","! Validation         18   60.463    0.005       0.0167     3.79e-05       0.0167        0.076       0.0999       0.0638          0.1       0.0822       0.0832        0.127        0.105        0.374      0.00389\n","Wall time: 60.46364463400005\n","! Best model       18    0.017\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     19     1       0.0169       0.0168     5.43e-05       0.0767          0.1       0.0682       0.0936       0.0809       0.0899        0.119        0.104        0.475      0.00495\n","     19     2       0.0139       0.0139     1.47e-05       0.0686       0.0911       0.0572       0.0915       0.0744       0.0749        0.117        0.096        0.226      0.00236\n","     19     3       0.0137       0.0135     0.000202       0.0688       0.0898       0.0599       0.0868       0.0733        0.077        0.111       0.0941         1.02       0.0106\n","     19     4       0.0142       0.0142      3.5e-05       0.0708       0.0922       0.0592        0.094       0.0766       0.0758        0.118       0.0971        0.407      0.00424\n","     19     5       0.0162        0.016     0.000191       0.0749       0.0979       0.0633       0.0981       0.0807       0.0832        0.122        0.103        0.998       0.0104\n","     19     6       0.0168       0.0164     0.000402       0.0762       0.0992       0.0645       0.0994        0.082        0.083        0.125        0.104         1.48       0.0154\n","     19     7       0.0147       0.0147     1.69e-05       0.0719       0.0938       0.0581       0.0995       0.0788       0.0752        0.123        0.099        0.288        0.003\n","     19     8       0.0131       0.0128     0.000319       0.0667       0.0875       0.0567       0.0867       0.0717       0.0733         0.11       0.0919         1.23       0.0129\n","     19     9       0.0148       0.0139     0.000847       0.0699       0.0913       0.0577       0.0942       0.0759       0.0748        0.118       0.0962         2.13       0.0222\n","     19    10       0.0183       0.0183     3.74e-05       0.0793        0.105       0.0658        0.106       0.0861        0.086        0.134         0.11         0.39      0.00407\n","     19    11       0.0222        0.022     0.000233       0.0884        0.115       0.0772        0.111        0.094       0.0999         0.14         0.12         1.04       0.0109\n","     19    12        0.023       0.0224      0.00057       0.0919        0.116       0.0832        0.109       0.0963        0.104        0.137         0.12         1.73        0.018\n","     19    13       0.0174       0.0174        2e-05       0.0787        0.102         0.07       0.0959        0.083       0.0908        0.121        0.106        0.271      0.00282\n","     19    14        0.016        0.016     5.68e-05       0.0751       0.0978       0.0637       0.0978       0.0807       0.0832        0.122        0.103        0.446      0.00465\n","     19    15       0.0217       0.0217     4.16e-05       0.0901        0.114       0.0853       0.0998       0.0926        0.107        0.127        0.117        0.445      0.00464\n","     19    16       0.0211       0.0211     2.43e-05       0.0883        0.112       0.0795        0.106       0.0927       0.0991        0.135        0.117        0.314      0.00327\n","     19    17        0.017        0.017      6.2e-05       0.0772        0.101       0.0647        0.102       0.0834       0.0847        0.127        0.106        0.531      0.00554\n","     19    18       0.0149       0.0149     1.22e-05       0.0718       0.0944       0.0598       0.0957       0.0778       0.0787         0.12       0.0993        0.231      0.00241\n","     19    19       0.0152       0.0151     5.58e-05       0.0718       0.0951       0.0608       0.0937       0.0773       0.0797         0.12       0.0999        0.477      0.00497\n","     19    20       0.0178       0.0177     0.000127       0.0775        0.103       0.0654        0.102       0.0835       0.0868        0.129        0.108        0.759      0.00791\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     19     1       0.0174       0.0173     3.69e-05       0.0772        0.102       0.0647        0.102       0.0834       0.0844         0.13        0.107        0.368      0.00383\n","     19     2       0.0168       0.0168     2.25e-05       0.0757          0.1       0.0629        0.101       0.0821       0.0832        0.128        0.105        0.286      0.00298\n","     19     3       0.0146       0.0146     2.43e-05       0.0716       0.0935       0.0597       0.0953       0.0775       0.0773         0.12       0.0984        0.306      0.00318\n","     19     4       0.0157       0.0157      5.1e-05       0.0737       0.0969       0.0626        0.096       0.0793       0.0816        0.122        0.102        0.463      0.00482\n","     19     5       0.0154       0.0153     4.43e-05        0.073       0.0958       0.0605       0.0979       0.0792       0.0785        0.123        0.101        0.399      0.00416\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              19   63.552    0.005       0.0168     0.000166        0.017       0.0767          0.1        0.066       0.0981       0.0821       0.0859        0.124        0.105        0.745      0.00776\n","! Validation         19   63.552    0.005       0.0159     3.58e-05        0.016       0.0742       0.0977       0.0621       0.0985       0.0803        0.081        0.124        0.103        0.364       0.0038\n","Wall time: 63.55328814400036\n","! Best model       19    0.016\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     20     1       0.0166       0.0165      0.00019       0.0765       0.0993       0.0659       0.0978       0.0819        0.086        0.121        0.104         1.01       0.0105\n","     20     2       0.0129       0.0129     2.13e-05       0.0672       0.0878       0.0568       0.0881       0.0724       0.0724        0.112       0.0925        0.283      0.00295\n","     20     3       0.0159       0.0159     4.97e-05       0.0735       0.0975       0.0624       0.0957       0.0791       0.0824        0.122        0.102        0.416      0.00433\n","     20     4       0.0187       0.0187     1.71e-05        0.081        0.106       0.0684        0.106       0.0873       0.0887        0.133        0.111        0.255      0.00266\n","     20     5       0.0176       0.0172     0.000327       0.0788        0.102       0.0682          0.1       0.0842       0.0883        0.124        0.106         1.29       0.0134\n","     20     6       0.0156       0.0156     2.46e-05       0.0751       0.0966       0.0655       0.0943       0.0799        0.084        0.118        0.101        0.326      0.00339\n","     20     7       0.0139       0.0139     2.86e-05       0.0689       0.0911        0.057       0.0926       0.0748       0.0741        0.118        0.096        0.334      0.00348\n","     20     8       0.0128       0.0128     1.33e-05       0.0674       0.0874       0.0561       0.0901       0.0731       0.0713        0.113       0.0921        0.239      0.00249\n","     20     9       0.0125       0.0125     1.75e-05       0.0669       0.0866       0.0567       0.0871       0.0719       0.0731        0.109       0.0909        0.266      0.00277\n","     20    10       0.0155       0.0155     5.12e-05       0.0741       0.0962       0.0605        0.101       0.0809       0.0768        0.126        0.102        0.468      0.00487\n","     20    11       0.0156       0.0155     0.000113       0.0732       0.0963       0.0622        0.095       0.0786       0.0824        0.119        0.101        0.706      0.00736\n","     20    12        0.014        0.014     3.89e-05       0.0703       0.0915       0.0591       0.0926       0.0759       0.0763        0.116       0.0961        0.391      0.00407\n","     20    13       0.0137       0.0136     0.000107       0.0686       0.0901       0.0562       0.0934       0.0748       0.0717        0.119       0.0952        0.689      0.00718\n","     20    14       0.0131        0.013     4.84e-05       0.0673       0.0884       0.0569       0.0881       0.0725        0.073        0.113        0.093        0.461       0.0048\n","     20    15       0.0135       0.0135     4.09e-05        0.069       0.0898       0.0577       0.0914       0.0746       0.0745        0.114       0.0944         0.42      0.00437\n","     20    16       0.0136       0.0136     2.57e-05       0.0678       0.0903       0.0558       0.0919       0.0738       0.0734        0.117       0.0952        0.294      0.00306\n","     20    17       0.0149       0.0148     6.05e-05       0.0717       0.0942       0.0606       0.0939       0.0773        0.078         0.12       0.0991        0.466      0.00485\n","     20    18       0.0149       0.0148     0.000126       0.0728        0.094       0.0632       0.0921       0.0776       0.0812        0.115       0.0983          0.8      0.00833\n","     20    19       0.0188       0.0187     4.86e-05       0.0797        0.106       0.0669        0.105       0.0862       0.0896        0.132        0.111        0.392      0.00409\n","     20    20       0.0141        0.014     9.42e-05       0.0705       0.0915       0.0602       0.0911       0.0756        0.078        0.114       0.0959        0.562      0.00586\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     20     1       0.0166       0.0166     3.76e-05       0.0755       0.0997       0.0631          0.1       0.0817       0.0824        0.127        0.105        0.375       0.0039\n","     20     2       0.0161       0.0161     2.24e-05        0.074        0.098       0.0613       0.0993       0.0803        0.081        0.125        0.103        0.285      0.00297\n","     20     3        0.014        0.014     2.41e-05         0.07       0.0916       0.0582       0.0937       0.0759       0.0754        0.117       0.0964        0.301      0.00313\n","     20     4       0.0151       0.0151     5.11e-05       0.0722        0.095       0.0612       0.0943       0.0778       0.0797         0.12       0.0998        0.462      0.00482\n","     20     5       0.0148       0.0147     4.36e-05       0.0713       0.0938        0.059        0.096       0.0775       0.0766        0.121       0.0989        0.395      0.00412\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              20   66.633    0.005       0.0148     7.22e-05       0.0149        0.072       0.0942       0.0608       0.0944       0.0776        0.079        0.119        0.099        0.503      0.00524\n","! Validation         20   66.633    0.005       0.0153     3.58e-05       0.0153       0.0726       0.0957       0.0606       0.0967       0.0786       0.0791        0.122        0.101        0.364      0.00379\n","Wall time: 66.634235386\n","! Best model       20    0.015\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     21     1       0.0121       0.0121     3.76e-05       0.0655        0.085       0.0558       0.0848       0.0703       0.0697        0.109       0.0896        0.437      0.00455\n","     21     2       0.0156       0.0155     0.000115       0.0734       0.0962       0.0609       0.0984       0.0796       0.0805        0.122        0.101        0.763      0.00794\n","     21     3       0.0155       0.0154     4.63e-05       0.0733       0.0961       0.0618       0.0962        0.079       0.0799        0.122        0.101        0.392      0.00409\n","     21     4       0.0194       0.0191     0.000283       0.0839        0.107       0.0744        0.103       0.0887       0.0944        0.129        0.112         1.22       0.0127\n","     21     5       0.0207       0.0206     8.38e-05       0.0875        0.111       0.0778        0.107       0.0923        0.098        0.133        0.116         0.59      0.00614\n","     21     6       0.0166       0.0166     5.84e-05       0.0759       0.0996       0.0662       0.0953       0.0807       0.0871        0.121        0.104        0.436      0.00455\n","     21     7       0.0132        0.013     0.000244        0.066       0.0881        0.055        0.088       0.0715       0.0706        0.115        0.093         1.15        0.012\n","     21     8       0.0185       0.0182     0.000293       0.0818        0.104       0.0719        0.102       0.0867       0.0905        0.128        0.109         1.23       0.0128\n","     21     9       0.0153       0.0153     4.51e-05        0.076       0.0957       0.0679       0.0923       0.0801       0.0841        0.115       0.0997        0.457      0.00476\n","     21    10       0.0126       0.0125     0.000114       0.0669       0.0865       0.0552       0.0903       0.0727       0.0698        0.113       0.0913        0.758       0.0079\n","     21    11       0.0136       0.0134     0.000184       0.0696       0.0895       0.0599       0.0891       0.0745       0.0756        0.112        0.094        0.895      0.00933\n","     21    12       0.0151       0.0151        7e-06       0.0725       0.0951       0.0601       0.0973       0.0787       0.0792        0.121          0.1        0.148      0.00154\n","     21    13       0.0148       0.0148     5.18e-05       0.0703        0.094        0.058       0.0949       0.0764       0.0771        0.121        0.099        0.461       0.0048\n","     21    14       0.0154       0.0154     4.56e-05       0.0732        0.096       0.0595        0.101         0.08       0.0789        0.123        0.101        0.448      0.00467\n","     21    15       0.0139       0.0138     6.84e-05       0.0689        0.091       0.0592       0.0884       0.0738       0.0765        0.115       0.0955         0.57      0.00594\n","     21    16        0.015       0.0149     3.05e-05       0.0727       0.0945       0.0605        0.097       0.0787       0.0785         0.12       0.0994        0.279       0.0029\n","     21    17       0.0127       0.0126     6.76e-05       0.0663        0.087       0.0534       0.0923       0.0728       0.0682        0.116        0.092        0.499      0.00519\n","     21    18       0.0126       0.0126     4.85e-05       0.0664       0.0868       0.0552       0.0886       0.0719       0.0701        0.113       0.0915        0.398      0.00415\n","     21    19        0.014       0.0139     8.61e-05       0.0686       0.0911        0.058       0.0899       0.0739       0.0759        0.116       0.0958        0.594      0.00619\n","     21    20       0.0151        0.015     7.61e-05       0.0727       0.0948       0.0631       0.0919       0.0775       0.0819        0.116       0.0991        0.614       0.0064\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     21     1        0.016       0.0159     3.78e-05       0.0739       0.0977       0.0616       0.0986       0.0801       0.0806        0.125        0.103        0.375      0.00391\n","     21     2       0.0154       0.0154     2.27e-05       0.0724        0.096       0.0598       0.0975       0.0787        0.079        0.123        0.101        0.286      0.00298\n","     21     3       0.0135       0.0135     2.47e-05       0.0686       0.0898       0.0569       0.0921       0.0745       0.0736        0.116       0.0946        0.303      0.00316\n","     21     4       0.0146       0.0145     5.15e-05       0.0708       0.0933       0.0598       0.0929       0.0763       0.0779        0.118       0.0981        0.464      0.00483\n","     21     5       0.0142       0.0142     4.38e-05       0.0699       0.0921       0.0577       0.0943        0.076        0.075        0.119       0.0971        0.396      0.00413\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              21   69.706    0.005        0.015     9.93e-05       0.0151       0.0726       0.0947       0.0617       0.0943        0.078       0.0797        0.119       0.0994        0.617      0.00643\n","! Validation         21   69.706    0.005       0.0147     3.61e-05       0.0147       0.0711       0.0938       0.0592       0.0951       0.0771       0.0772         0.12       0.0988        0.365       0.0038\n","Wall time: 69.70713557800036\n","! Best model       21    0.015\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     22     1       0.0137       0.0135     0.000183       0.0682       0.0901       0.0575       0.0898       0.0736       0.0748        0.115       0.0947        0.928      0.00966\n","     22     2       0.0147       0.0145     0.000172       0.0701       0.0932       0.0578       0.0946       0.0762       0.0765         0.12       0.0982        0.916      0.00954\n","     22     3       0.0168       0.0168     3.82e-05       0.0759          0.1       0.0654        0.097       0.0812        0.088        0.121        0.105        0.376      0.00392\n","     22     4       0.0144       0.0142      0.00015        0.072       0.0923       0.0632       0.0897       0.0764       0.0791        0.114       0.0967        0.814      0.00848\n","     22     5       0.0132       0.0131     0.000124       0.0684       0.0885       0.0581        0.089       0.0736        0.074        0.112        0.093        0.796      0.00829\n","     22     6       0.0125       0.0124      0.00011       0.0655       0.0863       0.0533       0.0899       0.0716        0.068        0.114       0.0912        0.674      0.00702\n","     22     7       0.0138       0.0137     9.82e-05       0.0679       0.0905       0.0547       0.0943       0.0745        0.072        0.119       0.0956        0.616      0.00642\n","     22     8       0.0166       0.0163     0.000252       0.0763       0.0989       0.0647       0.0994       0.0821       0.0817        0.126        0.104         1.13       0.0118\n","     22     9       0.0157       0.0156      1.2e-05       0.0756       0.0968       0.0644       0.0978       0.0811        0.081        0.122        0.102        0.199      0.00208\n","     22    10       0.0168       0.0167     6.04e-05       0.0755          0.1       0.0641       0.0983       0.0812       0.0858        0.124        0.105        0.496      0.00517\n","     22    11       0.0132       0.0131     8.96e-05       0.0671       0.0885       0.0569       0.0877       0.0723       0.0749        0.111       0.0928        0.628      0.00654\n","     22    12       0.0137       0.0136     5.66e-05        0.069       0.0904        0.058        0.091       0.0745        0.075        0.115       0.0951        0.545      0.00567\n","     22    13       0.0123       0.0123     2.83e-05       0.0653       0.0859       0.0548       0.0864       0.0706       0.0715        0.109       0.0903        0.318      0.00332\n","     22    14       0.0124       0.0123     7.07e-05        0.066       0.0858       0.0572       0.0836       0.0704       0.0738        0.106       0.0898        0.531      0.00553\n","     22    15       0.0132       0.0131     6.85e-05       0.0682       0.0887       0.0551       0.0943       0.0747       0.0713        0.116       0.0936        0.497      0.00518\n","     22    16       0.0111        0.011     1.67e-05       0.0623       0.0813       0.0516       0.0835       0.0676       0.0662        0.105       0.0857        0.279       0.0029\n","     22    17       0.0131        0.013     9.55e-05       0.0665       0.0881       0.0552       0.0891       0.0721       0.0729        0.113       0.0927        0.688      0.00716\n","     22    18       0.0132       0.0132     5.37e-05       0.0676       0.0887       0.0575        0.088       0.0727       0.0745        0.112       0.0932        0.413       0.0043\n","     22    19       0.0136       0.0136        6e-06       0.0689       0.0901        0.059       0.0887       0.0739       0.0771        0.112       0.0944        0.148      0.00154\n","     22    20       0.0151       0.0149     0.000184       0.0719       0.0944       0.0597       0.0964        0.078       0.0758        0.123       0.0996        0.958      0.00998\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     22     1       0.0154       0.0153     3.81e-05       0.0724       0.0958       0.0602       0.0969       0.0786       0.0788        0.123        0.101        0.375      0.00391\n","     22     2       0.0148       0.0148      2.3e-05       0.0709       0.0941       0.0584       0.0959       0.0772       0.0771        0.121       0.0991        0.287      0.00299\n","     22     3        0.013        0.013     2.54e-05       0.0673       0.0882       0.0557       0.0907       0.0732       0.0719        0.114       0.0929        0.307       0.0032\n","     22     4       0.0141        0.014     5.24e-05       0.0695       0.0917       0.0585       0.0914        0.075       0.0762        0.117       0.0964        0.467      0.00487\n","     22     5       0.0137       0.0137     4.42e-05       0.0686       0.0904       0.0566       0.0927       0.0746       0.0734        0.117       0.0953        0.399      0.00415\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              22   72.789    0.005       0.0139     9.34e-05        0.014       0.0694       0.0911       0.0584       0.0914       0.0749       0.0759        0.116       0.0957        0.597      0.00622\n","! Validation         22   72.789    0.005       0.0142     3.66e-05       0.0142       0.0698       0.0921       0.0579       0.0935       0.0757       0.0755        0.118        0.097        0.367      0.00382\n","Wall time: 72.7901878800003\n","! Best model       22    0.014\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     23     1       0.0128       0.0128     4.74e-05       0.0676       0.0875       0.0574       0.0881       0.0727       0.0742        0.109       0.0918        0.419      0.00437\n","     23     2       0.0123       0.0122      6.8e-05       0.0671       0.0855       0.0567       0.0878       0.0722       0.0717        0.108       0.0898        0.558      0.00581\n","     23     3       0.0129       0.0128     0.000114       0.0664       0.0874       0.0545       0.0902       0.0724       0.0715        0.113       0.0921          0.7      0.00729\n","     23     4       0.0143       0.0142     6.22e-05       0.0703       0.0922       0.0583       0.0944       0.0763       0.0761        0.118        0.097        0.497      0.00518\n","     23     5       0.0132        0.013     0.000222       0.0664       0.0881       0.0552        0.089       0.0721       0.0718        0.114       0.0929         1.05       0.0109\n","     23     6       0.0141       0.0141      3.6e-05       0.0696       0.0917       0.0572       0.0944       0.0758       0.0748        0.119       0.0967        0.382      0.00398\n","     23     7       0.0128       0.0127     0.000104       0.0667       0.0871       0.0559       0.0885       0.0722       0.0726         0.11       0.0915        0.587      0.00611\n","     23     8       0.0139       0.0138       0.0001       0.0685       0.0908       0.0551       0.0953       0.0752       0.0727        0.119       0.0959        0.567       0.0059\n","     23     9       0.0136       0.0135     6.22e-05       0.0668       0.0899       0.0547       0.0909       0.0728       0.0731        0.117       0.0948        0.509       0.0053\n","     23    10       0.0138       0.0137     7.71e-05       0.0698       0.0907       0.0596       0.0901       0.0749       0.0771        0.113       0.0951         0.62      0.00646\n","     23    11       0.0152        0.015     0.000207       0.0732       0.0948       0.0632       0.0931       0.0781       0.0801        0.119       0.0995         1.01       0.0105\n","     23    12       0.0135       0.0134     0.000143       0.0694       0.0895       0.0592       0.0897       0.0745       0.0751        0.113        0.094        0.818      0.00852\n","     23    13       0.0119       0.0114     0.000493       0.0632       0.0827       0.0525       0.0848       0.0686       0.0682        0.106       0.0871         1.61       0.0168\n","     23    14       0.0137       0.0135     0.000264       0.0693       0.0898       0.0592       0.0894       0.0743       0.0757        0.113       0.0943         1.12       0.0117\n","     23    15       0.0185       0.0184     7.52e-05       0.0825        0.105       0.0774       0.0928       0.0851       0.0963         0.12        0.108         0.58      0.00604\n","     23    16       0.0182       0.0181     0.000164       0.0826        0.104       0.0765       0.0949       0.0857       0.0955        0.119        0.107        0.904      0.00942\n","     23    17        0.015       0.0149      5.4e-05       0.0728       0.0945       0.0608       0.0968       0.0788       0.0766        0.123       0.0996         0.41      0.00427\n","     23    18       0.0148       0.0148     6.28e-05       0.0705        0.094       0.0586       0.0941       0.0764       0.0786        0.119       0.0988        0.542      0.00564\n","     23    19       0.0153       0.0152     5.04e-05       0.0737       0.0955       0.0599        0.101       0.0806       0.0755        0.126        0.101        0.438      0.00457\n","     23    20       0.0196       0.0196     4.06e-05       0.0853        0.108       0.0763        0.103       0.0898       0.0948        0.131        0.113        0.395      0.00411\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     23     1       0.0148       0.0148     3.85e-05       0.0711        0.094        0.059       0.0954       0.0772       0.0772        0.121        0.099        0.381      0.00397\n","     23     2       0.0143       0.0143     2.31e-05       0.0695       0.0924       0.0571       0.0944       0.0757       0.0754        0.119       0.0974        0.286      0.00298\n","     23     3       0.0126       0.0125     2.55e-05       0.0661       0.0866       0.0545       0.0892       0.0719       0.0704        0.112       0.0913        0.307       0.0032\n","     23     4       0.0137       0.0136     5.27e-05       0.0683       0.0902       0.0574       0.0901       0.0738       0.0747        0.115       0.0949        0.467      0.00486\n","     23     5       0.0132       0.0132     4.42e-05       0.0673       0.0888       0.0554       0.0911       0.0733       0.0721        0.115       0.0937        0.399      0.00415\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              23   75.874    0.005       0.0143     0.000122       0.0145       0.0711       0.0927       0.0604       0.0924       0.0764        0.078        0.117       0.0973        0.686      0.00714\n","! Validation         23   75.874    0.005       0.0137     3.68e-05       0.0137       0.0685       0.0905       0.0567        0.092       0.0744        0.074        0.117       0.0953        0.368      0.00383\n","Wall time: 75.87460525799997\n","! Best model       23    0.014\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     24     1       0.0188       0.0187     9.18e-05       0.0831        0.106       0.0752        0.099       0.0871       0.0947        0.125         0.11        0.547       0.0057\n","     24     2       0.0128       0.0127     7.22e-05       0.0663       0.0873        0.056       0.0868       0.0714       0.0721        0.112       0.0919        0.538      0.00561\n","     24     3       0.0126       0.0126     4.13e-05       0.0665       0.0867       0.0556       0.0884        0.072       0.0715        0.111       0.0912        0.415      0.00432\n","     24     4       0.0163       0.0161     0.000164       0.0773       0.0983        0.067       0.0979       0.0824       0.0835        0.123        0.103        0.859      0.00895\n","     24     5       0.0131        0.013     3.28e-05       0.0671       0.0883       0.0566       0.0883       0.0724       0.0729        0.113       0.0929        0.348      0.00362\n","     24     6       0.0128       0.0128     1.93e-05       0.0664       0.0875       0.0551        0.089        0.072       0.0723        0.112       0.0921        0.272      0.00283\n","     24     7       0.0145       0.0144     6.63e-05       0.0728        0.093        0.064       0.0905       0.0772       0.0807        0.114       0.0972         0.52      0.00542\n","     24     8       0.0142       0.0141     3.34e-05        0.071        0.092       0.0605       0.0919       0.0762       0.0775        0.116       0.0965        0.417      0.00434\n","     24     9       0.0136       0.0136     2.12e-05       0.0682       0.0903       0.0567       0.0914        0.074       0.0756        0.114       0.0948        0.297      0.00309\n","     24    10       0.0151        0.015     0.000162       0.0738       0.0947       0.0625       0.0965       0.0795       0.0803        0.118       0.0993        0.796      0.00829\n","     24    11       0.0165       0.0165     4.11e-05        0.077       0.0993       0.0629        0.105        0.084       0.0786        0.131        0.105          0.4      0.00417\n","     24    12       0.0124       0.0124     2.78e-05       0.0649       0.0862       0.0558       0.0832       0.0695        0.073        0.108       0.0904        0.308      0.00321\n","     24    13       0.0126       0.0124     0.000202       0.0663       0.0861       0.0553       0.0883       0.0718       0.0707        0.111       0.0907         1.02       0.0107\n","     24    14       0.0142       0.0142     2.91e-05       0.0715       0.0921       0.0615       0.0915       0.0765       0.0778        0.115       0.0967        0.319      0.00332\n","     24    15       0.0177       0.0175     0.000205       0.0788        0.102       0.0686        0.099       0.0838       0.0881        0.126        0.107        0.993       0.0103\n","     24    16       0.0129       0.0129     1.81e-05       0.0675       0.0879       0.0544       0.0938       0.0741       0.0686        0.117        0.093        0.263      0.00274\n","     24    17       0.0127       0.0127     1.98e-05       0.0678       0.0873       0.0562       0.0911       0.0736       0.0708        0.113        0.092        0.296      0.00308\n","     24    18       0.0128       0.0127     4.83e-05       0.0671       0.0873       0.0562        0.089       0.0726       0.0726        0.111       0.0918        0.418      0.00435\n","     24    19        0.013        0.013     6.06e-05       0.0673       0.0881       0.0567       0.0883       0.0725        0.073        0.112       0.0927        0.395      0.00411\n","     24    20       0.0111        0.011     4.25e-05       0.0622       0.0813       0.0527       0.0813        0.067        0.068        0.103       0.0855        0.426      0.00444\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     24     1       0.0143       0.0143     3.96e-05         0.07       0.0925        0.058        0.094        0.076       0.0758        0.119       0.0975        0.399      0.00415\n","     24     2       0.0139       0.0138     2.25e-05       0.0684        0.091       0.0561       0.0932       0.0746       0.0741        0.118       0.0959         0.28      0.00292\n","     24     3       0.0122       0.0122     2.43e-05        0.065       0.0853       0.0536       0.0879       0.0707       0.0692        0.111         0.09        0.299      0.00311\n","     24     4       0.0133       0.0132     5.18e-05       0.0673        0.089       0.0564        0.089       0.0727       0.0733        0.114       0.0936        0.458      0.00478\n","     24     5       0.0128       0.0128     4.27e-05       0.0663       0.0875       0.0545       0.0897       0.0721        0.071        0.114       0.0923         0.39      0.00406\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              24   78.980    0.005       0.0139        7e-05        0.014       0.0702       0.0913       0.0595       0.0915       0.0755       0.0764        0.115       0.0959        0.493      0.00513\n","! Validation         24   78.980    0.005       0.0133     3.62e-05       0.0133       0.0674       0.0891       0.0557       0.0907       0.0732       0.0727        0.115       0.0939        0.365       0.0038\n","Wall time: 78.98103825099997\n","! Best model       24    0.013\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     25     1       0.0135       0.0134     8.05e-05       0.0671       0.0895       0.0544       0.0924       0.0734       0.0722        0.117       0.0944        0.557       0.0058\n","     25     2       0.0112       0.0111      1.2e-05       0.0617       0.0817       0.0497       0.0858       0.0677       0.0639        0.109       0.0864        0.214      0.00223\n","     25     3       0.0112       0.0112     1.63e-05       0.0626       0.0819        0.053       0.0817       0.0674       0.0676        0.105       0.0862         0.28      0.00292\n","     25     4       0.0114       0.0113     5.73e-05       0.0643       0.0824       0.0542       0.0844       0.0693       0.0685        0.105       0.0867        0.518       0.0054\n","     25     5       0.0107       0.0107     8.27e-06       0.0602       0.0801       0.0498        0.081       0.0654       0.0653        0.104       0.0844        0.163       0.0017\n","     25     6       0.0112       0.0111     4.72e-05        0.062       0.0815       0.0511       0.0837       0.0674       0.0665        0.105       0.0859        0.449      0.00468\n","     25     7       0.0133       0.0133      1.6e-05       0.0656       0.0893       0.0539       0.0892       0.0715       0.0743        0.114       0.0939         0.29      0.00303\n","     25     8       0.0116       0.0116     1.14e-05       0.0642       0.0833       0.0544       0.0836        0.069       0.0692        0.106       0.0876        0.215      0.00224\n","     25     9       0.0111        0.011     7.93e-05       0.0629       0.0813       0.0525       0.0837       0.0681       0.0664        0.105       0.0856        0.545      0.00567\n","     25    10       0.0118       0.0118     3.92e-05       0.0645        0.084        0.054       0.0856       0.0698       0.0689        0.108       0.0885        0.442       0.0046\n","     25    11       0.0134       0.0132     0.000235       0.0683       0.0887       0.0578       0.0892       0.0735       0.0735        0.113       0.0933         1.08       0.0113\n","     25    12       0.0131       0.0131     2.18e-05       0.0687       0.0884       0.0579       0.0903       0.0741       0.0723        0.114       0.0932        0.301      0.00313\n","     25    13       0.0142       0.0141      3.5e-05       0.0699       0.0919       0.0595       0.0907       0.0751       0.0779        0.115       0.0964        0.399      0.00416\n","     25    14       0.0113       0.0111      0.00018       0.0623       0.0814       0.0522       0.0823       0.0673       0.0667        0.105       0.0858        0.924      0.00962\n","     25    15       0.0117       0.0117     2.18e-05       0.0636       0.0836       0.0531       0.0848       0.0689       0.0694        0.107        0.088         0.28      0.00292\n","     25    16       0.0117       0.0116     8.43e-05       0.0616       0.0832       0.0487       0.0876       0.0681       0.0649        0.111        0.088        0.582      0.00607\n","     25    17       0.0123       0.0122     2.83e-05       0.0648       0.0856       0.0526       0.0894        0.071       0.0674        0.113       0.0904        0.295      0.00307\n","     25    18        0.012        0.012     1.96e-05       0.0644       0.0846       0.0526       0.0879       0.0703       0.0688         0.11       0.0892         0.22      0.00229\n","     25    19       0.0125       0.0125     2.06e-05       0.0662       0.0864       0.0541       0.0904       0.0723       0.0711        0.111        0.091        0.328      0.00342\n","     25    20       0.0105       0.0104     0.000125       0.0607       0.0788       0.0493       0.0835       0.0664       0.0621        0.104       0.0833         0.66      0.00688\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     25     1       0.0139       0.0138     3.96e-05       0.0689        0.091        0.057       0.0928       0.0749       0.0745        0.117       0.0959        0.394      0.00411\n","     25     2       0.0134       0.0134     2.31e-05       0.0673       0.0896        0.055        0.092       0.0735       0.0727        0.116       0.0944        0.284      0.00296\n","     25     3       0.0119       0.0118     2.55e-05        0.064       0.0841       0.0527       0.0868       0.0697        0.068        0.109       0.0887        0.306      0.00319\n","     25     4       0.0129       0.0129     5.32e-05       0.0662       0.0877       0.0554       0.0879       0.0716        0.072        0.113       0.0924        0.467      0.00486\n","     25     5       0.0125       0.0124     4.38e-05       0.0652       0.0862       0.0536       0.0883        0.071       0.0698        0.112       0.0909        0.397      0.00413\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              25   82.095    0.005       0.0119     5.69e-05        0.012       0.0643       0.0845       0.0532       0.0864       0.0698       0.0689        0.109        0.089        0.437      0.00456\n","! Validation         25   82.095    0.005       0.0129      3.7e-05       0.0129       0.0663       0.0878       0.0547       0.0895       0.0721       0.0714        0.114       0.0925        0.369      0.00385\n","Wall time: 82.09622812200041\n","! Best model       25    0.013\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     26     1       0.0126       0.0126     3.67e-05        0.065       0.0868       0.0524       0.0902       0.0713         0.07        0.113       0.0916        0.385      0.00401\n","     26     2       0.0116       0.0115     9.37e-05       0.0637       0.0829       0.0548       0.0816       0.0682       0.0702        0.104        0.087        0.632      0.00659\n","     26     3       0.0116       0.0115     0.000117       0.0638       0.0829       0.0531       0.0852       0.0691       0.0673        0.107       0.0874        0.654      0.00681\n","     26     4       0.0124       0.0123     3.74e-05       0.0651       0.0859       0.0535       0.0883       0.0709       0.0701        0.111       0.0905        0.359      0.00374\n","     26     5       0.0102       0.0101     0.000124        0.059       0.0776        0.047        0.083        0.065       0.0607        0.103       0.0821        0.748      0.00779\n","     26     6         0.01      0.00998      6.6e-05       0.0589       0.0773       0.0473       0.0819       0.0646        0.061        0.102       0.0817        0.547      0.00569\n","     26     7       0.0115       0.0113     0.000142       0.0615       0.0824       0.0501       0.0841       0.0671       0.0662        0.108        0.087        0.833      0.00868\n","     26     8       0.0121       0.0121     3.08e-05       0.0649       0.0851       0.0545       0.0856       0.0701       0.0691         0.11       0.0897        0.313      0.00326\n","     26     9       0.0135       0.0135     4.39e-05        0.069       0.0897        0.059        0.089        0.074       0.0753        0.113       0.0943        0.461       0.0048\n","     26    10        0.014        0.014     3.31e-05       0.0691       0.0914       0.0571       0.0929        0.075       0.0752        0.117       0.0962        0.408      0.00425\n","     26    11       0.0112        0.011     0.000179       0.0616       0.0812       0.0505       0.0837       0.0671       0.0647        0.107       0.0857        0.867      0.00904\n","     26    12       0.0104       0.0104     4.29e-05       0.0613       0.0788       0.0516       0.0806       0.0661       0.0652        0.101       0.0829        0.365       0.0038\n","     26    13       0.0131       0.0129     0.000172       0.0666        0.088       0.0549       0.0902       0.0725         0.07        0.116       0.0929        0.844      0.00879\n","     26    14       0.0162       0.0161     9.37e-05       0.0766       0.0981       0.0682       0.0935       0.0808       0.0867        0.118        0.102        0.666      0.00694\n","     26    15       0.0159       0.0159     3.52e-05       0.0769       0.0975       0.0711       0.0886       0.0798       0.0893        0.112        0.101        0.411      0.00428\n","     26    16       0.0124        0.012       0.0004       0.0653       0.0849       0.0555       0.0848       0.0702       0.0711        0.107       0.0892         1.43       0.0149\n","     26    17       0.0113       0.0112     9.05e-05       0.0625       0.0818       0.0525       0.0825       0.0675       0.0681        0.104       0.0859        0.587      0.00612\n","     26    18       0.0149       0.0147     0.000193       0.0721       0.0938        0.062       0.0923       0.0772       0.0816        0.114        0.098         1.03       0.0107\n","     26    19       0.0168       0.0164     0.000393       0.0775        0.099       0.0691       0.0943       0.0817       0.0868         0.12        0.103         1.46       0.0152\n","     26    20       0.0179       0.0179     1.41e-05       0.0809        0.103       0.0687        0.105        0.087       0.0858        0.132        0.109        0.228      0.00238\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     26     1       0.0135       0.0134     4.04e-05       0.0679       0.0896        0.056       0.0915       0.0738       0.0732        0.116       0.0945        0.405      0.00421\n","     26     2        0.013        0.013     2.31e-05       0.0662       0.0882       0.0539       0.0908       0.0724       0.0713        0.115        0.093        0.282      0.00294\n","     26     3       0.0115       0.0115     2.52e-05       0.0631        0.083       0.0518       0.0856       0.0687       0.0669        0.108       0.0875        0.304      0.00317\n","     26     4       0.0126       0.0125     5.31e-05       0.0653       0.0865       0.0545       0.0868       0.0707       0.0708        0.111       0.0911        0.466      0.00485\n","     26     5       0.0121       0.0121     4.33e-05       0.0642       0.0849       0.0528        0.087       0.0699       0.0688         0.11       0.0896        0.393       0.0041\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              26   85.193    0.005       0.0129     0.000117        0.013       0.0671       0.0877       0.0567       0.0879       0.0723       0.0732        0.111       0.0922        0.661      0.00689\n","! Validation         26   85.193    0.005       0.0125      3.7e-05       0.0125       0.0653       0.0865       0.0538       0.0883       0.0711       0.0702        0.112       0.0912         0.37      0.00385\n","Wall time: 85.19334010000011\n","! Best model       26    0.013\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     27     1       0.0157       0.0156     0.000144        0.075       0.0966       0.0651       0.0947       0.0799       0.0816        0.121        0.101        0.784      0.00816\n","     27     2        0.012       0.0119     9.66e-05       0.0646       0.0845       0.0563       0.0812       0.0687       0.0712        0.106       0.0887         0.72       0.0075\n","     27     3       0.0114       0.0113     3.57e-05       0.0627       0.0823       0.0513       0.0853       0.0683        0.066        0.108       0.0869        0.406      0.00423\n","     27     4       0.0197       0.0195     0.000217       0.0853        0.108       0.0781       0.0997       0.0889       0.0992        0.124        0.111         1.06        0.011\n","     27     5       0.0183       0.0182     0.000133       0.0814        0.104       0.0738       0.0966       0.0852        0.093        0.124        0.108        0.792      0.00825\n","     27     6        0.016        0.016     1.54e-05       0.0736       0.0979       0.0592        0.102       0.0807       0.0789        0.128        0.103        0.251      0.00262\n","     27     7       0.0105       0.0105     2.08e-05       0.0606       0.0792       0.0504        0.081       0.0657       0.0644        0.103       0.0835        0.312      0.00326\n","     27     8       0.0157       0.0157     2.59e-05       0.0757       0.0969       0.0662       0.0947       0.0805       0.0826        0.121        0.102        0.269       0.0028\n","     27     9       0.0188       0.0185     0.000254        0.082        0.105       0.0716        0.103       0.0872       0.0902         0.13         0.11         1.11       0.0116\n","     27    10       0.0107       0.0107     6.38e-05       0.0618         0.08       0.0531       0.0791       0.0661       0.0677          0.1       0.0839        0.522      0.00544\n","     27    11        0.013        0.013     6.78e-05       0.0678       0.0881       0.0574       0.0886        0.073        0.074        0.111       0.0925        0.583      0.00607\n","     27    12       0.0152       0.0152     9.41e-06       0.0739       0.0953        0.066       0.0898       0.0779       0.0845        0.114       0.0992        0.205      0.00214\n","     27    13       0.0127       0.0127      3.6e-05       0.0684       0.0871       0.0579       0.0892       0.0736        0.072        0.111       0.0917         0.38      0.00396\n","     27    14       0.0119       0.0118     7.91e-05       0.0645        0.084        0.055       0.0836       0.0693       0.0717        0.104        0.088        0.487      0.00508\n","     27    15        0.015       0.0149     8.76e-05       0.0738       0.0945        0.066       0.0892       0.0776       0.0825        0.115       0.0986        0.601      0.00626\n","     27    16       0.0144       0.0144     5.11e-05       0.0712       0.0928       0.0619       0.0897       0.0758       0.0789        0.116       0.0973        0.463      0.00482\n","     27    17       0.0105       0.0105     8.39e-06       0.0612       0.0793       0.0514       0.0807       0.0661        0.066        0.101       0.0834         0.18      0.00187\n","     27    18       0.0107       0.0107     5.52e-05       0.0621         0.08       0.0501       0.0859        0.068       0.0625        0.107       0.0846        0.521      0.00542\n","     27    19       0.0154       0.0153     0.000104       0.0735       0.0956       0.0631       0.0942       0.0787       0.0823        0.118          0.1        0.672        0.007\n","     27    20       0.0153       0.0153     2.81e-05       0.0741       0.0955       0.0636       0.0951       0.0794       0.0816        0.119          0.1        0.254      0.00264\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     27     1       0.0131       0.0131     4.08e-05        0.067       0.0885       0.0552       0.0906       0.0729       0.0721        0.114       0.0933        0.409      0.00426\n","     27     2       0.0127       0.0127      2.3e-05       0.0653        0.087       0.0531       0.0897       0.0714       0.0702        0.113       0.0918         0.28      0.00292\n","     27     3       0.0112       0.0112     2.51e-05       0.0622       0.0819       0.0511       0.0845       0.0678       0.0659        0.107       0.0864        0.302      0.00315\n","     27     4       0.0123       0.0122     5.32e-05       0.0645       0.0856       0.0536       0.0861       0.0699       0.0697        0.111       0.0902        0.467      0.00486\n","     27     5       0.0118       0.0118     4.31e-05       0.0633       0.0839       0.0521       0.0858        0.069        0.068        0.109       0.0885        0.392      0.00408\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              27   88.285    0.005       0.0141     7.66e-05       0.0142       0.0706       0.0918       0.0609       0.0902       0.0755       0.0781        0.114       0.0962        0.529      0.00551\n","! Validation         27   88.285    0.005       0.0122      3.7e-05       0.0122       0.0645       0.0854        0.053       0.0874       0.0702       0.0692        0.111       0.0901         0.37      0.00385\n","Wall time: 88.28530925800032\n","! Best model       27    0.012\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     28     1       0.0125       0.0125     4.65e-05       0.0636       0.0863       0.0513       0.0881       0.0697       0.0704        0.112        0.091        0.429      0.00447\n","     28     2       0.0129       0.0126     0.000289       0.0661       0.0868       0.0553       0.0876       0.0715       0.0727         0.11       0.0912         1.19       0.0124\n","     28     3       0.0145       0.0145      2.9e-05       0.0718       0.0931        0.062       0.0913       0.0767       0.0795        0.116       0.0975        0.377      0.00392\n","     28     4       0.0112       0.0111     5.49e-05       0.0634       0.0816       0.0543       0.0816        0.068       0.0678        0.104       0.0859        0.486      0.00506\n","     28     5       0.0107       0.0107     4.17e-05       0.0613       0.0799       0.0499       0.0842       0.0671       0.0634        0.106       0.0845        0.401      0.00418\n","     28     6        0.016       0.0159     6.64e-05       0.0748       0.0975        0.063       0.0985       0.0807       0.0805        0.125        0.103        0.544      0.00567\n","     28     7       0.0157       0.0156     7.07e-05       0.0737       0.0966       0.0603        0.101       0.0804       0.0774        0.127        0.102        0.496      0.00517\n","     28     8       0.0118       0.0118     1.39e-05       0.0639        0.084       0.0523        0.087       0.0697       0.0679        0.109       0.0886        0.248      0.00258\n","     28     9       0.0111        0.011     6.98e-05       0.0619       0.0811       0.0491       0.0875       0.0683       0.0621         0.11       0.0859        0.535      0.00557\n","     28    10       0.0162       0.0162     3.45e-05       0.0776       0.0985       0.0702       0.0922       0.0812       0.0885        0.116        0.102        0.384        0.004\n","     28    11       0.0184       0.0183     5.27e-05       0.0838        0.105       0.0776       0.0962       0.0869        0.096         0.12        0.108        0.441       0.0046\n","     28    12       0.0125       0.0124     0.000129       0.0654        0.086       0.0536       0.0892       0.0714       0.0677        0.114       0.0909        0.751      0.00782\n","     28    13       0.0119       0.0118      1.3e-05       0.0652       0.0842       0.0578       0.0799       0.0689       0.0733        0.103       0.0879        0.233      0.00243\n","     28    14       0.0145       0.0144     0.000103       0.0712       0.0929       0.0601       0.0935       0.0768       0.0766        0.119       0.0978        0.667      0.00695\n","     28    15       0.0136       0.0135     5.39e-05       0.0696         0.09       0.0577       0.0934       0.0756       0.0723        0.118        0.095        0.442      0.00461\n","     28    16       0.0112       0.0112     1.59e-05       0.0625       0.0819       0.0525       0.0825       0.0675       0.0675        0.105       0.0862        0.208      0.00217\n","     28    17       0.0111        0.011     8.89e-05       0.0617       0.0812       0.0516        0.082       0.0668        0.066        0.105       0.0855        0.633       0.0066\n","     28    18       0.0126       0.0125     4.56e-05       0.0669       0.0867       0.0574       0.0859       0.0716        0.073        0.109        0.091         0.43      0.00448\n","     28    19       0.0121        0.012     7.43e-05       0.0632       0.0848       0.0517       0.0861       0.0689        0.069         0.11       0.0894        0.601      0.00626\n","     28    20       0.0129       0.0128     8.18e-05       0.0685       0.0875       0.0589       0.0879       0.0734       0.0744        0.109       0.0917        0.564      0.00587\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     28     1       0.0128       0.0128     4.13e-05       0.0662       0.0874       0.0545       0.0896        0.072       0.0712        0.113       0.0921        0.417      0.00435\n","     28     2       0.0124       0.0124      2.3e-05       0.0646       0.0861       0.0524       0.0889       0.0706       0.0692        0.112       0.0909         0.28      0.00291\n","     28     3        0.011        0.011     2.46e-05       0.0615        0.081       0.0504       0.0837       0.0671        0.065        0.106       0.0855        0.298       0.0031\n","     28     4        0.012        0.012      5.3e-05       0.0637       0.0847       0.0529       0.0854       0.0692       0.0688         0.11       0.0893        0.466      0.00485\n","     28     5       0.0115       0.0115     4.24e-05       0.0626        0.083       0.0514       0.0848       0.0681       0.0672        0.108       0.0875        0.387      0.00403\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              28   91.376    0.005       0.0131     6.87e-05       0.0132       0.0678       0.0885       0.0573       0.0888        0.073       0.0737        0.112       0.0931        0.503      0.00524\n","! Validation         28   91.376    0.005       0.0119     3.68e-05        0.012       0.0637       0.0845       0.0523       0.0865       0.0694       0.0683         0.11       0.0891         0.37      0.00385\n","Wall time: 91.37717645800012\n","! Best model       28    0.012\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     29     1        0.011       0.0109     3.52e-05       0.0616       0.0809       0.0513       0.0821       0.0667       0.0656        0.105       0.0853        0.369      0.00385\n","     29     2        0.012        0.012     5.71e-05       0.0643       0.0847        0.053       0.0869         0.07        0.069        0.109       0.0892        0.465      0.00485\n","     29     3       0.0126       0.0126     4.03e-05       0.0657       0.0868       0.0549       0.0874       0.0711        0.071        0.112       0.0915        0.416      0.00434\n","     29     4        0.012        0.012     7.33e-06       0.0656       0.0846       0.0554        0.086       0.0707       0.0705        0.107        0.089        0.174      0.00182\n","     29     5       0.0114       0.0114     5.61e-05       0.0631       0.0825       0.0512        0.087       0.0691       0.0646         0.11       0.0873        0.459      0.00478\n","     29     6        0.011        0.011        3e-05       0.0613       0.0812       0.0509       0.0822       0.0665       0.0658        0.105       0.0856        0.329      0.00343\n","     29     7       0.0099      0.00987     3.04e-05       0.0586       0.0768        0.049       0.0778       0.0634       0.0625       0.0995        0.081        0.403       0.0042\n","     29     8      0.00903      0.00898     4.19e-05        0.056       0.0733       0.0455        0.077       0.0613       0.0576       0.0975       0.0775        0.322      0.00335\n","     29     9       0.0129       0.0128     8.48e-05       0.0664       0.0876       0.0552       0.0888        0.072       0.0718        0.113       0.0922        0.641      0.00668\n","     29    10       0.0133       0.0133     1.37e-05       0.0672       0.0892       0.0562       0.0892       0.0727       0.0735        0.114       0.0939        0.246      0.00257\n","     29    11       0.0126       0.0126      5.2e-05       0.0653       0.0867       0.0531       0.0897       0.0714        0.072         0.11       0.0912         0.37      0.00386\n","     29    12       0.0125       0.0124     7.61e-05       0.0656       0.0861       0.0566       0.0836       0.0701       0.0743        0.106         0.09        0.525      0.00547\n","     29    13       0.0113       0.0112     0.000125       0.0645       0.0818       0.0564       0.0807       0.0685         0.07        0.101       0.0857        0.742      0.00772\n","     29    14      0.00956       0.0094     0.000166       0.0562        0.075       0.0451       0.0784       0.0617       0.0583          0.1       0.0793        0.857      0.00893\n","     29    15        0.013       0.0128      0.00018       0.0673       0.0875       0.0556       0.0905       0.0731       0.0715        0.113       0.0922        0.966       0.0101\n","     29    16       0.0162        0.016      0.00014       0.0757       0.0979       0.0666        0.094       0.0803       0.0851         0.12        0.102        0.788      0.00821\n","     29    17       0.0143       0.0142     0.000113       0.0715       0.0922        0.062       0.0904       0.0762       0.0785        0.115       0.0967        0.743      0.00774\n","     29    18       0.0108       0.0108     5.56e-05       0.0613       0.0803       0.0506       0.0827       0.0666        0.065        0.104       0.0847        0.411      0.00429\n","     29    19       0.0101       0.0101      4.6e-05       0.0599       0.0776       0.0511       0.0774       0.0642       0.0651       0.0979       0.0815        0.481      0.00501\n","     29    20       0.0141       0.0138     0.000278       0.0696       0.0909       0.0589       0.0911        0.075       0.0748        0.117       0.0958         1.23       0.0128\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     29     1       0.0125       0.0125     4.17e-05       0.0654       0.0864       0.0538       0.0887       0.0713       0.0703        0.112       0.0911        0.422       0.0044\n","     29     2       0.0121       0.0121     2.31e-05       0.0639       0.0852       0.0518        0.088       0.0699       0.0683        0.111       0.0899        0.281      0.00293\n","     29     3       0.0108       0.0108     2.45e-05       0.0609       0.0802       0.0499       0.0829       0.0664       0.0643        0.105       0.0847        0.297       0.0031\n","     29     4       0.0118       0.0117     5.32e-05       0.0631       0.0839       0.0523       0.0847       0.0685       0.0679        0.109       0.0884        0.467      0.00487\n","     29     5       0.0113       0.0113     4.23e-05       0.0619       0.0821       0.0509       0.0838       0.0673       0.0665        0.107       0.0865        0.385      0.00401\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              29   94.475    0.005       0.0119     8.14e-05        0.012       0.0643       0.0844       0.0539       0.0851       0.0695       0.0696        0.108       0.0888        0.547       0.0057\n","! Validation         29   94.475    0.005       0.0117      3.7e-05       0.0117        0.063       0.0836       0.0517       0.0856       0.0687       0.0675        0.109       0.0882        0.371      0.00386\n","Wall time: 94.47583997200036\n","! Best model       29    0.012\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     30     1       0.0151       0.0151     3.92e-06       0.0735       0.0952       0.0608       0.0991       0.0799       0.0775        0.123          0.1        0.129      0.00135\n","     30     2      0.00991      0.00958     0.000331        0.058       0.0757       0.0482       0.0776       0.0629       0.0616        0.098       0.0798         1.34       0.0139\n","     30     3       0.0128       0.0126     0.000165       0.0668       0.0869       0.0563       0.0877        0.072       0.0706        0.113       0.0917        0.874       0.0091\n","     30     4       0.0155       0.0154     3.91e-05       0.0725       0.0961       0.0603       0.0968       0.0786       0.0799        0.122        0.101        0.372      0.00388\n","     30     5       0.0115       0.0112     0.000286       0.0626       0.0819       0.0525       0.0826       0.0676       0.0676        0.105       0.0862         1.16       0.0121\n","     30     6       0.0105       0.0101     0.000396       0.0596       0.0778       0.0488       0.0812        0.065       0.0627        0.102       0.0821         1.44        0.015\n","     30     7      0.00967      0.00964      2.2e-05       0.0588        0.076       0.0499       0.0768       0.0633       0.0625       0.0976         0.08        0.307       0.0032\n","     30     8       0.0119       0.0116     0.000288       0.0627       0.0833       0.0519       0.0841        0.068       0.0681        0.108       0.0878         1.23       0.0128\n","     30     9       0.0111       0.0109     0.000206       0.0609       0.0806       0.0486       0.0854        0.067       0.0637        0.107       0.0852        0.913      0.00951\n","     30    10       0.0117       0.0116     0.000113        0.062       0.0834       0.0507       0.0848       0.0677       0.0669        0.109        0.088        0.634       0.0066\n","     30    11       0.0139       0.0137      0.00024       0.0691       0.0905       0.0568       0.0936       0.0752       0.0736        0.117       0.0954         1.07       0.0111\n","     30    12       0.0133       0.0131     0.000141       0.0687       0.0887       0.0603       0.0856       0.0729       0.0775        0.108       0.0926         0.76      0.00792\n","     30    13       0.0108       0.0106     0.000174       0.0618       0.0797       0.0512        0.083       0.0671        0.065        0.103       0.0839        0.904      0.00942\n","     30    14       0.0104       0.0104     2.32e-05       0.0608       0.0788       0.0523       0.0777        0.065       0.0675       0.0975       0.0825        0.326       0.0034\n","     30    15       0.0129       0.0128     0.000174       0.0677       0.0874       0.0594       0.0843       0.0719       0.0758        0.107       0.0913        0.902      0.00939\n","     30    16       0.0105       0.0104     0.000139        0.059       0.0788       0.0482       0.0807       0.0644       0.0627        0.104       0.0832        0.752      0.00783\n","     30    17       0.0139       0.0139     2.39e-05       0.0719       0.0911        0.062       0.0917       0.0769       0.0768        0.114       0.0956        0.317       0.0033\n","     30    18        0.018       0.0178     0.000126       0.0807        0.103        0.069        0.104       0.0866       0.0859        0.131        0.109        0.751      0.00782\n","     30    19        0.013        0.013     6.53e-05       0.0677       0.0881       0.0564       0.0902       0.0733        0.073        0.112       0.0926        0.377      0.00393\n","     30    20       0.0116       0.0116     6.54e-05       0.0645       0.0832       0.0536       0.0863         0.07       0.0677        0.108       0.0877        0.408      0.00425\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     30     1       0.0123       0.0122     4.13e-05       0.0647       0.0855       0.0531       0.0879       0.0705       0.0694        0.111       0.0901        0.414      0.00431\n","     30     2       0.0119       0.0119     2.35e-05       0.0632       0.0843       0.0512       0.0873       0.0692       0.0675        0.111        0.089        0.283      0.00295\n","     30     3       0.0106       0.0106     2.56e-05       0.0603       0.0795       0.0493       0.0823       0.0658       0.0636        0.104        0.084        0.305      0.00317\n","     30     4       0.0116       0.0115     5.42e-05       0.0625       0.0831       0.0516       0.0841       0.0679       0.0671        0.108       0.0876        0.473      0.00492\n","     30     5       0.0111        0.011     4.33e-05       0.0612       0.0812       0.0503       0.0829       0.0666       0.0658        0.105       0.0856        0.392      0.00409\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              30   97.569    0.005       0.0122     0.000151       0.0124       0.0655       0.0856       0.0549       0.0867       0.0708       0.0707         0.11       0.0901        0.748      0.00779\n","! Validation         30   97.569    0.005       0.0114     3.76e-05       0.0115       0.0624       0.0827       0.0511       0.0849        0.068       0.0667        0.108       0.0873        0.373      0.00389\n","Wall time: 97.5694939330001\n","! Best model       30    0.011\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     31     1       0.0155       0.0155     2.24e-05        0.075       0.0962       0.0666       0.0917       0.0792       0.0843        0.117          0.1        0.293      0.00305\n","     31     2       0.0156       0.0155     0.000147       0.0759       0.0963       0.0686       0.0904       0.0795       0.0868        0.113       0.0998        0.768        0.008\n","     31     3      0.00992      0.00991     8.09e-06       0.0582        0.077       0.0475       0.0794       0.0635       0.0606        0.102       0.0814        0.167      0.00174\n","     31     4       0.0107       0.0107     3.88e-05       0.0614         0.08       0.0528       0.0787       0.0657       0.0676          0.1        0.084        0.363      0.00379\n","     31     5       0.0117       0.0117     1.06e-05       0.0647       0.0837       0.0535       0.0872       0.0703       0.0676        0.109       0.0883        0.208      0.00217\n","     31     6      0.00917      0.00915      1.7e-05       0.0571        0.074       0.0468       0.0778       0.0623       0.0585       0.0979       0.0782         0.27      0.00281\n","     31     7       0.0114       0.0113     4.12e-05       0.0623       0.0823       0.0509       0.0851        0.068       0.0665        0.107       0.0868          0.4      0.00417\n","     31     8       0.0108       0.0107     2.21e-05       0.0615       0.0802       0.0495       0.0856       0.0676       0.0634        0.106       0.0847        0.325      0.00338\n","     31     9       0.0102       0.0101     0.000119       0.0596       0.0778       0.0492       0.0803       0.0647       0.0628        0.101       0.0821        0.627      0.00653\n","     31    10       0.0112       0.0111     7.85e-05       0.0627       0.0817       0.0523       0.0833       0.0678       0.0661        0.106       0.0861        0.529      0.00551\n","     31    11      0.00993       0.0099     2.94e-05       0.0588        0.077       0.0488       0.0788       0.0638       0.0622          0.1       0.0812        0.315      0.00328\n","     31    12       0.0121       0.0118     0.000317       0.0631        0.084       0.0517       0.0858       0.0688       0.0688        0.108       0.0885         1.29       0.0135\n","     31    13       0.0103       0.0102     7.93e-05       0.0589       0.0782       0.0478       0.0811       0.0645       0.0625        0.103       0.0825        0.565      0.00588\n","     31    14      0.00998      0.00994     4.58e-05       0.0573       0.0771       0.0448       0.0821       0.0635       0.0597        0.104       0.0816        0.446      0.00464\n","     31    15       0.0102      0.00992     0.000318       0.0585       0.0771       0.0466       0.0822       0.0644       0.0604        0.103       0.0815         1.28       0.0133\n","     31    16      0.00972      0.00966     5.18e-05       0.0575       0.0761       0.0475       0.0775       0.0625       0.0613       0.0991       0.0802        0.511      0.00533\n","     31    17       0.0107       0.0105     0.000227       0.0594       0.0791       0.0489       0.0806       0.0647       0.0649        0.102       0.0833         1.03       0.0107\n","     31    18      0.00936      0.00931     4.43e-05       0.0572       0.0747       0.0476       0.0765        0.062       0.0607       0.0967       0.0787        0.447      0.00466\n","     31    19       0.0109       0.0109     3.19e-05       0.0613       0.0807       0.0503       0.0832       0.0668        0.065        0.105       0.0851        0.313      0.00326\n","     31    20      0.00977      0.00955     0.000216       0.0576       0.0756       0.0465       0.0798       0.0631       0.0595          0.1       0.0799         1.06       0.0111\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     31     1        0.012        0.012     4.17e-05       0.0641       0.0846       0.0525       0.0872       0.0698       0.0686         0.11       0.0892        0.417      0.00435\n","     31     2       0.0117       0.0116     2.37e-05       0.0626       0.0835       0.0507       0.0866       0.0686       0.0666         0.11       0.0881        0.284      0.00296\n","     31     3       0.0104       0.0104     2.58e-05       0.0597       0.0788       0.0488       0.0816       0.0652       0.0629        0.104       0.0833        0.305      0.00318\n","     31     4       0.0114       0.0113     5.46e-05       0.0619       0.0823        0.051       0.0835       0.0673       0.0663        0.107       0.0869        0.474      0.00494\n","     31     5       0.0108       0.0108     4.36e-05       0.0605       0.0804       0.0498        0.082       0.0659       0.0651        0.104       0.0847        0.393      0.00409\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              31  100.652    0.005       0.0109     9.33e-05        0.011       0.0614       0.0807       0.0509       0.0824       0.0666       0.0659        0.104        0.085         0.56      0.00584\n","! Validation         31  100.652    0.005       0.0112     3.79e-05       0.0113       0.0618        0.082       0.0506       0.0842       0.0674       0.0659        0.107       0.0865        0.375       0.0039\n","Wall time: 100.65331203900041\n","! Best model       31    0.011\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     32     1       0.0106       0.0105     3.44e-05         0.06       0.0795        0.049       0.0821       0.0656       0.0653        0.102       0.0837        0.388      0.00404\n","     32     2      0.00867      0.00854     0.000131       0.0553       0.0715       0.0442       0.0777       0.0609       0.0558       0.0955       0.0756        0.752      0.00783\n","     32     3        0.012       0.0118     0.000162       0.0642       0.0841       0.0541       0.0844       0.0693       0.0697        0.107       0.0884        0.938      0.00977\n","     32     4       0.0102       0.0101     9.94e-05       0.0607       0.0778       0.0525       0.0772       0.0648       0.0659       0.0973       0.0816        0.692      0.00721\n","     32     5       0.0102      0.00987     0.000377       0.0585       0.0769        0.047       0.0816       0.0643       0.0597        0.103       0.0813         1.34        0.014\n","     32     6       0.0105       0.0105      3.5e-05       0.0608       0.0791       0.0504       0.0816        0.066       0.0637        0.103       0.0835        0.374      0.00389\n","     32     7       0.0123       0.0119     0.000372       0.0629       0.0843       0.0509        0.087        0.069       0.0679         0.11        0.089         1.36       0.0142\n","     32     8       0.0109       0.0105     0.000364       0.0607       0.0792         0.05        0.082        0.066       0.0632        0.104       0.0837         1.35       0.0141\n","     32     9       0.0113       0.0112     7.17e-05       0.0629        0.082       0.0534        0.082       0.0677       0.0686        0.104       0.0862         0.52      0.00541\n","     32    10       0.0114        0.011     0.000377       0.0619       0.0812       0.0504        0.085       0.0677       0.0646        0.107       0.0857         1.42       0.0147\n","     32    11       0.0119       0.0116     0.000318       0.0636       0.0832       0.0536       0.0837       0.0687       0.0705        0.104       0.0873         1.29       0.0135\n","     32    12      0.00994      0.00988     5.96e-05       0.0589       0.0769        0.048       0.0807       0.0643       0.0614        0.101       0.0812        0.488      0.00508\n","     32    13      0.00977      0.00942     0.000345       0.0566       0.0751       0.0481       0.0737       0.0609       0.0629       0.0949       0.0789         1.32       0.0138\n","     32    14      0.00956      0.00952     4.09e-05       0.0582       0.0755       0.0486       0.0776       0.0631       0.0609       0.0984       0.0796        0.423      0.00441\n","     32    15       0.0105       0.0104     5.95e-05       0.0591       0.0789       0.0485       0.0803       0.0644       0.0638        0.103       0.0832        0.444      0.00462\n","     32    16       0.0101      0.00992     0.000202       0.0585       0.0771        0.049       0.0773       0.0632        0.062        0.101       0.0813        0.931       0.0097\n","     32    17       0.0108       0.0107     3.76e-05         0.06       0.0802       0.0485        0.083       0.0657       0.0623        0.107       0.0848        0.361      0.00376\n","     32    18       0.0125       0.0124     9.02e-05       0.0664       0.0862       0.0577       0.0836       0.0707       0.0738        0.107       0.0903        0.642      0.00669\n","     32    19       0.0111       0.0109     0.000234       0.0625       0.0806       0.0539       0.0796       0.0668       0.0696       0.0991       0.0843         1.06       0.0111\n","     32    20       0.0117       0.0116     0.000105       0.0617       0.0832       0.0491        0.087       0.0681       0.0653        0.111        0.088        0.703      0.00732\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     32     1       0.0118       0.0117     4.16e-05       0.0634       0.0837       0.0519       0.0864       0.0691       0.0678        0.109       0.0883        0.415      0.00432\n","     32     2       0.0114       0.0114      2.4e-05        0.062       0.0826       0.0501       0.0858        0.068       0.0658        0.109       0.0873        0.287      0.00299\n","     32     3       0.0102       0.0102     2.64e-05       0.0592       0.0782       0.0483        0.081       0.0647       0.0623        0.103       0.0826        0.309      0.00322\n","     32     4       0.0112       0.0111     5.51e-05       0.0613       0.0816       0.0504       0.0829       0.0667       0.0655        0.107       0.0861        0.477      0.00497\n","     32     5       0.0106       0.0106      4.4e-05       0.0599       0.0796       0.0493       0.0812       0.0652       0.0645        0.103       0.0839        0.396      0.00412\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              32  103.771    0.005       0.0106     0.000176       0.0108       0.0607       0.0797       0.0503       0.0814       0.0658        0.065        0.103        0.084         0.84      0.00875\n","! Validation         32  103.771    0.005        0.011     3.82e-05        0.011       0.0612       0.0812         0.05       0.0835       0.0667       0.0652        0.106       0.0857        0.377      0.00392\n","Wall time: 103.77147550500013\n","! Best model       32    0.011\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     33     1      0.00964      0.00917     0.000473       0.0574       0.0741       0.0486        0.075       0.0618       0.0617        0.094       0.0779         1.59       0.0166\n","     33     2       0.0127       0.0127     2.58e-05       0.0653       0.0872       0.0506       0.0947       0.0727       0.0645         0.12       0.0924        0.336       0.0035\n","     33     3       0.0123       0.0122     9.45e-05       0.0665       0.0855       0.0558        0.088       0.0719       0.0689        0.112       0.0902        0.658      0.00686\n","     33     4       0.0105       0.0102     0.000298       0.0605       0.0782       0.0519       0.0777       0.0648       0.0658       0.0985       0.0822         1.18       0.0123\n","     33     5       0.0117       0.0116     4.28e-05       0.0625       0.0834       0.0496       0.0881       0.0689       0.0646        0.112       0.0883        0.456      0.00475\n","     33     6        0.016       0.0158     0.000182       0.0764       0.0972       0.0691        0.091         0.08       0.0867        0.115        0.101          0.9      0.00938\n","     33     7       0.0183       0.0182     4.26e-05       0.0834        0.104       0.0786        0.093       0.0858       0.0969        0.118        0.108        0.407      0.00424\n","     33     8       0.0126       0.0125     2.68e-05       0.0667       0.0866       0.0567       0.0868       0.0717       0.0719         0.11       0.0911        0.328      0.00342\n","     33     9       0.0109       0.0108      0.00018        0.061       0.0803       0.0519       0.0793       0.0656       0.0669        0.102       0.0844        0.916      0.00954\n","     33    10       0.0139       0.0138     3.87e-05       0.0693       0.0909       0.0575       0.0928       0.0752       0.0743        0.117       0.0958        0.418      0.00435\n","     33    11       0.0136       0.0132     0.000316       0.0679        0.089       0.0569       0.0898       0.0734       0.0722        0.116       0.0939         1.25       0.0131\n","     33    12       0.0102       0.0102     2.02e-05       0.0587        0.078       0.0453       0.0856       0.0655        0.059        0.106       0.0826         0.31      0.00323\n","     33    13       0.0112       0.0111     0.000102        0.062       0.0817       0.0508       0.0843       0.0675       0.0661        0.106       0.0861        0.609      0.00635\n","     33    14       0.0137       0.0137     1.88e-05       0.0709       0.0904       0.0636       0.0854       0.0745       0.0797        0.109       0.0942        0.294      0.00306\n","     33    15       0.0113       0.0113     3.83e-05       0.0631       0.0822       0.0533       0.0825       0.0679       0.0682        0.105       0.0864        0.381      0.00397\n","     33    16      0.00919      0.00917     2.09e-05       0.0569       0.0741       0.0471       0.0765       0.0618       0.0595       0.0968       0.0782        0.293      0.00305\n","     33    17        0.011       0.0109     4.77e-05       0.0618       0.0809         0.05       0.0853       0.0677       0.0661        0.104       0.0853        0.438      0.00457\n","     33    18       0.0118       0.0118     2.82e-05       0.0634       0.0839       0.0515       0.0871       0.0693       0.0676        0.109       0.0885        0.343      0.00358\n","     33    19       0.0107       0.0107     2.69e-05       0.0603         0.08       0.0497       0.0816       0.0657       0.0657        0.103       0.0842         0.28      0.00292\n","     33    20      0.00978      0.00966      0.00012        0.057        0.076       0.0466       0.0777       0.0621       0.0615       0.0989       0.0802        0.713      0.00743\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     33     1       0.0115       0.0115     4.17e-05       0.0628       0.0829       0.0513       0.0858       0.0685        0.067        0.108       0.0875        0.415      0.00432\n","     33     2       0.0112       0.0112     2.41e-05       0.0614       0.0819       0.0496       0.0851       0.0674       0.0651        0.108       0.0865        0.289      0.00301\n","     33     3       0.0101         0.01     2.66e-05       0.0587       0.0775       0.0478       0.0805       0.0641       0.0616        0.102       0.0819         0.31      0.00323\n","     33     4        0.011       0.0109     5.54e-05       0.0607       0.0809       0.0499       0.0824       0.0662       0.0648        0.106       0.0854        0.478      0.00498\n","     33     5       0.0104       0.0104     4.43e-05       0.0594       0.0789       0.0488       0.0805       0.0646       0.0639        0.102       0.0832        0.397      0.00414\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              33  106.890    0.005       0.0119     0.000107        0.012       0.0645       0.0845       0.0543       0.0851       0.0697         0.07        0.108       0.0889        0.605      0.00631\n","! Validation         33  106.890    0.005       0.0108     3.84e-05       0.0109       0.0606       0.0805       0.0495       0.0829       0.0662       0.0645        0.105       0.0849        0.378      0.00394\n","Wall time: 106.89112503500019\n","! Best model       33    0.011\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     34     1       0.0102       0.0102     1.97e-05       0.0596       0.0781       0.0497       0.0793       0.0645        0.063        0.102       0.0824        0.242      0.00252\n","     34     2       0.0112       0.0112     3.54e-05       0.0625       0.0817       0.0517       0.0842       0.0679       0.0657        0.107       0.0862        0.375       0.0039\n","     34     3      0.00835       0.0082     0.000153       0.0544       0.0701       0.0449       0.0732       0.0591        0.056        0.092        0.074        0.822      0.00856\n","     34     4       0.0113       0.0113     4.07e-05        0.062       0.0822       0.0508       0.0843       0.0675       0.0674        0.106       0.0866        0.387      0.00403\n","     34     5         0.01      0.00991     0.000123       0.0578        0.077       0.0482       0.0769       0.0626       0.0641       0.0978        0.081        0.727      0.00757\n","     34     6      0.00991      0.00974      0.00017       0.0589       0.0764       0.0495       0.0779       0.0637       0.0628       0.0981       0.0804        0.775      0.00808\n","     34     7      0.00894      0.00893     1.74e-05       0.0555       0.0731       0.0451       0.0764       0.0607       0.0585       0.0959       0.0772        0.253      0.00263\n","     34     8         0.01      0.00982     0.000221       0.0585       0.0767       0.0482       0.0792       0.0637       0.0623       0.0994       0.0808         1.07       0.0111\n","     34     9      0.00992      0.00991     1.19e-05       0.0588        0.077       0.0479       0.0806       0.0642       0.0612        0.102       0.0813        0.223      0.00232\n","     34    10      0.00874       0.0087     3.57e-05       0.0556       0.0722       0.0457       0.0753       0.0605       0.0581       0.0942       0.0762        0.395      0.00412\n","     34    11       0.0101         0.01     3.03e-05       0.0589       0.0775       0.0483       0.0801       0.0642       0.0611        0.103        0.082        0.334      0.00348\n","     34    12         0.01      0.00998     4.31e-05       0.0586       0.0773       0.0466       0.0825       0.0646        0.061        0.102       0.0817        0.372      0.00387\n","     34    13       0.0105       0.0105     7.56e-06       0.0598       0.0794       0.0484       0.0827       0.0655       0.0632        0.105       0.0839        0.169      0.00176\n","     34    14       0.0104       0.0104     2.95e-05       0.0583       0.0789       0.0461       0.0826       0.0643       0.0608        0.106       0.0835        0.358      0.00373\n","     34    15      0.00893      0.00887     5.84e-05       0.0565       0.0729       0.0468       0.0759       0.0613       0.0593       0.0944       0.0768        0.518       0.0054\n","     34    16      0.00981      0.00975     6.41e-05       0.0574       0.0764       0.0451       0.0818       0.0635       0.0581        0.104       0.0809        0.494      0.00515\n","     34    17       0.0103       0.0102     3.33e-05       0.0586       0.0783        0.048       0.0798       0.0639       0.0609        0.105       0.0828        0.382      0.00397\n","     34    18       0.0115       0.0115     5.74e-05       0.0633       0.0828        0.054       0.0818       0.0679       0.0691        0.105       0.0871        0.541      0.00564\n","     34    19       0.0119       0.0119     1.58e-05       0.0643       0.0844       0.0544       0.0843       0.0693       0.0699        0.108       0.0888        0.261      0.00272\n","     34    20       0.0103       0.0103     4.71e-05       0.0601       0.0784       0.0495       0.0812       0.0653        0.063        0.102       0.0827        0.387      0.00403\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     34     1       0.0113       0.0113     4.24e-05       0.0622       0.0821       0.0507       0.0851       0.0679       0.0663        0.107       0.0867        0.423      0.00441\n","     34     2        0.011        0.011     2.41e-05       0.0608       0.0812       0.0491       0.0844       0.0667       0.0644        0.107       0.0857        0.288        0.003\n","     34     3      0.00992      0.00989     2.62e-05       0.0582       0.0769       0.0473         0.08       0.0637        0.061        0.102       0.0813        0.306      0.00319\n","     34     4       0.0108       0.0108     5.51e-05       0.0602       0.0802       0.0493       0.0818       0.0656       0.0641        0.105       0.0847        0.477      0.00497\n","     34     5       0.0103       0.0102     4.39e-05       0.0588       0.0782       0.0484       0.0797        0.064       0.0633        0.102       0.0825        0.394      0.00411\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              34  110.017    0.005       0.0101     6.08e-05       0.0101        0.059       0.0776       0.0484         0.08       0.0642       0.0624        0.101       0.0819        0.454      0.00473\n","! Validation         34  110.017    0.005       0.0106     3.84e-05       0.0107       0.0601       0.0798        0.049       0.0822       0.0656       0.0638        0.105       0.0842        0.378      0.00394\n","Wall time: 110.01756731200021\n","! Best model       34    0.011\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     35     1      0.00962      0.00956     5.15e-05       0.0572       0.0757       0.0458       0.0799       0.0628       0.0597          0.1         0.08         0.42      0.00438\n","     35     2       0.0096      0.00955      4.4e-05       0.0575       0.0756       0.0485       0.0756        0.062       0.0624       0.0968       0.0796        0.474      0.00493\n","     35     3       0.0104       0.0103     2.61e-05       0.0589       0.0786       0.0475       0.0817       0.0646       0.0629        0.103        0.083        0.284      0.00296\n","     35     4      0.00984      0.00961     0.000226       0.0573       0.0759       0.0471       0.0775       0.0623       0.0613       0.0988         0.08         1.05        0.011\n","     35     5       0.0109       0.0109     2.82e-05       0.0609       0.0807        0.049       0.0846       0.0668       0.0637        0.107       0.0853        0.336       0.0035\n","     35     6       0.0105       0.0104     0.000105       0.0597       0.0787       0.0489       0.0813       0.0651       0.0628        0.103       0.0831          0.7      0.00729\n","     35     7       0.0111       0.0111     1.39e-05       0.0613       0.0814       0.0507       0.0826       0.0666       0.0657        0.106       0.0859        0.238      0.00248\n","     35     8       0.0102       0.0101     8.16e-05       0.0585       0.0777       0.0473        0.081       0.0642       0.0615        0.103       0.0821          0.5       0.0052\n","     35     9      0.00937      0.00931     5.95e-05       0.0572       0.0747       0.0472       0.0774       0.0623       0.0603       0.0973       0.0788        0.523      0.00545\n","     35    10       0.0127       0.0127     2.83e-05       0.0664        0.087       0.0556       0.0881       0.0719       0.0722        0.111       0.0915         0.36      0.00375\n","     35    11       0.0146       0.0146     5.53e-05       0.0724       0.0934       0.0593       0.0986        0.079       0.0745        0.123       0.0986        0.503      0.00524\n","     35    12        0.016        0.016     5.18e-05        0.076       0.0978        0.065        0.098       0.0815       0.0818        0.124        0.103        0.474      0.00494\n","     35    13       0.0138       0.0138     2.27e-05       0.0703       0.0909       0.0596       0.0917       0.0756       0.0756        0.116       0.0955        0.263      0.00274\n","     35    14      0.00938       0.0093      8.4e-05       0.0584       0.0746       0.0493       0.0765       0.0629       0.0623       0.0945       0.0784         0.62      0.00646\n","     35    15      0.00994      0.00988     5.75e-05       0.0577       0.0769       0.0475        0.078       0.0628       0.0611        0.101       0.0812        0.428      0.00446\n","     35    16       0.0123       0.0121     0.000218       0.0663       0.0851       0.0573       0.0843       0.0708       0.0718        0.107       0.0893         1.09       0.0113\n","     35    17       0.0158       0.0157     5.16e-05       0.0761        0.097       0.0698       0.0888       0.0793       0.0875        0.114        0.101        0.523      0.00545\n","     35    18       0.0113       0.0111     0.000226        0.064       0.0815       0.0554       0.0813       0.0683       0.0696        0.101       0.0854            1       0.0104\n","     35    19      0.00846      0.00804     0.000421       0.0533       0.0694       0.0447       0.0707       0.0577       0.0566       0.0896       0.0731         1.49       0.0155\n","     35    20       0.0119       0.0118     2.44e-05       0.0651       0.0842        0.056       0.0833       0.0696       0.0712        0.105       0.0883        0.262      0.00273\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     35     1       0.0111       0.0111     4.24e-05       0.0616       0.0814       0.0502       0.0845       0.0674       0.0655        0.106       0.0859        0.424      0.00442\n","     35     2       0.0108       0.0108     2.43e-05       0.0603       0.0805       0.0486       0.0837       0.0662       0.0637        0.106        0.085        0.289      0.00301\n","     35     3      0.00977      0.00975     2.61e-05       0.0578       0.0764       0.0469       0.0795       0.0632       0.0604        0.101       0.0807        0.305      0.00318\n","     35     4       0.0106       0.0106     5.51e-05       0.0597       0.0796       0.0488       0.0814       0.0651       0.0634        0.105       0.0841        0.477      0.00497\n","     35     5       0.0101         0.01     4.39e-05       0.0583       0.0775       0.0479       0.0791       0.0635       0.0628        0.101       0.0818        0.394      0.00411\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              35  113.161    0.005       0.0113     9.38e-05       0.0114       0.0627       0.0822       0.0526        0.083       0.0678       0.0677        0.105       0.0865        0.577      0.00601\n","! Validation         35  113.161    0.005       0.0105     3.83e-05       0.0105       0.0595       0.0791       0.0485       0.0816       0.0651       0.0632        0.104       0.0835        0.378      0.00394\n","Wall time: 113.16187504400023\n","! Best model       35    0.010\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     36     1       0.0138       0.0132     0.000625       0.0698       0.0889         0.06       0.0895       0.0748       0.0771        0.109        0.093         1.84       0.0191\n","     36     2       0.0106       0.0105     7.27e-05       0.0615       0.0794       0.0535       0.0776       0.0655       0.0682        0.098       0.0831        0.495      0.00515\n","     36     3      0.00942      0.00924     0.000183       0.0566       0.0744        0.047       0.0757       0.0614       0.0601       0.0968       0.0784        0.856      0.00891\n","     36     4       0.0138       0.0137      6.7e-05       0.0702       0.0906       0.0626       0.0853        0.074       0.0803        0.108       0.0943        0.531      0.00553\n","     36     5       0.0124       0.0124     9.91e-06       0.0666       0.0863       0.0591       0.0816       0.0704       0.0754        0.105         0.09        0.217      0.00226\n","     36     6      0.00948      0.00946     2.91e-05       0.0569       0.0752       0.0454       0.0799       0.0627       0.0588          0.1       0.0796        0.323      0.00336\n","     36     7       0.0113       0.0112     3.85e-05       0.0632        0.082       0.0537       0.0823        0.068       0.0698        0.102       0.0859        0.372      0.00387\n","     36     8       0.0116       0.0114     0.000187       0.0638       0.0827       0.0529       0.0856       0.0692       0.0675        0.107       0.0872        0.877      0.00913\n","     36     9      0.00931      0.00926        5e-05       0.0565       0.0744       0.0441       0.0813       0.0627       0.0555        0.102       0.0789        0.479      0.00499\n","     36    10      0.00885      0.00883     1.33e-05       0.0557       0.0727       0.0451       0.0767       0.0609       0.0568        0.097       0.0769        0.201      0.00209\n","     36    11      0.00913      0.00884     0.000295       0.0553       0.0727       0.0454        0.075       0.0602       0.0578       0.0959       0.0768         1.21       0.0126\n","     36    12       0.0101      0.00998      9.2e-05       0.0588       0.0773       0.0493       0.0778       0.0635       0.0644       0.0981       0.0813        0.644      0.00671\n","     36    13       0.0099      0.00967     0.000238       0.0578       0.0761        0.047       0.0795       0.0632       0.0592        0.102       0.0805          1.1       0.0115\n","     36    14      0.00934      0.00927     7.12e-05       0.0557       0.0745       0.0445        0.078       0.0613        0.057        0.101       0.0789        0.584      0.00609\n","     36    15      0.00901      0.00901     4.79e-06       0.0558       0.0734       0.0456       0.0764        0.061       0.0573        0.098       0.0777        0.144       0.0015\n","     36    16       0.0127       0.0124     0.000291       0.0649       0.0862       0.0533       0.0882       0.0707       0.0703        0.111       0.0909         1.22       0.0128\n","     36    17        0.012        0.012     3.56e-05       0.0645       0.0847       0.0544       0.0846       0.0695       0.0706        0.107        0.089        0.341      0.00355\n","     36    18       0.0102         0.01     0.000167       0.0583       0.0774       0.0476       0.0797       0.0637       0.0612        0.102       0.0818        0.908      0.00945\n","     36    19       0.0103       0.0101     0.000169       0.0605       0.0779       0.0523       0.0769       0.0646       0.0661       0.0973       0.0817        0.952      0.00992\n","     36    20        0.012       0.0119      6.5e-05       0.0656       0.0845        0.058       0.0807       0.0694       0.0733        0.103       0.0883        0.539      0.00561\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     36     1       0.0109       0.0109     4.23e-05       0.0611       0.0807       0.0497        0.084       0.0668       0.0649        0.105       0.0852        0.421      0.00438\n","     36     2       0.0107       0.0107     2.44e-05       0.0598       0.0799       0.0481       0.0832       0.0657       0.0631        0.106       0.0844        0.292      0.00304\n","     36     3      0.00964      0.00961     2.66e-05       0.0573       0.0758       0.0465        0.079       0.0628       0.0599          0.1       0.0801        0.309      0.00321\n","     36     4       0.0105       0.0104     5.55e-05       0.0592        0.079       0.0483       0.0809       0.0646       0.0628        0.104       0.0835        0.479      0.00499\n","     36     5      0.00993      0.00988     4.46e-05       0.0579       0.0769       0.0475       0.0786        0.063       0.0623          0.1       0.0811        0.397      0.00414\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              36  116.296    0.005       0.0106     0.000135       0.0108       0.0609       0.0798        0.051       0.0806       0.0658       0.0658        0.102        0.084        0.691       0.0072\n","! Validation         36  116.296    0.005       0.0103     3.87e-05       0.0103       0.0591       0.0785        0.048       0.0811       0.0646       0.0626        0.103       0.0829        0.379      0.00395\n","Wall time: 116.29674897099994\n","! Best model       36    0.010\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     37     1       0.0112       0.0111     8.81e-05       0.0628       0.0817       0.0516       0.0853       0.0684       0.0653        0.107       0.0862        0.594      0.00619\n","     37     2      0.00969      0.00958     0.000113       0.0576       0.0757       0.0465       0.0799       0.0632       0.0599          0.1         0.08         0.77      0.00802\n","     37     3       0.0102       0.0102     3.05e-05       0.0582       0.0781       0.0465       0.0816       0.0641       0.0611        0.104       0.0826        0.378      0.00393\n","     37     4       0.0109       0.0107     0.000184       0.0597       0.0802        0.046       0.0872       0.0666       0.0608        0.109       0.0849        0.998       0.0104\n","     37     5      0.00991       0.0097     0.000205       0.0573       0.0762       0.0467       0.0785       0.0626       0.0611       0.0998       0.0804         1.02       0.0107\n","     37     6      0.00928      0.00926     2.24e-05       0.0557       0.0744       0.0442       0.0789       0.0615       0.0557        0.102       0.0789        0.317       0.0033\n","     37     7      0.00969      0.00941     0.000284       0.0562        0.075        0.045       0.0786       0.0618       0.0572        0.102       0.0795         1.23       0.0128\n","     37     8      0.00883      0.00866     0.000165       0.0543        0.072       0.0443       0.0745       0.0594       0.0579       0.0941        0.076        0.852      0.00887\n","     37     9         0.01      0.00987     0.000138       0.0586       0.0769       0.0499        0.076       0.0629       0.0633       0.0985       0.0809        0.632      0.00658\n","     37    10       0.0103       0.0101     0.000181       0.0591       0.0777       0.0483       0.0808       0.0646       0.0624        0.102        0.082        0.942      0.00981\n","     37    11      0.00871      0.00867      3.2e-05       0.0551       0.0721       0.0445       0.0763       0.0604       0.0573        0.095       0.0761        0.349      0.00364\n","     37    12      0.00945      0.00936     9.19e-05       0.0574       0.0749       0.0464       0.0795       0.0629       0.0599       0.0981        0.079        0.588      0.00613\n","     37    13      0.00851       0.0085     1.29e-05       0.0551       0.0713       0.0464       0.0724       0.0594       0.0583        0.092       0.0751        0.211       0.0022\n","     37    14      0.00885      0.00873     0.000128       0.0551       0.0723        0.044       0.0772       0.0606        0.056        0.097       0.0765        0.792      0.00825\n","     37    15      0.00846      0.00841     5.06e-05       0.0545       0.0709       0.0447       0.0741       0.0594        0.057       0.0928       0.0749        0.457      0.00476\n","     37    16       0.0102         0.01     0.000169       0.0579       0.0775       0.0456       0.0824        0.064       0.0602        0.104        0.082        0.923      0.00962\n","     37    17      0.00822      0.00817      5.2e-05        0.053       0.0699       0.0434        0.072       0.0577        0.057       0.0905       0.0737        0.496      0.00517\n","     37    18      0.00862      0.00859     3.39e-05        0.055       0.0717        0.045       0.0748       0.0599       0.0572       0.0942       0.0757        0.364      0.00379\n","     37    19      0.00931      0.00929     2.08e-05       0.0569       0.0746       0.0466       0.0773        0.062       0.0596       0.0978       0.0787        0.304      0.00316\n","     37    20      0.00963      0.00959      4.6e-05       0.0576       0.0758        0.047       0.0788       0.0629       0.0606       0.0994         0.08        0.486      0.00506\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     37     1       0.0108       0.0107     4.23e-05       0.0607       0.0801       0.0493       0.0834       0.0664       0.0643        0.105       0.0846        0.422       0.0044\n","     37     2       0.0105       0.0105     2.44e-05       0.0593       0.0792       0.0477       0.0826       0.0651       0.0624        0.105       0.0837        0.292      0.00304\n","     37     3      0.00951      0.00949     2.66e-05       0.0569       0.0754       0.0461       0.0786       0.0624       0.0594       0.0999       0.0796        0.308      0.00321\n","     37     4       0.0103       0.0103     5.54e-05       0.0587       0.0784       0.0479       0.0805       0.0642       0.0622        0.104       0.0829        0.479      0.00498\n","     37     5      0.00977      0.00972     4.45e-05       0.0574       0.0763       0.0471        0.078       0.0626       0.0617       0.0992       0.0805        0.397      0.00414\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              37  119.394    0.005       0.0094     0.000102       0.0095       0.0569        0.075       0.0461       0.0783       0.0622       0.0594       0.0991       0.0792        0.635      0.00662\n","! Validation         37  119.394    0.005       0.0101     3.86e-05       0.0102       0.0586       0.0779       0.0476       0.0806       0.0641        0.062        0.103       0.0823         0.38      0.00395\n","Wall time: 119.39451768100025\n","! Best model       37    0.010\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     38     1      0.00925      0.00923     2.46e-05       0.0568       0.0743       0.0466       0.0771       0.0619       0.0599       0.0969       0.0784        0.272      0.00284\n","     38     2       0.0111        0.011     7.46e-05        0.061       0.0812       0.0481       0.0868       0.0675       0.0626        0.109        0.086        0.583      0.00608\n","     38     3      0.00973      0.00971     1.25e-05       0.0585       0.0762       0.0482        0.079       0.0636       0.0611       0.0998       0.0805        0.244      0.00254\n","     38     4       0.0102       0.0101     7.25e-05       0.0588       0.0777       0.0489       0.0787       0.0638       0.0639       0.0997       0.0818        0.586      0.00611\n","     38     5      0.00924      0.00916     7.57e-05       0.0572        0.074       0.0482        0.075       0.0616       0.0616       0.0941       0.0779        0.541      0.00564\n","     38     6       0.0114       0.0113     3.62e-05       0.0638       0.0823        0.057       0.0776       0.0673       0.0727       0.0987       0.0857         0.31      0.00322\n","     38     7      0.00863      0.00859     4.13e-05       0.0545       0.0717       0.0455       0.0724       0.0589       0.0576       0.0937       0.0757        0.402      0.00419\n","     38     8      0.00922      0.00921     9.64e-06       0.0567       0.0743       0.0464       0.0772       0.0618       0.0596       0.0971       0.0784          0.2      0.00208\n","     38     9       0.0107       0.0107     1.41e-05       0.0609       0.0801       0.0505       0.0817       0.0661       0.0648        0.104       0.0845        0.242      0.00252\n","     38    10       0.0117       0.0116     0.000115       0.0629       0.0833       0.0504       0.0879       0.0691       0.0657         0.11        0.088        0.656      0.00683\n","     38    11       0.0109       0.0108       0.0001       0.0627       0.0804       0.0532       0.0816       0.0674       0.0684          0.1       0.0843        0.686      0.00715\n","     38    12      0.00941      0.00939     2.55e-05        0.058        0.075       0.0497       0.0746       0.0621       0.0622       0.0955       0.0788        0.314      0.00327\n","     38    13       0.0103       0.0103     2.65e-05       0.0599       0.0784       0.0492       0.0813       0.0652        0.064        0.101       0.0826        0.318      0.00331\n","     38    14       0.0103       0.0102     5.97e-05       0.0603       0.0781       0.0506       0.0797       0.0652       0.0648       0.0996       0.0822        0.508      0.00529\n","     38    15       0.0123       0.0123     4.59e-05       0.0653       0.0857       0.0527       0.0905       0.0716       0.0677        0.114       0.0906        0.485      0.00505\n","     38    16      0.00901      0.00901     3.93e-06       0.0558       0.0734       0.0449       0.0777       0.0613       0.0564       0.0991       0.0777        0.108      0.00113\n","     38    17      0.00883      0.00866     0.000174       0.0543        0.072       0.0437       0.0754       0.0595       0.0558       0.0965       0.0762        0.878      0.00914\n","     38    18       0.0104       0.0103     3.26e-05       0.0591       0.0786       0.0498       0.0777       0.0638       0.0646        0.101       0.0828        0.371      0.00386\n","     38    19      0.00959      0.00936     0.000229       0.0577       0.0748         0.05       0.0732       0.0616       0.0628       0.0944       0.0786         1.07       0.0111\n","     38    20      0.00969      0.00948     0.000211       0.0579       0.0753       0.0483       0.0772       0.0627        0.062       0.0966       0.0793        0.966       0.0101\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     38     1       0.0106       0.0106     4.19e-05       0.0602       0.0795       0.0489       0.0829       0.0659       0.0637        0.104       0.0839        0.415      0.00433\n","     38     2       0.0104       0.0103     2.47e-05       0.0588       0.0786       0.0472        0.082       0.0646       0.0618        0.104       0.0831        0.295      0.00308\n","     38     3      0.00939      0.00937     2.74e-05       0.0565       0.0749       0.0457       0.0782       0.0619       0.0589       0.0994       0.0792        0.313      0.00326\n","     38     4       0.0102       0.0101     5.59e-05       0.0583       0.0779       0.0475       0.0801       0.0638       0.0616        0.103       0.0823        0.481      0.00501\n","     38     5      0.00962      0.00957     4.53e-05        0.057       0.0757       0.0468       0.0775       0.0621       0.0612       0.0985       0.0798        0.402      0.00418\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              38  122.535    0.005         0.01     6.92e-05       0.0101       0.0591       0.0774       0.0491       0.0791       0.0641        0.063          0.1       0.0816        0.487      0.00507\n","! Validation         38  122.535    0.005      0.00999      3.9e-05         0.01       0.0582       0.0773       0.0472       0.0801       0.0637       0.0615        0.102       0.0817        0.381      0.00397\n","Wall time: 122.53536686200005\n","! Best model       38    0.010\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     39     1       0.0104       0.0102     0.000188       0.0596       0.0782       0.0489       0.0812        0.065       0.0631        0.102       0.0825        0.968       0.0101\n","     39     2       0.0094      0.00935     4.39e-05       0.0557       0.0748       0.0447       0.0778       0.0613       0.0583       0.0999       0.0791        0.384        0.004\n","     39     3      0.00904      0.00901     3.02e-05       0.0543       0.0734       0.0427       0.0773         0.06       0.0567       0.0987       0.0777        0.365       0.0038\n","     39     4      0.00919      0.00918     1.04e-05        0.056       0.0741       0.0436       0.0809       0.0622       0.0555        0.102       0.0785        0.211       0.0022\n","     39     5      0.00906      0.00897     8.87e-05       0.0563       0.0733        0.046        0.077       0.0615       0.0584       0.0963       0.0774        0.617      0.00643\n","     39     6       0.0106       0.0105     7.45e-05       0.0602       0.0793       0.0515       0.0776       0.0646       0.0679       0.0981        0.083        0.559      0.00582\n","     39     7       0.0089      0.00884     5.69e-05       0.0556       0.0728       0.0478       0.0712       0.0595       0.0608       0.0921       0.0765        0.451       0.0047\n","     39     8      0.00945      0.00942     3.37e-05       0.0566       0.0751        0.046       0.0779       0.0619       0.0587          0.1       0.0794        0.369      0.00384\n","     39     9      0.00934      0.00924     0.000105       0.0555       0.0744       0.0448        0.077       0.0609       0.0589       0.0982       0.0786        0.688      0.00717\n","     39    10      0.00824       0.0082     3.28e-05       0.0543       0.0701       0.0448       0.0732        0.059       0.0568        0.091       0.0739        0.339      0.00353\n","     39    11      0.00944      0.00936     8.05e-05        0.057       0.0748        0.047       0.0771        0.062       0.0611       0.0966       0.0789         0.65      0.00677\n","     39    12      0.00749      0.00739     9.19e-05       0.0503       0.0665       0.0413       0.0683       0.0548       0.0529       0.0877       0.0703        0.625      0.00651\n","     39    13       0.0101       0.0101     1.46e-05       0.0586       0.0776       0.0493       0.0773       0.0633       0.0635          0.1       0.0818        0.204      0.00213\n","     39    14      0.00927      0.00924     2.64e-05       0.0565       0.0744       0.0456       0.0784        0.062       0.0584       0.0989       0.0786        0.367      0.00383\n","     39    15      0.00955      0.00945     9.25e-05       0.0565       0.0752       0.0448       0.0799       0.0623       0.0579        0.101       0.0796        0.613      0.00638\n","     39    16      0.00927      0.00919     7.59e-05       0.0569       0.0742       0.0485       0.0735        0.061       0.0614       0.0947       0.0781        0.562      0.00585\n","     39    17       0.0122       0.0121     3.77e-05       0.0663       0.0852       0.0577       0.0833       0.0705       0.0732        0.105       0.0892        0.306      0.00318\n","     39    18       0.0105       0.0104     0.000125       0.0591       0.0787       0.0478       0.0816       0.0647       0.0619        0.105       0.0832        0.801      0.00835\n","     39    19      0.00955      0.00938     0.000173       0.0569       0.0749       0.0457       0.0793       0.0625       0.0595       0.0988       0.0792        0.804      0.00838\n","     39    20       0.0101       0.0101     3.48e-05       0.0587       0.0776       0.0479       0.0804       0.0642        0.062        0.102       0.0819        0.398      0.00415\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     39     1       0.0104       0.0104     4.22e-05       0.0597       0.0788       0.0484       0.0824       0.0654        0.063        0.103       0.0832         0.42      0.00437\n","     39     2       0.0102       0.0102     2.47e-05       0.0584       0.0781       0.0468       0.0815       0.0642       0.0613        0.104       0.0825        0.295      0.00307\n","     39     3      0.00928      0.00926     2.71e-05       0.0562       0.0744       0.0453       0.0778       0.0616       0.0584        0.099       0.0787        0.311      0.00324\n","     39     4       0.0101         0.01     5.56e-05       0.0579       0.0774        0.047       0.0796       0.0633        0.061        0.103       0.0818         0.48        0.005\n","     39     5      0.00948      0.00943      4.5e-05       0.0566       0.0751       0.0464        0.077       0.0617       0.0607       0.0977       0.0792          0.4      0.00417\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              39  125.658    0.005      0.00948     7.08e-05      0.00955        0.057       0.0753       0.0468       0.0775       0.0622       0.0605       0.0985       0.0795        0.514      0.00536\n","! Validation         39  125.658    0.005      0.00985     3.89e-05      0.00989       0.0578       0.0768       0.0468       0.0797       0.0632       0.0609        0.101       0.0811        0.381      0.00397\n","Wall time: 125.65914863499984\n","! Best model       39    0.010\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     40     1      0.00986      0.00962     0.000247       0.0586       0.0759       0.0482       0.0793       0.0637       0.0611        0.099       0.0801         1.05       0.0109\n","     40     2      0.00992      0.00985     6.04e-05       0.0584       0.0768        0.049       0.0773       0.0632       0.0626       0.0992       0.0809        0.557       0.0058\n","     40     3       0.0102       0.0101     9.96e-05       0.0583       0.0776       0.0467       0.0814       0.0641       0.0606        0.104       0.0821        0.563      0.00586\n","     40     4       0.0102      0.00999     0.000241       0.0606       0.0773       0.0528       0.0762       0.0645       0.0668       0.0948       0.0808         1.11       0.0115\n","     40     5       0.0155       0.0154     2.35e-05       0.0771       0.0961       0.0714       0.0885         0.08       0.0884         0.11       0.0992        0.326       0.0034\n","     40     6       0.0158       0.0155     0.000267       0.0743       0.0963        0.061        0.101        0.081       0.0786        0.124        0.101         1.18       0.0123\n","     40     7       0.0119       0.0118     0.000167        0.064       0.0839       0.0524       0.0871       0.0698       0.0664        0.111       0.0887        0.835       0.0087\n","     40     8      0.00981      0.00978     3.04e-05       0.0581       0.0765       0.0485       0.0773       0.0629       0.0624       0.0989       0.0806        0.328      0.00342\n","     40     9       0.0105       0.0105     2.87e-05       0.0589       0.0791       0.0472       0.0824       0.0648       0.0617        0.106       0.0837        0.359      0.00374\n","     40    10      0.00992      0.00984     8.06e-05       0.0574       0.0767       0.0457       0.0808       0.0633       0.0603        0.102       0.0811         0.58      0.00604\n","     40    11      0.00984       0.0098     3.47e-05       0.0573       0.0766       0.0459       0.0799       0.0629       0.0602        0.102        0.081        0.371      0.00386\n","     40    12      0.00982      0.00975     6.85e-05       0.0578       0.0764       0.0468       0.0797       0.0633       0.0607        0.101       0.0807         0.45      0.00468\n","     40    13       0.0117       0.0115     0.000187       0.0655        0.083       0.0607       0.0753        0.068       0.0761       0.0952       0.0857        0.982       0.0102\n","     40    14       0.0112       0.0111     2.55e-05       0.0623       0.0816        0.053       0.0808       0.0669       0.0681        0.103       0.0858        0.295      0.00307\n","     40    15       0.0103       0.0103     5.72e-06       0.0588       0.0785       0.0463       0.0839       0.0651       0.0588        0.108       0.0831        0.158      0.00165\n","     40    16      0.00869      0.00861     8.41e-05       0.0547       0.0718       0.0437       0.0767       0.0602       0.0551       0.0968        0.076        0.614      0.00639\n","     40    17        0.009       0.0089     9.82e-05       0.0554        0.073       0.0446       0.0769       0.0608       0.0574       0.0969       0.0772        0.607      0.00632\n","     40    18      0.00954      0.00952     1.94e-05       0.0578       0.0755       0.0471       0.0793       0.0632       0.0609       0.0984       0.0796        0.292      0.00304\n","     40    19      0.00979      0.00966     0.000122       0.0588       0.0761        0.051       0.0744       0.0627       0.0637       0.0961       0.0799        0.698      0.00727\n","     40    20      0.00933      0.00923     9.95e-05       0.0571       0.0743       0.0475       0.0762       0.0619       0.0607       0.0959       0.0783         0.63      0.00656\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     40     1       0.0103       0.0102     4.21e-05       0.0593       0.0783        0.048        0.082        0.065       0.0625        0.103       0.0827        0.418      0.00435\n","     40     2       0.0101         0.01     2.48e-05       0.0579       0.0775       0.0464        0.081       0.0637       0.0608        0.103       0.0819        0.296      0.00308\n","     40     3      0.00918      0.00915     2.74e-05       0.0558        0.074        0.045       0.0774       0.0612        0.058       0.0985       0.0782        0.312      0.00325\n","     40     4      0.00993      0.00987     5.57e-05       0.0575       0.0769       0.0466       0.0793        0.063       0.0604        0.102       0.0813         0.48        0.005\n","     40     5      0.00935       0.0093     4.54e-05       0.0562       0.0746        0.046       0.0766       0.0613       0.0603       0.0972       0.0787        0.402      0.00419\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              40  128.778    0.005       0.0105     9.95e-05       0.0106       0.0606       0.0794       0.0505       0.0807       0.0656        0.065        0.102       0.0836        0.599      0.00624\n","! Validation         40  128.778    0.005      0.00972     3.91e-05      0.00976       0.0574       0.0763       0.0464       0.0793       0.0628       0.0604        0.101       0.0806        0.382      0.00398\n","Wall time: 128.7786955620004\n","! Best model       40    0.010\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     41     1      0.00912      0.00892     0.000197       0.0556       0.0731       0.0446       0.0776       0.0611       0.0569       0.0977       0.0773         1.01       0.0106\n","     41     2      0.00913      0.00901     0.000125       0.0556       0.0734       0.0449       0.0771        0.061       0.0577       0.0975       0.0776        0.777       0.0081\n","     41     3      0.00906      0.00886     0.000204       0.0558       0.0728       0.0459       0.0755       0.0607       0.0581       0.0957       0.0769        0.985       0.0103\n","     41     4       0.0108       0.0107     6.45e-05       0.0635       0.0802       0.0574       0.0757       0.0665       0.0716        0.095       0.0833        0.521      0.00542\n","     41     5       0.0109       0.0109      1.2e-05       0.0626       0.0806       0.0537       0.0805       0.0671       0.0673        0.102       0.0847        0.241      0.00251\n","     41     6      0.00897      0.00887     9.17e-05       0.0546       0.0729       0.0436       0.0767       0.0601       0.0557       0.0987       0.0772        0.608      0.00634\n","     41     7      0.00817      0.00812     4.94e-05       0.0536       0.0697       0.0435       0.0738       0.0587       0.0555       0.0918       0.0736        0.458      0.00477\n","     41     8      0.00899      0.00896     3.47e-05       0.0556       0.0732       0.0472       0.0724       0.0598       0.0604       0.0937       0.0771        0.374      0.00389\n","     41     9      0.00897      0.00891     6.47e-05       0.0553        0.073       0.0462       0.0736       0.0599       0.0591       0.0949        0.077        0.524      0.00546\n","     41    10      0.00943      0.00934     9.23e-05       0.0573       0.0747       0.0487       0.0746       0.0616       0.0624       0.0947       0.0786        0.632      0.00658\n","     41    11      0.00915      0.00905     0.000101       0.0537       0.0736       0.0404       0.0802       0.0603       0.0536        0.102       0.0781        0.647      0.00674\n","     41    12      0.00944      0.00938     6.13e-05       0.0563       0.0749       0.0459       0.0771       0.0615       0.0597       0.0985       0.0791        0.499       0.0052\n","     41    13      0.00881       0.0088     9.26e-06       0.0549       0.0726       0.0447       0.0753         0.06       0.0585       0.0946       0.0766        0.162      0.00169\n","     41    14      0.00905      0.00894      0.00011       0.0549       0.0732       0.0422       0.0801       0.0612       0.0538        0.101       0.0776        0.685      0.00714\n","     41    15      0.00893       0.0089     3.03e-05       0.0561        0.073       0.0462       0.0759        0.061       0.0583       0.0958       0.0771        0.312      0.00325\n","     41    16       0.0135       0.0133     0.000226       0.0676       0.0892       0.0566       0.0897       0.0731        0.074        0.114       0.0938          1.1       0.0115\n","     41    17       0.0125       0.0125      5.4e-05       0.0674       0.0865       0.0574       0.0876       0.0725       0.0729        0.109       0.0908         0.43      0.00448\n","     41    18       0.0106       0.0106     5.88e-05       0.0621       0.0795        0.053       0.0804       0.0667       0.0665        0.101       0.0836        0.544      0.00566\n","     41    19      0.00881      0.00863     0.000179       0.0546       0.0719       0.0435       0.0769       0.0602       0.0555       0.0966       0.0761         0.82      0.00854\n","     41    20      0.00928      0.00908     0.000197       0.0552       0.0737       0.0452       0.0752       0.0602       0.0585       0.0972       0.0779        0.969       0.0101\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     41     1       0.0102       0.0101     4.25e-05        0.059       0.0778       0.0476       0.0816       0.0646        0.062        0.102       0.0822        0.423      0.00441\n","     41     2      0.00995      0.00992     2.47e-05       0.0576       0.0771       0.0461       0.0805       0.0633       0.0603        0.103       0.0815        0.295      0.00307\n","     41     3      0.00908      0.00906      2.7e-05       0.0555       0.0736       0.0447       0.0772       0.0609       0.0575       0.0982       0.0779        0.309      0.00322\n","     41     4      0.00981      0.00975     5.54e-05       0.0571       0.0764       0.0462        0.079       0.0626       0.0599        0.102       0.0808        0.479      0.00499\n","     41     5      0.00923      0.00918      4.5e-05       0.0559       0.0741       0.0457       0.0762        0.061       0.0598       0.0966       0.0782        0.401      0.00417\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              41  131.884    0.005      0.00959     9.81e-05      0.00968       0.0576       0.0757       0.0475       0.0778       0.0627       0.0611       0.0987       0.0799        0.615      0.00641\n","! Validation         41  131.884    0.005      0.00961     3.89e-05      0.00964        0.057       0.0758       0.0461       0.0789       0.0625       0.0599          0.1       0.0801        0.381      0.00397\n","Wall time: 131.88451783399978\n","! Best model       41    0.010\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     42     1       0.0109       0.0105     0.000439       0.0592       0.0792       0.0491       0.0794       0.0642       0.0649        0.102       0.0835         1.53        0.016\n","     42     2      0.00941      0.00927     0.000142       0.0562       0.0745       0.0453        0.078       0.0616       0.0583       0.0992       0.0788        0.799      0.00833\n","     42     3        0.011       0.0106     0.000381       0.0618       0.0798       0.0539       0.0778       0.0658       0.0689        0.098       0.0834         1.42       0.0148\n","     42     4       0.0115       0.0112     0.000208       0.0642        0.082       0.0577       0.0773       0.0675       0.0719       0.0992       0.0856        0.995       0.0104\n","     42     5       0.0115       0.0112     0.000312       0.0623       0.0818       0.0507       0.0853        0.068       0.0651        0.108       0.0864         1.25        0.013\n","     42     6       0.0108       0.0101     0.000663       0.0591       0.0777       0.0485       0.0802       0.0644       0.0624        0.102        0.082         1.87       0.0195\n","     42     7      0.00819      0.00817     1.53e-05       0.0534       0.0699       0.0433       0.0737       0.0585       0.0547       0.0933        0.074        0.262      0.00273\n","     42     8      0.00952      0.00899     0.000533       0.0549       0.0734       0.0436       0.0776       0.0606       0.0556       0.0998       0.0777         1.68       0.0175\n","     42     9      0.00927      0.00884     0.000434       0.0544       0.0727       0.0444       0.0745       0.0594       0.0584       0.0951       0.0767         1.45       0.0151\n","     42    10      0.00825      0.00795     0.000296       0.0522        0.069       0.0418       0.0732       0.0575       0.0534       0.0926        0.073          1.2       0.0125\n","     42    11       0.0089      0.00834     0.000558        0.054       0.0707       0.0443       0.0735       0.0589       0.0558       0.0935       0.0747         1.74       0.0181\n","     42    12      0.00873      0.00866     6.67e-05       0.0539        0.072       0.0423       0.0771       0.0597       0.0549       0.0975       0.0762        0.503      0.00524\n","     42    13      0.00889      0.00835     0.000537       0.0536       0.0707       0.0431       0.0745       0.0588       0.0554       0.0941       0.0748         1.66       0.0173\n","     42    14      0.00901      0.00852     0.000489       0.0537       0.0714       0.0437       0.0739       0.0588       0.0561       0.0949       0.0755         1.64        0.017\n","     42    15      0.00892      0.00879     0.000132       0.0544       0.0725       0.0436       0.0761       0.0598       0.0572       0.0961       0.0767         0.81      0.00843\n","     42    16      0.00868      0.00827     0.000412       0.0535       0.0703       0.0415       0.0777       0.0596       0.0521       0.0971       0.0746         1.49       0.0155\n","     42    17      0.00906      0.00905     1.41e-05       0.0563       0.0736       0.0457       0.0774       0.0615       0.0581       0.0975       0.0778        0.218      0.00227\n","     42    18       0.0115       0.0115     1.07e-05       0.0638       0.0828       0.0543       0.0827       0.0685        0.069        0.105       0.0871        0.187      0.00195\n","     42    19       0.0129       0.0125     0.000452       0.0682       0.0863         0.06       0.0846       0.0723       0.0738        0.107       0.0905         1.54       0.0161\n","     42    20       0.0106       0.0106     6.73e-05       0.0609       0.0796       0.0511       0.0807       0.0659       0.0646        0.103       0.0839        0.477      0.00497\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     42     1         0.01      0.00998     4.22e-05       0.0586       0.0773       0.0473       0.0812       0.0642       0.0615        0.102       0.0816        0.418      0.00436\n","     42     2      0.00982       0.0098     2.49e-05       0.0572       0.0766       0.0457       0.0801       0.0629       0.0598        0.102        0.081        0.297       0.0031\n","     42     3      0.00899      0.00897     2.76e-05       0.0552       0.0733       0.0444       0.0768       0.0606       0.0572       0.0978       0.0775        0.312      0.00325\n","     42     4      0.00969      0.00964     5.57e-05       0.0568       0.0759       0.0459       0.0786       0.0622       0.0594        0.101       0.0803         0.48        0.005\n","     42     5      0.00911      0.00907     4.56e-05       0.0556       0.0737       0.0454       0.0758       0.0606       0.0594        0.096       0.0777        0.403       0.0042\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              42  134.990    0.005      0.00957     0.000308      0.00987       0.0575       0.0757       0.0474       0.0778       0.0626       0.0609       0.0988       0.0798         1.14       0.0118\n","! Validation         42  134.990    0.005      0.00949     3.92e-05      0.00953       0.0567       0.0754       0.0457       0.0785       0.0621       0.0595       0.0998       0.0797        0.382      0.00398\n","Wall time: 134.99078719699992\n","! Best model       42    0.010\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     43     1      0.00882      0.00848     0.000345       0.0533       0.0712       0.0427       0.0745       0.0586       0.0551       0.0956       0.0754         1.33       0.0138\n","     43     2       0.0107       0.0105     0.000196       0.0595       0.0794       0.0498       0.0789       0.0644       0.0658        0.101       0.0835        0.927      0.00966\n","     43     3       0.0128       0.0128     3.12e-05       0.0683       0.0874       0.0588       0.0874       0.0731       0.0738         0.11       0.0917        0.356      0.00371\n","     43     4       0.0142       0.0139     0.000372       0.0713       0.0911       0.0616       0.0906       0.0761       0.0774        0.114       0.0955          1.4       0.0146\n","     43     5       0.0114       0.0114     6.02e-05       0.0638       0.0825       0.0551       0.0811       0.0681       0.0697        0.103       0.0866        0.515      0.00536\n","     43     6      0.00997      0.00986     0.000111       0.0591       0.0768       0.0492       0.0787        0.064       0.0622       0.0999        0.081        0.673      0.00701\n","     43     7      0.00779      0.00773     5.77e-05       0.0514        0.068       0.0417       0.0707       0.0562       0.0527       0.0913        0.072        0.505      0.00526\n","     43     8      0.00874      0.00871      3.7e-05       0.0548       0.0722       0.0447        0.075       0.0598       0.0578       0.0946       0.0762        0.404      0.00421\n","     43     9      0.00883       0.0088     3.56e-05       0.0549       0.0726       0.0446       0.0754         0.06       0.0578       0.0955       0.0766        0.405      0.00422\n","     43    10      0.00879      0.00859     0.000202       0.0543       0.0717       0.0436       0.0757       0.0596       0.0557       0.0959       0.0758        0.845       0.0088\n","     43    11      0.00944      0.00942     2.11e-05       0.0576       0.0751       0.0483       0.0764       0.0623       0.0611       0.0972       0.0791        0.298       0.0031\n","     43    12      0.00856      0.00849      6.9e-05       0.0534       0.0713       0.0438       0.0727       0.0582       0.0562       0.0945       0.0753        0.482      0.00502\n","     43    13      0.00961      0.00946      0.00015       0.0566       0.0752       0.0461       0.0776       0.0619       0.0599        0.099       0.0795        0.826      0.00861\n","     43    14      0.00862      0.00857     4.26e-05       0.0547       0.0716       0.0458       0.0725       0.0592        0.058       0.0931       0.0755        0.435      0.00453\n","     43    15       0.0101       0.0101     1.53e-05       0.0593       0.0777       0.0491       0.0796       0.0643       0.0631        0.101       0.0819        0.263      0.00274\n","     43    16      0.00838      0.00834     4.09e-05       0.0532       0.0707       0.0442       0.0712       0.0577        0.057       0.0921       0.0746        0.369      0.00384\n","     43    17      0.00861      0.00858     2.62e-05       0.0542       0.0717       0.0441       0.0742       0.0592       0.0563       0.0953       0.0758        0.274      0.00285\n","     43    18      0.00835      0.00833     1.78e-05       0.0533       0.0706       0.0423       0.0752       0.0588       0.0541       0.0954       0.0748        0.256      0.00266\n","     43    19      0.00917      0.00913     4.63e-05       0.0562       0.0739       0.0445       0.0796        0.062       0.0563          0.1       0.0783        0.414      0.00431\n","     43    20       0.0092      0.00918     2.96e-05       0.0564       0.0741       0.0453       0.0785       0.0619        0.058       0.0988       0.0784        0.331      0.00345\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     43     1       0.0099      0.00986     4.21e-05       0.0582       0.0768       0.0469       0.0808       0.0638        0.061        0.101       0.0811        0.418      0.00436\n","     43     2      0.00971      0.00969     2.48e-05       0.0568       0.0762       0.0454       0.0797       0.0626       0.0594        0.102       0.0805        0.297      0.00309\n","     43     3       0.0089      0.00887     2.76e-05       0.0549       0.0729       0.0441       0.0765       0.0603       0.0568       0.0974       0.0771        0.312      0.00325\n","     43     4      0.00958      0.00952     5.55e-05       0.0564       0.0755       0.0455       0.0783       0.0619       0.0589        0.101       0.0799         0.48        0.005\n","     43     5        0.009      0.00895     4.56e-05       0.0552       0.0732       0.0451       0.0755       0.0603        0.059       0.0955       0.0772        0.403       0.0042\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              43  138.110    0.005      0.00951     9.53e-05      0.00961       0.0573       0.0755       0.0473       0.0773       0.0623       0.0607       0.0985       0.0796        0.565      0.00589\n","! Validation         43  138.110    0.005      0.00938     3.91e-05      0.00942       0.0563       0.0749       0.0454       0.0782       0.0618        0.059       0.0994       0.0792        0.382      0.00398\n","Wall time: 138.11046300399994\n","! Best model       43    0.009\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     44     1      0.00831       0.0083     1.46e-05       0.0538       0.0705       0.0444       0.0725       0.0585       0.0565       0.0923       0.0744        0.187      0.00195\n","     44     2      0.00968      0.00961      6.4e-05        0.057       0.0759       0.0472       0.0764       0.0618       0.0619       0.0979       0.0799        0.441       0.0046\n","     44     3      0.00936      0.00929     6.99e-05       0.0573       0.0746       0.0474       0.0771       0.0623       0.0603        0.097       0.0787          0.6      0.00625\n","     44     4      0.00871      0.00865     5.42e-05       0.0544        0.072       0.0432       0.0768         0.06       0.0564       0.0958       0.0761         0.48        0.005\n","     44     5      0.00853       0.0084     0.000139       0.0536       0.0709       0.0434       0.0739       0.0587       0.0557       0.0941       0.0749        0.764      0.00796\n","     44     6        0.011        0.011     7.94e-06       0.0623       0.0811       0.0528       0.0813       0.0671        0.068        0.102       0.0852        0.189      0.00197\n","     44     7      0.00964      0.00962     1.96e-05       0.0584       0.0759       0.0489       0.0772       0.0631       0.0623       0.0975       0.0799        0.272      0.00283\n","     44     8      0.00925       0.0092     4.84e-05       0.0574       0.0742       0.0489       0.0742       0.0616       0.0614       0.0947       0.0781        0.465      0.00485\n","     44     9       0.0083      0.00822     7.85e-05       0.0523       0.0702       0.0407       0.0756       0.0581        0.052       0.0967       0.0744        0.572      0.00596\n","     44    10      0.00899      0.00894     5.18e-05       0.0552       0.0731       0.0437       0.0784        0.061       0.0557       0.0992       0.0775        0.511      0.00533\n","     44    11       0.0103       0.0102     5.18e-05       0.0583       0.0781       0.0467       0.0816       0.0641       0.0607        0.105       0.0827        0.508      0.00529\n","     44    12       0.0123       0.0123     5.69e-05       0.0663       0.0857        0.054        0.091       0.0725       0.0678        0.113       0.0905        0.555      0.00578\n","     44    13       0.0118       0.0116     0.000154       0.0648       0.0834       0.0571       0.0802       0.0686       0.0716        0.103       0.0873        0.705      0.00735\n","     44    14       0.0104       0.0103     2.91e-05       0.0606       0.0786       0.0523       0.0772       0.0648       0.0675       0.0971       0.0823        0.327       0.0034\n","     44    15      0.00896      0.00892     3.31e-05       0.0553       0.0731       0.0446       0.0768       0.0607       0.0567        0.098       0.0773        0.354      0.00368\n","     44    16       0.0103       0.0102     2.69e-05       0.0602       0.0783       0.0521       0.0763       0.0642       0.0664        0.098       0.0822        0.345      0.00359\n","     44    17       0.0106       0.0105     6.04e-05       0.0607       0.0794       0.0524       0.0774       0.0649       0.0665          0.1       0.0834        0.493      0.00514\n","     44    18      0.00852       0.0085     1.93e-05       0.0539       0.0713       0.0446       0.0725       0.0586       0.0563       0.0945       0.0754        0.308       0.0032\n","     44    19      0.00832      0.00829     2.81e-05       0.0526       0.0705       0.0418       0.0741       0.0579       0.0536       0.0956       0.0746        0.317       0.0033\n","     44    20       0.0104       0.0104     1.41e-05       0.0591       0.0788       0.0482        0.081       0.0646       0.0629        0.103       0.0832        0.213      0.00222\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     44     1      0.00978      0.00974     4.22e-05       0.0578       0.0763       0.0465       0.0804       0.0635       0.0605        0.101       0.0807        0.419      0.00436\n","     44     2      0.00961      0.00958     2.49e-05       0.0565       0.0757       0.0451       0.0794       0.0622        0.059        0.101       0.0801        0.298       0.0031\n","     44     3      0.00882      0.00879     2.76e-05       0.0546       0.0725       0.0438       0.0763         0.06       0.0564        0.097       0.0767        0.312      0.00325\n","     44     4      0.00948      0.00942     5.55e-05       0.0561       0.0751       0.0451        0.078       0.0616       0.0584          0.1       0.0794        0.479      0.00499\n","     44     5       0.0089      0.00885     4.57e-05        0.055       0.0728       0.0448       0.0752         0.06       0.0586       0.0951       0.0768        0.404      0.00421\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              44  141.266    0.005      0.00963      5.1e-05      0.00968       0.0577       0.0759       0.0477       0.0776       0.0626       0.0613       0.0989       0.0801         0.43      0.00448\n","! Validation         44  141.266    0.005      0.00928     3.92e-05      0.00932        0.056       0.0745       0.0451       0.0779       0.0615       0.0586        0.099       0.0788        0.383      0.00398\n","Wall time: 141.26694867900005\n","! Best model       44    0.009\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     45     1      0.00966      0.00963        3e-05       0.0584       0.0759       0.0491        0.077       0.0631       0.0619       0.0982         0.08        0.358      0.00373\n","     45     2      0.00999      0.00997     2.27e-05       0.0593       0.0772         0.05       0.0779        0.064        0.064       0.0986       0.0813        0.301      0.00314\n","     45     3      0.00878      0.00875     3.16e-05       0.0544       0.0724       0.0447       0.0739       0.0593       0.0569       0.0961       0.0765         0.37      0.00386\n","     45     4       0.0115       0.0115     4.22e-05       0.0635       0.0828       0.0552       0.0802       0.0677       0.0706        0.103       0.0868        0.462      0.00481\n","     45     5       0.0155       0.0155     5.33e-05       0.0766       0.0963       0.0694        0.091       0.0802       0.0856        0.115          0.1        0.486      0.00506\n","     45     6       0.0126       0.0126     3.07e-05       0.0666       0.0867       0.0558       0.0881        0.072       0.0705        0.112       0.0914        0.358      0.00373\n","     45     7      0.00821      0.00818     3.15e-05       0.0534         0.07       0.0423       0.0757        0.059       0.0538       0.0944       0.0741        0.378      0.00394\n","     45     8       0.0076      0.00751     8.65e-05       0.0504       0.0671         0.04       0.0711       0.0555       0.0506       0.0915        0.071        0.614       0.0064\n","     45     9       0.0102       0.0101     5.36e-05       0.0595       0.0779       0.0492         0.08       0.0646       0.0624        0.102       0.0822         0.46      0.00479\n","     45    10       0.0108       0.0107     8.42e-05       0.0616         0.08       0.0517       0.0813       0.0665       0.0657        0.103       0.0843        0.551      0.00574\n","     45    11       0.0105       0.0104     3.34e-05       0.0612        0.079       0.0525       0.0785       0.0655       0.0672       0.0985       0.0828         0.37      0.00386\n","     45    12      0.00847      0.00836     0.000108       0.0535       0.0707       0.0413       0.0778       0.0596       0.0532       0.0967       0.0749        0.699      0.00728\n","     45    13      0.00898      0.00893     4.44e-05       0.0553       0.0731       0.0442       0.0775       0.0608       0.0582       0.0963       0.0772        0.361      0.00376\n","     45    14       0.0096      0.00957     2.87e-05        0.057       0.0757       0.0464       0.0782       0.0623       0.0594        0.101         0.08        0.352      0.00367\n","     45    15      0.00874       0.0086     0.000146       0.0543       0.0717       0.0434       0.0761       0.0597       0.0559       0.0959       0.0759        0.859      0.00895\n","     45    16       0.0103       0.0103     5.96e-05       0.0581       0.0784       0.0458       0.0828       0.0643       0.0605        0.105       0.0829        0.532      0.00554\n","     45    17      0.00951      0.00894     0.000571        0.056       0.0732        0.046       0.0761        0.061       0.0573       0.0974       0.0774         1.74       0.0181\n","     45    18       0.0112       0.0111     9.18e-05       0.0629       0.0814       0.0572       0.0744       0.0658       0.0728       0.0964       0.0846        0.536      0.00559\n","     45    19      0.00929      0.00909     0.000199       0.0561       0.0738       0.0459       0.0767       0.0613       0.0588        0.097       0.0779         1.02       0.0106\n","     45    20       0.0102      0.00978      0.00044       0.0587       0.0765       0.0488       0.0785       0.0637       0.0628       0.0984       0.0806         1.54        0.016\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     45     1      0.00967      0.00963     4.25e-05       0.0575       0.0759       0.0462       0.0801       0.0632         0.06          0.1       0.0802        0.423      0.00441\n","     45     2      0.00952      0.00949     2.47e-05       0.0562       0.0754       0.0448        0.079       0.0619       0.0586        0.101       0.0797        0.297      0.00309\n","     45     3      0.00874      0.00872     2.72e-05       0.0544       0.0722       0.0435        0.076       0.0598       0.0561       0.0967       0.0764        0.309      0.00322\n","     45     4      0.00938      0.00932     5.51e-05       0.0558       0.0747       0.0448       0.0778       0.0613        0.058          0.1        0.079        0.477      0.00497\n","     45     5      0.00879      0.00875     4.54e-05       0.0546       0.0724       0.0445       0.0749       0.0597       0.0581       0.0946       0.0764        0.404       0.0042\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              45  144.425    0.005      0.00997     0.000109       0.0101       0.0588       0.0773       0.0489       0.0786       0.0638       0.0629          0.1       0.0814        0.617      0.00643\n","! Validation         45  144.425    0.005      0.00918      3.9e-05      0.00922       0.0557       0.0741       0.0448       0.0776       0.0612       0.0582       0.0986       0.0784        0.382      0.00398\n","Wall time: 144.42539060800027\n","! Best model       45    0.009\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     46     1      0.00866      0.00849     0.000173       0.0536       0.0713       0.0429       0.0749       0.0589       0.0554       0.0954       0.0754        0.911      0.00949\n","     46     2       0.0122       0.0118     0.000356       0.0638       0.0841       0.0523        0.087       0.0696       0.0666        0.111       0.0888         1.39       0.0145\n","     46     3       0.0106       0.0106     1.28e-05       0.0612       0.0798       0.0518       0.0798       0.0658       0.0669        0.101       0.0838        0.237      0.00247\n","     46     4       0.0091      0.00905     4.79e-05       0.0573       0.0736       0.0501       0.0716       0.0609       0.0628       0.0915       0.0771        0.422       0.0044\n","     46     5      0.00905      0.00884     0.000218       0.0556       0.0727        0.044       0.0788       0.0614       0.0557       0.0983        0.077         1.03       0.0108\n","     46     6      0.00795       0.0079     4.89e-05       0.0532       0.0688       0.0429       0.0737       0.0583       0.0542       0.0912       0.0727        0.453      0.00472\n","     46     7      0.00902      0.00897     4.97e-05       0.0555       0.0733       0.0452       0.0762       0.0607       0.0583       0.0964       0.0774        0.346       0.0036\n","     46     8      0.00943      0.00939     3.71e-05       0.0567        0.075       0.0465       0.0769       0.0617         0.06       0.0983       0.0791        0.419      0.00437\n","     46     9      0.00925       0.0092     5.35e-05       0.0579       0.0742       0.0495       0.0747       0.0621       0.0628       0.0929       0.0778        0.507      0.00528\n","     46    10       0.0101      0.00998     9.57e-05       0.0585       0.0773       0.0484       0.0785       0.0635       0.0625          0.1       0.0815        0.688      0.00717\n","     46    11      0.00788      0.00786     2.21e-05       0.0519       0.0686       0.0394       0.0769       0.0581       0.0501       0.0954       0.0727         0.25      0.00261\n","     46    12      0.00726      0.00719     7.34e-05       0.0486       0.0656       0.0387       0.0684       0.0535       0.0494       0.0896       0.0695        0.604      0.00629\n","     46    13      0.00994      0.00992     1.88e-05       0.0577        0.077       0.0458       0.0817       0.0637       0.0591        0.104       0.0816        0.279      0.00291\n","     46    14      0.00721      0.00715     6.47e-05       0.0501       0.0654       0.0407       0.0691       0.0549       0.0516       0.0866       0.0691        0.577      0.00601\n","     46    15      0.00951      0.00931     0.000195       0.0571       0.0747       0.0482       0.0748       0.0615       0.0624       0.0946       0.0785        0.969       0.0101\n","     46    16      0.00865      0.00864     1.34e-05       0.0543       0.0719       0.0445       0.0741       0.0593       0.0561       0.0959        0.076         0.18      0.00187\n","     46    17      0.00949      0.00937     0.000115       0.0572       0.0749       0.0473       0.0768       0.0621       0.0607       0.0973        0.079         0.69      0.00719\n","     46    18      0.00982      0.00979     2.74e-05       0.0583       0.0766        0.047        0.081        0.064       0.0605        0.101       0.0809        0.331      0.00345\n","     46    19      0.00962      0.00957     5.06e-05        0.057       0.0757       0.0454       0.0802       0.0628       0.0584        0.102       0.0801        0.456      0.00475\n","     46    20      0.00853      0.00851     1.95e-05        0.054       0.0714       0.0434       0.0753       0.0593       0.0562       0.0947       0.0754        0.304      0.00317\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     46     1      0.00956      0.00952     4.22e-05       0.0572       0.0755       0.0459       0.0798       0.0628       0.0596          0.1       0.0798        0.419      0.00436\n","     46     2      0.00944      0.00941     2.49e-05       0.0559       0.0751       0.0445       0.0788       0.0616       0.0582        0.101       0.0794        0.299      0.00311\n","     46     3      0.00867      0.00865     2.77e-05       0.0541       0.0719       0.0433       0.0758       0.0595       0.0557       0.0965       0.0761        0.312      0.00325\n","     46     4      0.00929      0.00923     5.54e-05       0.0555       0.0743       0.0445       0.0775        0.061       0.0576       0.0997       0.0787        0.479      0.00499\n","     46     5       0.0087      0.00865     4.58e-05       0.0543        0.072       0.0442       0.0746       0.0594       0.0577       0.0942        0.076        0.405      0.00422\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              46  147.570    0.005      0.00908     8.47e-05      0.00916        0.056       0.0737       0.0457       0.0765       0.0611       0.0587        0.097       0.0778        0.552      0.00575\n","! Validation         46  147.570    0.005      0.00909     3.92e-05      0.00913       0.0554       0.0738       0.0445       0.0773       0.0609       0.0578       0.0982        0.078        0.383      0.00399\n","Wall time: 147.5703935600004\n","! Best model       46    0.009\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     47     1       0.0101       0.0101     7.78e-06       0.0574       0.0777       0.0458       0.0804       0.0631       0.0602        0.104       0.0822        0.191      0.00198\n","     47     2       0.0109       0.0107     0.000177       0.0617       0.0799       0.0532       0.0787        0.066       0.0671        0.101        0.084         0.91      0.00947\n","     47     3      0.00874       0.0087     3.79e-05       0.0555       0.0722       0.0458       0.0749       0.0604       0.0584       0.0939       0.0761        0.426      0.00443\n","     47     4      0.00877      0.00864     0.000131       0.0545       0.0719       0.0444       0.0747       0.0595       0.0567       0.0953        0.076        0.739       0.0077\n","     47     5      0.00978       0.0096     0.000181       0.0577       0.0758       0.0452       0.0828        0.064       0.0566        0.104       0.0803        0.963         0.01\n","     47     6       0.0107       0.0106     3.25e-05       0.0602       0.0798        0.048       0.0847       0.0664       0.0622        0.107       0.0844        0.409      0.00426\n","     47     7      0.00997      0.00956       0.0004       0.0593       0.0757       0.0521       0.0735       0.0628       0.0654       0.0928       0.0791         1.46       0.0152\n","     47     8      0.00761      0.00752     9.07e-05       0.0512       0.0671       0.0421       0.0695       0.0558       0.0536       0.0881       0.0709        0.563      0.00586\n","     47     9      0.00904       0.0089     0.000131       0.0549        0.073       0.0455       0.0738       0.0597       0.0576       0.0967       0.0772        0.758       0.0079\n","     47    10       0.0121       0.0119      0.00012       0.0654       0.0845       0.0558       0.0846       0.0702       0.0702        0.108       0.0889        0.799      0.00832\n","     47    11       0.0107       0.0106     4.88e-05       0.0618       0.0797       0.0524       0.0807       0.0665       0.0664        0.101       0.0838        0.473      0.00493\n","     47    12      0.00895       0.0088     0.000153       0.0551       0.0726       0.0434       0.0786        0.061       0.0568       0.0966       0.0767        0.845      0.00881\n","     47    13      0.00952       0.0093     0.000224        0.058       0.0746       0.0497       0.0747       0.0622       0.0634        0.093       0.0782        0.936      0.00975\n","     47    14       0.0116       0.0115     8.23e-05       0.0641        0.083       0.0548       0.0827       0.0688       0.0695        0.105       0.0873        0.548      0.00571\n","     47    15       0.0116       0.0115     0.000194       0.0647       0.0828        0.055       0.0841       0.0696       0.0687        0.105       0.0871         1.01       0.0105\n","     47    16      0.00934      0.00931     2.88e-05       0.0564       0.0746       0.0442       0.0808       0.0625       0.0566        0.102       0.0791        0.343      0.00358\n","     47    17      0.00841      0.00837     4.35e-05       0.0537       0.0708       0.0423       0.0764       0.0594       0.0551       0.0947       0.0749        0.427      0.00444\n","     47    18       0.0123       0.0122     5.39e-05       0.0661       0.0855       0.0575       0.0832       0.0704       0.0722        0.107       0.0898        0.496      0.00517\n","     47    19       0.0139       0.0138     5.56e-05       0.0724        0.091        0.066       0.0853       0.0757       0.0806        0.109       0.0947        0.447      0.00465\n","     47    20      0.00865      0.00856     8.27e-05       0.0557       0.0716        0.048       0.0713       0.0596       0.0604       0.0898       0.0751        0.602      0.00628\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     47     1      0.00946      0.00942     4.25e-05       0.0569       0.0751       0.0456       0.0794       0.0625       0.0591       0.0995       0.0793        0.422      0.00439\n","     47     2      0.00933      0.00931     2.49e-05       0.0556       0.0746       0.0442       0.0784       0.0613       0.0578          0.1        0.079        0.298      0.00311\n","     47     3      0.00859      0.00856     2.76e-05       0.0538       0.0716        0.043       0.0755       0.0593       0.0554       0.0961       0.0758        0.311      0.00324\n","     47     4      0.00919      0.00914     5.52e-05       0.0552        0.074       0.0441       0.0772       0.0607       0.0571       0.0994       0.0783        0.478      0.00498\n","     47     5      0.00862      0.00857     4.58e-05       0.0541       0.0716        0.044       0.0743       0.0591       0.0574       0.0938       0.0756        0.406      0.00423\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              47  150.691    0.005         0.01     0.000114       0.0101       0.0593       0.0774       0.0496       0.0788       0.0642       0.0633       0.0999       0.0816        0.667      0.00695\n","! Validation         47  150.691    0.005        0.009     3.92e-05      0.00904       0.0551       0.0734       0.0442        0.077       0.0606       0.0574       0.0978       0.0776        0.383      0.00399\n","Wall time: 150.6915105830003\n","! Best model       47    0.009\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     48     1      0.00896      0.00884     0.000111       0.0554       0.0728       0.0459       0.0745       0.0602       0.0582       0.0954       0.0768        0.702      0.00732\n","     48     2       0.0143       0.0142     0.000113       0.0735       0.0922       0.0661       0.0883       0.0772       0.0819         0.11       0.0959        0.636      0.00662\n","     48     3       0.0133       0.0133     1.66e-05       0.0698       0.0892       0.0637       0.0822       0.0729       0.0795        0.106       0.0927        0.236      0.00246\n","     48     4      0.00954      0.00946     8.23e-05       0.0553       0.0753       0.0437       0.0784       0.0611       0.0585        0.101       0.0796        0.563      0.00587\n","     48     5      0.00899      0.00888     0.000113       0.0552       0.0729       0.0452       0.0753       0.0602       0.0573       0.0969       0.0771        0.783      0.00815\n","     48     6       0.0113       0.0113     1.22e-05       0.0635       0.0823       0.0538        0.083       0.0684       0.0681        0.105       0.0866        0.187      0.00195\n","     48     7      0.00918      0.00913     4.77e-05        0.056       0.0739       0.0471        0.074       0.0605       0.0602       0.0957       0.0779         0.43      0.00448\n","     48     8      0.00791      0.00777     0.000139       0.0516       0.0682       0.0408       0.0731       0.0569       0.0524        0.092       0.0722        0.815      0.00849\n","     48     9      0.00915      0.00912      2.6e-05       0.0567       0.0739       0.0474       0.0753       0.0613       0.0604       0.0954       0.0779        0.315      0.00328\n","     48    10      0.00993      0.00987     5.31e-05       0.0596       0.0769       0.0511       0.0765       0.0638       0.0648       0.0966       0.0807        0.398      0.00414\n","     48    11       0.0085      0.00843     7.24e-05       0.0537        0.071       0.0435        0.074       0.0588       0.0561        0.094        0.075        0.529      0.00551\n","     48    12      0.00861      0.00859      1.9e-05       0.0549       0.0717       0.0442       0.0762       0.0602       0.0556       0.0962       0.0759        0.242      0.00252\n","     48    13      0.00843      0.00843     6.33e-06       0.0542        0.071       0.0432       0.0762       0.0597       0.0553        0.095       0.0751        0.136      0.00142\n","     48    14      0.00968      0.00958     0.000101       0.0568       0.0757       0.0444       0.0814       0.0629       0.0591        0.101       0.0801        0.708      0.00737\n","     48    15       0.0089      0.00886     4.21e-05       0.0553       0.0728       0.0454       0.0752       0.0603       0.0583       0.0955       0.0769        0.393      0.00409\n","     48    16      0.00864      0.00858     5.67e-05       0.0547       0.0717       0.0435        0.077       0.0603       0.0555       0.0961       0.0758        0.455      0.00474\n","     48    17      0.00796       0.0079     6.29e-05       0.0524       0.0687       0.0425       0.0723       0.0574       0.0544       0.0909       0.0726        0.528       0.0055\n","     48    18      0.00844       0.0084     3.74e-05       0.0544       0.0709       0.0434       0.0762       0.0598       0.0554       0.0946        0.075        0.351      0.00366\n","     48    19       0.0084      0.00821     0.000191       0.0528       0.0701       0.0426        0.073       0.0578       0.0544       0.0939       0.0742        0.971       0.0101\n","     48    20      0.00836       0.0083     5.75e-05       0.0523       0.0705       0.0416       0.0738       0.0577       0.0544       0.0948       0.0746         0.48        0.005\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     48     1      0.00938      0.00933     4.25e-05       0.0566       0.0747       0.0453       0.0791       0.0622       0.0588       0.0992        0.079        0.423       0.0044\n","     48     2      0.00926      0.00924     2.47e-05       0.0554       0.0743        0.044       0.0781       0.0611       0.0575       0.0998       0.0787        0.297       0.0031\n","     48     3      0.00852       0.0085     2.73e-05       0.0536       0.0713       0.0427       0.0753        0.059       0.0551       0.0958       0.0755        0.309      0.00322\n","     48     4      0.00911      0.00905     5.49e-05       0.0549       0.0736       0.0439       0.0769       0.0604       0.0568       0.0991       0.0779        0.477      0.00496\n","     48     5      0.00852      0.00847     4.54e-05       0.0538       0.0712       0.0437        0.074       0.0588        0.057       0.0934       0.0752        0.404      0.00421\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              48  153.798    0.005      0.00936      6.8e-05      0.00943       0.0569       0.0748        0.047       0.0768       0.0619       0.0605       0.0974       0.0789        0.493      0.00513\n","! Validation         48  153.798    0.005      0.00892      3.9e-05      0.00896       0.0548       0.0731       0.0439       0.0767       0.0603       0.0571       0.0975       0.0773        0.382      0.00398\n","Wall time: 153.79912901399985\n","! Best model       48    0.009\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     49     1       0.0083      0.00825     4.96e-05        0.053       0.0703        0.044       0.0711       0.0576        0.056       0.0924       0.0742        0.505      0.00526\n","     49     2      0.00827      0.00823     4.81e-05       0.0527       0.0702       0.0426       0.0728       0.0577       0.0553        0.093       0.0742        0.426      0.00444\n","     49     3      0.00822      0.00812     9.83e-05       0.0525       0.0697       0.0422       0.0733       0.0577       0.0545       0.0929       0.0737        0.669      0.00696\n","     49     4      0.00934       0.0092     0.000137       0.0558       0.0742       0.0451       0.0772       0.0612       0.0591       0.0976       0.0784        0.769      0.00801\n","     49     5       0.0109       0.0107     0.000239       0.0619         0.08       0.0526       0.0805       0.0665       0.0663        0.102       0.0841         1.09       0.0113\n","     49     6       0.0111       0.0109     0.000134       0.0625       0.0809       0.0535       0.0805        0.067       0.0685        0.101       0.0848        0.844      0.00879\n","     49     7      0.00806      0.00804      2.2e-05       0.0529       0.0694       0.0426       0.0736       0.0581       0.0541       0.0926       0.0734        0.338      0.00352\n","     49     8      0.00971      0.00937      0.00034       0.0575       0.0749       0.0476       0.0772       0.0624       0.0597       0.0985       0.0791         1.27       0.0132\n","     49     9      0.00986      0.00966     0.000204       0.0607        0.076       0.0554       0.0713       0.0634       0.0677       0.0904        0.079        0.947      0.00987\n","     49    10      0.00819      0.00802     0.000175       0.0528       0.0693       0.0427       0.0729       0.0578       0.0545        0.092       0.0732         0.94       0.0098\n","     49    11      0.00928      0.00912      0.00016       0.0555       0.0739       0.0466       0.0733         0.06       0.0603       0.0954       0.0778        0.926      0.00965\n","     49    12       0.0115       0.0114     2.67e-05       0.0645       0.0827       0.0554       0.0829       0.0691       0.0691        0.105        0.087        0.298      0.00311\n","     49    13       0.0145       0.0143     0.000209       0.0714       0.0924       0.0585       0.0972       0.0778       0.0733        0.122       0.0976        0.915      0.00953\n","     49    14       0.0108       0.0108     6.53e-05       0.0618       0.0803       0.0507       0.0839       0.0673       0.0637        0.106       0.0848        0.533      0.00555\n","     49    15      0.00838      0.00822     0.000159       0.0543       0.0701       0.0448       0.0733        0.059       0.0565       0.0916        0.074         0.84      0.00874\n","     49    16       0.0108       0.0104     0.000461       0.0592       0.0788       0.0503        0.077       0.0636        0.066       0.0995       0.0828         1.53       0.0159\n","     49    17       0.0131       0.0131     3.95e-05       0.0699       0.0885       0.0641       0.0814       0.0728       0.0804        0.103       0.0916        0.348      0.00362\n","     49    18      0.00976      0.00923     0.000531       0.0569       0.0743       0.0465       0.0779       0.0622       0.0587       0.0984       0.0785         1.69       0.0176\n","     49    19      0.00766      0.00743     0.000226       0.0503       0.0667         0.04       0.0708       0.0554       0.0498       0.0916       0.0707         1.05       0.0109\n","     49    20        0.009      0.00883     0.000166       0.0553       0.0727       0.0441       0.0776       0.0609       0.0566       0.0973       0.0769        0.799      0.00833\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     49     1      0.00928      0.00924     4.26e-05       0.0563       0.0744        0.045       0.0788       0.0619       0.0584       0.0988       0.0786        0.425      0.00443\n","     49     2      0.00917      0.00915     2.46e-05       0.0551        0.074       0.0438       0.0779       0.0608       0.0571       0.0995       0.0783        0.297      0.00309\n","     49     3      0.00846      0.00844     2.72e-05       0.0534       0.0711       0.0425       0.0751       0.0588       0.0548       0.0956       0.0752        0.307       0.0032\n","     49     4      0.00903      0.00897     5.48e-05       0.0546       0.0733       0.0436       0.0767       0.0601       0.0564       0.0987       0.0776        0.476      0.00496\n","     49     5      0.00843      0.00839     4.52e-05       0.0535       0.0709       0.0434       0.0737       0.0586       0.0566        0.093       0.0748        0.404      0.00421\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              49  156.893    0.005      0.00966     0.000175      0.00984       0.0581        0.076       0.0485       0.0773       0.0629        0.062       0.0983       0.0802        0.836      0.00871\n","! Validation         49  156.893    0.005      0.00884     3.89e-05      0.00888       0.0546       0.0727       0.0437       0.0764         0.06       0.0567       0.0972       0.0769        0.382      0.00398\n","Wall time: 156.89395007799976\n","! Best model       49    0.009\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     50     1      0.00937       0.0086     0.000769       0.0539       0.0717       0.0433       0.0751       0.0592       0.0547       0.0972        0.076         2.06       0.0214\n","     50     2      0.00804      0.00796     7.92e-05       0.0522        0.069       0.0427       0.0713        0.057        0.054        0.092        0.073        0.649      0.00676\n","     50     3      0.00858      0.00823     0.000351       0.0527       0.0702       0.0422       0.0737       0.0579       0.0554        0.093       0.0742         1.35       0.0141\n","     50     4      0.00833      0.00791     0.000418       0.0524       0.0688       0.0416        0.074       0.0578       0.0522       0.0936       0.0729         1.48       0.0154\n","     50     5      0.00771      0.00759     0.000126       0.0513       0.0674       0.0419       0.0701        0.056        0.053       0.0895       0.0712        0.727      0.00757\n","     50     6      0.00803      0.00749     0.000536       0.0512        0.067       0.0411       0.0715       0.0563       0.0516       0.0902       0.0709         1.68       0.0175\n","     50     7       0.0092      0.00912     7.55e-05       0.0571       0.0739       0.0501       0.0712       0.0607       0.0633       0.0915       0.0774        0.591      0.00615\n","     50     8      0.00975      0.00951     0.000234       0.0572       0.0755       0.0481       0.0755       0.0618       0.0627        0.096       0.0794         1.08       0.0113\n","     50     9      0.00851        0.008     0.000516        0.053       0.0692       0.0432       0.0728        0.058        0.055       0.0912       0.0731         1.66       0.0173\n","     50    10       0.0107       0.0106     0.000156       0.0614       0.0796        0.052       0.0802       0.0661       0.0664        0.101       0.0836        0.805      0.00839\n","     50    11       0.0116       0.0111     0.000456        0.063       0.0815       0.0527       0.0836       0.0681       0.0663        0.106       0.0859         1.58       0.0164\n","     50    12      0.00784      0.00781     3.01e-05        0.051       0.0684       0.0403       0.0724       0.0564       0.0529       0.0918       0.0724        0.318      0.00331\n","     50    13      0.00928       0.0091     0.000184       0.0558       0.0738       0.0447       0.0779       0.0613       0.0571       0.0991       0.0781         0.93      0.00968\n","     50    14      0.00798       0.0077     0.000277       0.0524       0.0679       0.0431       0.0709        0.057       0.0546       0.0887       0.0717         1.21       0.0126\n","     50    15      0.00951      0.00946     5.24e-05        0.056       0.0752       0.0436       0.0809       0.0622        0.058        0.101       0.0796        0.397      0.00414\n","     50    16      0.00885      0.00855     0.000301       0.0538       0.0716       0.0426       0.0762       0.0594       0.0557       0.0956       0.0757         1.25        0.013\n","     50    17       0.0105       0.0104     2.19e-05       0.0602       0.0791       0.0487       0.0833        0.066       0.0611        0.106       0.0837        0.252      0.00263\n","     50    18      0.00967      0.00959     8.28e-05       0.0577       0.0757        0.045        0.083        0.064       0.0572        0.103       0.0802        0.643      0.00669\n","     50    19      0.00773      0.00752     0.000214       0.0504       0.0671       0.0403       0.0707       0.0555       0.0518       0.0902        0.071        0.971       0.0101\n","     50    20       0.0104       0.0103     2.89e-05       0.0588       0.0786       0.0465       0.0834       0.0649       0.0607        0.106       0.0832        0.395      0.00411\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     50     1      0.00919      0.00915     4.23e-05        0.056        0.074       0.0447       0.0785       0.0616        0.058       0.0984       0.0782        0.422      0.00439\n","     50     2       0.0091      0.00907     2.46e-05       0.0549       0.0737       0.0435       0.0776       0.0606       0.0568       0.0992        0.078        0.297       0.0031\n","     50     3      0.00841      0.00838     2.74e-05       0.0532       0.0708       0.0423       0.0749       0.0586       0.0545       0.0954        0.075        0.309      0.00322\n","     50     4      0.00894      0.00889     5.48e-05       0.0543       0.0729       0.0433       0.0764       0.0599        0.056       0.0984       0.0772        0.476      0.00496\n","     50     5      0.00836      0.00831     4.54e-05       0.0533       0.0705       0.0432       0.0735       0.0583       0.0563       0.0926       0.0745        0.405      0.00421\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              50  159.992    0.005      0.00883     0.000245      0.00908       0.0551       0.0727       0.0447       0.0759       0.0603       0.0574       0.0963       0.0768            1       0.0104\n","! Validation         50  159.992    0.005      0.00876     3.89e-05       0.0088       0.0543       0.0724       0.0434       0.0762       0.0598       0.0564       0.0968       0.0766        0.382      0.00398\n","Wall time: 159.99235773700002\n","! Best model       50    0.009\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     51     1       0.0121       0.0117     0.000452       0.0655       0.0835       0.0567       0.0831       0.0699       0.0728        0.102       0.0872          1.5       0.0156\n","     51     2      0.00912      0.00909     3.12e-05        0.057       0.0738       0.0478       0.0754       0.0616       0.0595       0.0962       0.0778        0.376      0.00392\n","     51     3       0.0082      0.00817     3.17e-05       0.0525       0.0699       0.0411       0.0752       0.0582        0.052       0.0962       0.0741        0.305      0.00318\n","     51     4       0.0109       0.0108     0.000104       0.0617       0.0805       0.0504       0.0843       0.0674        0.064        0.106       0.0851        0.647      0.00674\n","     51     5       0.0137       0.0136     0.000107       0.0704       0.0903       0.0619       0.0874       0.0747        0.077        0.112       0.0947        0.689      0.00717\n","     51     6       0.0105       0.0104     0.000138       0.0611       0.0788       0.0534       0.0766        0.065       0.0681       0.0968       0.0824        0.739      0.00769\n","     51     7       0.0079      0.00777     0.000127       0.0509       0.0682         0.04       0.0727       0.0563       0.0515        0.093       0.0723        0.792      0.00825\n","     51     8      0.00947      0.00939     8.32e-05       0.0579        0.075       0.0488       0.0762       0.0625       0.0623       0.0953       0.0788        0.583      0.00607\n","     51     9      0.00942      0.00935     6.81e-05       0.0583       0.0748       0.0496       0.0759       0.0627       0.0626       0.0946       0.0786        0.512      0.00533\n","     51    10      0.00868      0.00867     1.14e-05       0.0549        0.072       0.0443       0.0761       0.0602       0.0569       0.0954       0.0761        0.206      0.00215\n","     51    11      0.00883      0.00869     0.000136       0.0552       0.0721       0.0438        0.078       0.0609       0.0555       0.0972       0.0764        0.831      0.00865\n","     51    12      0.00847      0.00844     2.88e-05       0.0534       0.0711       0.0423       0.0757        0.059       0.0538       0.0968       0.0753        0.358      0.00373\n","     51    13      0.00813      0.00801     0.000123        0.052       0.0692       0.0417       0.0725       0.0571        0.054       0.0925       0.0732          0.7       0.0073\n","     51    14      0.00919      0.00916     2.78e-05       0.0558       0.0741       0.0455       0.0762       0.0609        0.059       0.0974       0.0782        0.326       0.0034\n","     51    15      0.00897      0.00894     3.05e-05        0.055       0.0731       0.0433       0.0784       0.0608       0.0556       0.0994       0.0775        0.332      0.00346\n","     51    16       0.0087      0.00857     0.000124       0.0543       0.0716       0.0442       0.0745       0.0593       0.0558       0.0958       0.0758        0.715      0.00745\n","     51    17      0.00699      0.00696     3.29e-05       0.0505       0.0645       0.0428       0.0659       0.0544       0.0536       0.0821       0.0679        0.386      0.00402\n","     51    18      0.00765      0.00762     2.76e-05       0.0513       0.0675       0.0413       0.0713       0.0563       0.0522       0.0908       0.0715        0.358      0.00373\n","     51    19       0.0107       0.0106     8.07e-06       0.0596       0.0798       0.0469       0.0848       0.0659       0.0615        0.107       0.0845         0.16      0.00166\n","     51    20      0.00943      0.00933       0.0001        0.058       0.0747         0.05       0.0742       0.0621       0.0639       0.0927       0.0783        0.621      0.00647\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     51     1      0.00911      0.00907      4.2e-05       0.0557       0.0737       0.0444       0.0782       0.0613       0.0577       0.0981       0.0779        0.415      0.00433\n","     51     2      0.00902        0.009     2.48e-05       0.0547       0.0734       0.0433       0.0774       0.0604       0.0565       0.0989       0.0777          0.3      0.00312\n","     51     3      0.00835      0.00832     2.81e-05        0.053       0.0706       0.0421       0.0747       0.0584       0.0543       0.0951       0.0747        0.314      0.00327\n","     51     4      0.00887      0.00881     5.51e-05       0.0541       0.0726        0.043       0.0762       0.0596       0.0557       0.0981       0.0769        0.478      0.00498\n","     51     5      0.00828      0.00824     4.62e-05        0.053       0.0702       0.0429       0.0732       0.0581        0.056       0.0923       0.0742        0.408      0.00425\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              51  163.084    0.005      0.00927     8.96e-05      0.00936       0.0568       0.0745       0.0468       0.0767       0.0618         0.06       0.0972       0.0786        0.557       0.0058\n","! Validation         51  163.084    0.005      0.00869     3.93e-05      0.00873       0.0541       0.0721       0.0432       0.0759       0.0596        0.056       0.0965       0.0763        0.383      0.00399\n","Wall time: 163.08479708400046\n","! Best model       51    0.009\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     52     1      0.00771      0.00769     2.34e-05       0.0507       0.0678       0.0397       0.0728       0.0562       0.0507        0.093       0.0719        0.277      0.00288\n","     52     2      0.00978      0.00962     0.000163       0.0595       0.0759       0.0523       0.0739       0.0631        0.065       0.0939       0.0795        0.862      0.00897\n","     52     3      0.00837      0.00833     3.93e-05       0.0536       0.0706       0.0444        0.072       0.0582       0.0571       0.0919       0.0745        0.354      0.00369\n","     52     4       0.0083      0.00827     2.19e-05       0.0534       0.0704       0.0416        0.077       0.0593       0.0536       0.0955       0.0745        0.309      0.00322\n","     52     5      0.00772      0.00767      4.9e-05       0.0513       0.0678       0.0407       0.0725       0.0566       0.0526       0.0908       0.0717        0.402      0.00419\n","     52     6      0.00936      0.00929     6.57e-05       0.0571       0.0746       0.0471       0.0771       0.0621       0.0606       0.0966       0.0786        0.516      0.00538\n","     52     7      0.00819      0.00816     2.95e-05       0.0534       0.0699       0.0423       0.0756       0.0589       0.0533       0.0947        0.074        0.359      0.00373\n","     52     8         0.01      0.00985     0.000169        0.058       0.0768        0.048       0.0781        0.063       0.0623       0.0997        0.081        0.905      0.00943\n","     52     9      0.00768      0.00764     3.52e-05        0.051       0.0676       0.0412       0.0706       0.0559       0.0529       0.0901       0.0715        0.433      0.00451\n","     52    10      0.00915        0.009     0.000151       0.0563       0.0734       0.0473       0.0743       0.0608       0.0598       0.0949       0.0774        0.754      0.00786\n","     52    11      0.00872      0.00868     4.04e-05       0.0552       0.0721       0.0467       0.0721       0.0594       0.0604       0.0911       0.0757        0.422      0.00439\n","     52    12      0.00798      0.00781     0.000171       0.0522       0.0684       0.0432       0.0702       0.0567       0.0544         0.09       0.0722        0.931      0.00969\n","     52    13      0.00802      0.00795     7.26e-05       0.0514        0.069        0.041       0.0722       0.0566       0.0532       0.0929        0.073         0.55      0.00573\n","     52    14      0.00915      0.00897     0.000185       0.0564       0.0733       0.0462       0.0769       0.0616       0.0582       0.0966       0.0774        0.843      0.00878\n","     52    15      0.00976      0.00973     2.83e-05       0.0572       0.0763       0.0448       0.0821       0.0635       0.0575        0.104       0.0809        0.287      0.00299\n","     52    16      0.00767      0.00762      4.9e-05       0.0523       0.0675       0.0439        0.069       0.0565       0.0547       0.0877       0.0712        0.361      0.00376\n","     52    17      0.00905      0.00888     0.000171       0.0536       0.0729       0.0416       0.0777       0.0596       0.0544          0.1       0.0772        0.962         0.01\n","     52    18      0.00902      0.00899     2.28e-05       0.0567       0.0734       0.0458       0.0787       0.0622       0.0576       0.0975       0.0776        0.301      0.00314\n","     52    19      0.00823      0.00819     3.34e-05       0.0525         0.07       0.0415       0.0746        0.058       0.0533        0.095       0.0742        0.338      0.00352\n","     52    20      0.00974      0.00967     7.34e-05       0.0587       0.0761       0.0522       0.0719        0.062       0.0674        0.091       0.0792        0.551      0.00574\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     52     1      0.00902      0.00898     4.23e-05       0.0554       0.0733       0.0442       0.0779        0.061       0.0573       0.0977       0.0775        0.419      0.00437\n","     52     2      0.00894      0.00892     2.48e-05       0.0544       0.0731       0.0431       0.0771       0.0601       0.0561       0.0985       0.0773        0.299      0.00312\n","     52     3      0.00829      0.00826      2.8e-05       0.0528       0.0703       0.0419       0.0745       0.0582        0.054       0.0949       0.0744        0.312      0.00325\n","     52     4      0.00878      0.00873     5.49e-05       0.0538       0.0723       0.0428       0.0759       0.0593       0.0553       0.0977       0.0765        0.476      0.00496\n","     52     5       0.0082      0.00815      4.6e-05       0.0528       0.0699       0.0427       0.0729       0.0578       0.0557       0.0919       0.0738        0.408      0.00425\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              52  166.167    0.005       0.0086     7.96e-05      0.00868       0.0545       0.0717       0.0446       0.0745       0.0595       0.0571       0.0944       0.0758        0.536      0.00558\n","! Validation         52  166.167    0.005      0.00861     3.92e-05      0.00865       0.0538       0.0718       0.0429       0.0757       0.0593       0.0557       0.0962       0.0759        0.383      0.00399\n","Wall time: 166.16768860200045\n","! Best model       52    0.009\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     53     1      0.00891      0.00886     4.52e-05        0.056       0.0728       0.0451        0.078       0.0615       0.0575       0.0965        0.077        0.428      0.00445\n","     53     2       0.0103       0.0103     4.43e-05       0.0607       0.0784       0.0481       0.0858        0.067       0.0605        0.105       0.0829        0.441       0.0046\n","     53     3      0.00786      0.00785      1.2e-05       0.0516       0.0686       0.0411       0.0726       0.0569       0.0522        0.093       0.0726         0.21      0.00218\n","     53     4      0.00831      0.00821     0.000103       0.0543       0.0701       0.0453       0.0724       0.0588        0.057       0.0908       0.0739        0.559      0.00582\n","     53     5      0.00824      0.00823     1.01e-05       0.0535       0.0702       0.0443       0.0721       0.0582       0.0558       0.0925       0.0741        0.211       0.0022\n","     53     6      0.00997      0.00994     2.78e-05       0.0572       0.0771        0.045       0.0815       0.0632       0.0587        0.105       0.0817        0.355      0.00369\n","     53     7      0.00732       0.0073     1.75e-05       0.0507       0.0661        0.041       0.0702       0.0556       0.0518        0.088       0.0699        0.284      0.00296\n","     53     8       0.0098      0.00978     1.53e-05        0.059       0.0765       0.0501       0.0768       0.0634       0.0641       0.0967       0.0804        0.275      0.00287\n","     53     9      0.00733      0.00712     0.000211       0.0496       0.0653        0.039       0.0709       0.0549       0.0495       0.0889       0.0692         1.05       0.0109\n","     53    10      0.00944      0.00937     7.23e-05       0.0592       0.0749       0.0537       0.0701       0.0619       0.0672       0.0883       0.0777        0.536      0.00558\n","     53    11      0.00858      0.00849     9.27e-05       0.0554       0.0713       0.0476        0.071       0.0593        0.059       0.0909        0.075        0.642      0.00669\n","     53    12      0.00784      0.00783     1.15e-05       0.0512       0.0684        0.039       0.0756       0.0573       0.0503       0.0948       0.0726        0.236      0.00246\n","     53    13      0.00826      0.00819     6.34e-05       0.0523         0.07       0.0397       0.0774       0.0585       0.0506       0.0979       0.0743        0.505      0.00526\n","     53    14      0.00882      0.00868     0.000138       0.0543       0.0721       0.0425       0.0779       0.0602       0.0545       0.0982       0.0764        0.748      0.00779\n","     53    15      0.00743      0.00736     6.52e-05       0.0492       0.0664       0.0381       0.0714       0.0548       0.0504       0.0903       0.0703        0.521      0.00543\n","     53    16      0.00822      0.00812     9.48e-05       0.0525       0.0697       0.0433        0.071       0.0572       0.0557       0.0916       0.0736        0.604       0.0063\n","     53    17      0.00768      0.00761     7.03e-05       0.0506       0.0675       0.0393       0.0732       0.0562       0.0505       0.0925       0.0715        0.567       0.0059\n","     53    18      0.00776       0.0077     5.89e-05       0.0515       0.0679       0.0421       0.0702       0.0561       0.0538       0.0896       0.0717        0.504      0.00525\n","     53    19      0.00971      0.00969     1.85e-05       0.0575       0.0761       0.0462       0.0801       0.0632       0.0595        0.102       0.0805        0.259       0.0027\n","     53    20      0.00803      0.00797     5.89e-05       0.0517       0.0691       0.0413       0.0723       0.0568       0.0533        0.093       0.0731        0.515      0.00537\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     53     1      0.00894       0.0089     4.22e-05       0.0551        0.073       0.0439       0.0776       0.0607        0.057       0.0974       0.0772        0.418      0.00435\n","     53     2      0.00887      0.00884     2.48e-05       0.0542       0.0728       0.0429       0.0769       0.0599       0.0558       0.0982        0.077          0.3      0.00312\n","     53     3      0.00823       0.0082     2.81e-05       0.0526       0.0701       0.0417       0.0743        0.058       0.0537       0.0947       0.0742        0.313      0.00326\n","     53     4       0.0087      0.00865     5.48e-05       0.0536        0.072       0.0425       0.0756       0.0591        0.055       0.0974       0.0762        0.476      0.00496\n","     53     5      0.00813      0.00808     4.62e-05       0.0525       0.0696       0.0425       0.0727       0.0576       0.0554       0.0916       0.0735        0.408      0.00425\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              53  169.266    0.005      0.00843     6.15e-05      0.00849       0.0539        0.071       0.0436       0.0745       0.0591       0.0558       0.0944       0.0751        0.472      0.00492\n","! Validation         53  169.266    0.005      0.00854     3.92e-05      0.00857       0.0536       0.0715       0.0427       0.0754       0.0591       0.0554       0.0959       0.0756        0.383      0.00399\n","Wall time: 169.266616418\n","! Best model       53    0.009\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     54     1      0.00737      0.00725     0.000121       0.0498       0.0659       0.0403        0.069       0.0546       0.0518       0.0874       0.0696        0.689      0.00718\n","     54     2      0.00892      0.00887     5.25e-05       0.0546       0.0729       0.0423       0.0792       0.0608       0.0545       0.0999       0.0772        0.484      0.00504\n","     54     3      0.00767      0.00753      0.00014       0.0521       0.0672       0.0442       0.0681       0.0561       0.0555       0.0858       0.0707        0.841      0.00876\n","     54     4      0.00831      0.00827     4.18e-05       0.0535       0.0704       0.0431       0.0742       0.0587       0.0544       0.0945       0.0745         0.43      0.00448\n","     54     5      0.00784      0.00779     4.72e-05       0.0519       0.0683       0.0403       0.0753       0.0578       0.0513       0.0935       0.0724        0.486      0.00506\n","     54     6      0.00727      0.00721     5.57e-05       0.0508       0.0657       0.0417        0.069       0.0553       0.0524       0.0863       0.0694        0.525      0.00547\n","     54     7       0.0106       0.0104     0.000262       0.0606       0.0788       0.0483       0.0853       0.0668       0.0618        0.105       0.0833         1.12       0.0117\n","     54     8       0.0121        0.012     2.57e-05       0.0651       0.0848       0.0536       0.0881       0.0708       0.0692         0.11       0.0894        0.323      0.00336\n","     54     9      0.00925      0.00906     0.000187       0.0569       0.0736       0.0502       0.0704       0.0603       0.0636       0.0904        0.077        0.975       0.0102\n","     54    10      0.00832       0.0083     1.61e-05       0.0527       0.0705       0.0414       0.0753       0.0584       0.0533        0.096       0.0747        0.231      0.00241\n","     54    11      0.00902        0.009      2.1e-05       0.0562       0.0734       0.0472       0.0743       0.0607       0.0603       0.0943       0.0773        0.282      0.00294\n","     54    12      0.00993      0.00985     7.41e-05         0.06       0.0768       0.0508       0.0782       0.0645       0.0635       0.0981       0.0808        0.587      0.00611\n","     54    13       0.0092      0.00918     2.32e-05       0.0563       0.0741       0.0448       0.0791        0.062       0.0572       0.0996       0.0784         0.31      0.00323\n","     54    14      0.00789      0.00786     3.16e-05       0.0513       0.0686       0.0403       0.0734       0.0569       0.0525       0.0928       0.0726         0.36      0.00375\n","     54    15       0.0076      0.00757     3.28e-05       0.0508       0.0673       0.0407       0.0708       0.0558       0.0515       0.0911       0.0713        0.329      0.00343\n","     54    16      0.00855      0.00852     2.19e-05       0.0535       0.0714       0.0431       0.0743       0.0587       0.0556       0.0955       0.0756        0.262      0.00272\n","     54    17      0.00947      0.00946     1.86e-05       0.0557       0.0752       0.0427       0.0815       0.0621       0.0556        0.104       0.0797        0.264      0.00275\n","     54    18      0.00812      0.00785     0.000265       0.0522       0.0685       0.0416       0.0733       0.0574       0.0533       0.0917       0.0725         1.19       0.0124\n","     54    19      0.00885      0.00879     5.66e-05       0.0548       0.0726       0.0457        0.073       0.0594       0.0586       0.0944       0.0765        0.526      0.00548\n","     54    20      0.00816      0.00802     0.000142       0.0533       0.0693       0.0447       0.0705       0.0576       0.0562       0.0898        0.073        0.811      0.00844\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     54     1      0.00885       0.0088     4.29e-05       0.0548       0.0726       0.0436       0.0773       0.0605       0.0566        0.097       0.0768        0.428      0.00446\n","     54     2      0.00878      0.00876     2.46e-05       0.0539       0.0724       0.0426       0.0766       0.0596       0.0555       0.0978       0.0767        0.297      0.00309\n","     54     3      0.00817      0.00814     2.72e-05       0.0524       0.0698       0.0415       0.0741       0.0578       0.0534       0.0944       0.0739        0.306      0.00319\n","     54     4      0.00863      0.00857     5.41e-05       0.0533       0.0716       0.0423       0.0754       0.0588       0.0546       0.0971       0.0758        0.472      0.00491\n","     54     5      0.00806      0.00801     4.52e-05       0.0523       0.0692       0.0422       0.0725       0.0573        0.055       0.0912       0.0731        0.405      0.00422\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              54  172.353    0.005      0.00864     8.17e-05      0.00872       0.0546       0.0719       0.0444       0.0751       0.0597       0.0568       0.0952        0.076        0.551      0.00574\n","! Validation         54  172.353    0.005      0.00846     3.88e-05       0.0085       0.0534       0.0711       0.0425       0.0752       0.0588        0.055       0.0955       0.0753        0.382      0.00398\n","Wall time: 172.35363891700035\n","! Best model       54    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     55     1      0.00668      0.00655     0.000128       0.0477       0.0626        0.038        0.067       0.0525        0.048       0.0846       0.0663         0.77      0.00802\n","     55     2      0.00781      0.00777     4.16e-05       0.0515       0.0682       0.0413        0.072       0.0566       0.0523       0.0921       0.0722        0.391      0.00408\n","     55     3      0.00917        0.009     0.000171       0.0559       0.0734       0.0457       0.0763        0.061       0.0582       0.0969       0.0775        0.915      0.00953\n","     55     4      0.00785      0.00774     0.000111       0.0511       0.0681       0.0406       0.0722       0.0564       0.0519       0.0922       0.0721        0.642      0.00668\n","     55     5       0.0077      0.00762     8.75e-05       0.0512       0.0675       0.0404       0.0726       0.0565       0.0509       0.0922       0.0715        0.605       0.0063\n","     55     6      0.00805       0.0079     0.000145       0.0509       0.0688       0.0399       0.0729       0.0564       0.0531       0.0925       0.0728        0.802      0.00836\n","     55     7      0.00887      0.00885     1.48e-05       0.0555       0.0728       0.0447       0.0771       0.0609       0.0573       0.0965       0.0769        0.208      0.00217\n","     55     8       0.0101      0.00987     0.000265        0.059       0.0768       0.0492       0.0786       0.0639       0.0622       0.0999        0.081         1.15        0.012\n","     55     9        0.013       0.0129     8.26e-05       0.0686       0.0879       0.0596       0.0865       0.0731       0.0751        0.109       0.0922        0.591      0.00615\n","     55    10       0.0124       0.0123     0.000107       0.0679       0.0859       0.0605       0.0826       0.0716       0.0753        0.104       0.0896        0.692      0.00721\n","     55    11      0.00814      0.00808     5.99e-05       0.0537       0.0695       0.0441       0.0729       0.0585       0.0557       0.0911       0.0734        0.466      0.00486\n","     55    12      0.00758      0.00751     7.54e-05       0.0508        0.067       0.0414       0.0695       0.0554        0.053       0.0887       0.0708        0.525      0.00547\n","     55    13      0.00968      0.00963      4.7e-05       0.0578       0.0759       0.0486       0.0763       0.0624       0.0626       0.0973       0.0799        0.476      0.00496\n","     55    14       0.0112       0.0112      5.2e-05       0.0624       0.0818       0.0517       0.0839       0.0678       0.0662        0.106       0.0862        0.512      0.00533\n","     55    15      0.00858      0.00851     6.34e-05       0.0529       0.0714       0.0419        0.075       0.0585       0.0563       0.0946       0.0754        0.457      0.00476\n","     55    16      0.00786      0.00783     2.84e-05       0.0526       0.0685       0.0419       0.0742        0.058       0.0533       0.0915       0.0724        0.263      0.00274\n","     55    17         0.01      0.00991     8.16e-05       0.0593        0.077       0.0482       0.0815       0.0648       0.0605        0.102       0.0814         0.62      0.00646\n","     55    18      0.00967      0.00965     1.68e-05       0.0592        0.076       0.0522       0.0734       0.0628        0.066       0.0928       0.0794        0.273      0.00285\n","     55    19      0.00869      0.00866     3.56e-05       0.0545        0.072       0.0447       0.0741       0.0594       0.0562        0.096       0.0761        0.398      0.00415\n","     55    20      0.00782      0.00774     8.06e-05       0.0515       0.0681       0.0408       0.0728       0.0568       0.0525       0.0916       0.0721        0.578      0.00602\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     55     1      0.00877      0.00873     4.22e-05       0.0546       0.0723       0.0434        0.077       0.0602       0.0562       0.0967       0.0764        0.418      0.00436\n","     55     2      0.00872      0.00869     2.47e-05       0.0537       0.0721       0.0424       0.0763       0.0594       0.0552       0.0975       0.0764          0.3      0.00312\n","     55     3      0.00811      0.00808     2.81e-05       0.0522       0.0695       0.0413       0.0738       0.0576       0.0531       0.0942       0.0736        0.313      0.00326\n","     55     4      0.00855       0.0085     5.45e-05       0.0531       0.0713        0.042       0.0752       0.0586       0.0543       0.0968       0.0755        0.474      0.00494\n","     55     5      0.00799      0.00794     4.62e-05       0.0521       0.0689        0.042       0.0722       0.0571       0.0547       0.0909       0.0728        0.409      0.00426\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              55  175.467    0.005      0.00896     8.47e-05      0.00905       0.0557       0.0732       0.0458       0.0756       0.0607       0.0588       0.0958       0.0773        0.567       0.0059\n","! Validation         55  175.467    0.005      0.00839     3.92e-05      0.00843       0.0531       0.0709       0.0422       0.0749       0.0586       0.0547       0.0953        0.075        0.383      0.00399\n","Wall time: 175.4675285150006\n","! Best model       55    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     56     1      0.00831      0.00822     8.78e-05       0.0531       0.0701        0.044       0.0714       0.0577       0.0568       0.0911        0.074        0.628      0.00654\n","     56     2      0.00892      0.00886      6.3e-05       0.0547       0.0728       0.0435       0.0771       0.0603       0.0564       0.0977        0.077        0.503      0.00524\n","     56     3       0.0079      0.00789     1.63e-05       0.0529       0.0687       0.0434       0.0718       0.0576       0.0547       0.0904       0.0726        0.265      0.00277\n","     56     4      0.00815      0.00793     0.000221        0.053       0.0689       0.0422       0.0745       0.0584        0.053       0.0929       0.0729        0.969       0.0101\n","     56     5      0.00745       0.0074     5.26e-05       0.0499       0.0665       0.0393       0.0711       0.0552       0.0503       0.0907       0.0705        0.481      0.00501\n","     56     6      0.00792      0.00777     0.000153       0.0518       0.0682       0.0412       0.0731       0.0571       0.0522       0.0922       0.0722        0.845       0.0088\n","     56     7      0.00905      0.00901        4e-05        0.056       0.0734       0.0456        0.077       0.0613       0.0584       0.0967       0.0776        0.414      0.00431\n","     56     8      0.00868      0.00858     9.89e-05       0.0544       0.0717       0.0445       0.0743       0.0594       0.0561       0.0955       0.0758        0.701      0.00731\n","     56     9      0.00777      0.00773     4.59e-05        0.051        0.068       0.0404       0.0723       0.0563       0.0517       0.0923        0.072        0.438      0.00456\n","     56    10       0.0123       0.0123     3.22e-05       0.0648       0.0858       0.0523       0.0899       0.0711       0.0675        0.114       0.0907        0.341      0.00355\n","     56    11       0.0118       0.0113     0.000485       0.0658       0.0822       0.0593       0.0787        0.069       0.0722       0.0993       0.0857         1.56       0.0163\n","     56    12       0.0111        0.011     5.33e-05       0.0634       0.0813       0.0546       0.0811       0.0678       0.0694        0.101       0.0851         0.42      0.00437\n","     56    13      0.00849      0.00845     3.71e-05       0.0532       0.0711       0.0415       0.0767       0.0591       0.0538       0.0969       0.0753        0.385      0.00401\n","     56    14      0.00861      0.00799     0.000616       0.0524       0.0692       0.0408       0.0756       0.0582       0.0521       0.0945       0.0733         1.84       0.0191\n","     56    15       0.0075      0.00748     2.62e-05       0.0503       0.0669       0.0395       0.0718       0.0557       0.0504       0.0914       0.0709        0.299      0.00311\n","     56    16      0.00749      0.00692     0.000574       0.0481       0.0644       0.0377        0.069       0.0533       0.0477       0.0887       0.0682         1.72       0.0179\n","     56    17      0.00915      0.00896     0.000186       0.0554       0.0732       0.0437       0.0788       0.0613        0.057       0.0979       0.0775        0.957      0.00996\n","     56    18      0.00761      0.00756     5.24e-05       0.0512       0.0673       0.0417       0.0701       0.0559       0.0525       0.0897       0.0711        0.419      0.00436\n","     56    19      0.00747      0.00709      0.00038       0.0498       0.0651       0.0415       0.0664        0.054       0.0523       0.0852       0.0688          1.4       0.0146\n","     56    20      0.00758      0.00754     3.87e-05       0.0503       0.0672       0.0389        0.073        0.056       0.0505       0.0919       0.0712         0.41      0.00428\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     56     1      0.00869      0.00865     4.24e-05       0.0543        0.072       0.0431       0.0768       0.0599       0.0559       0.0964       0.0761        0.422      0.00439\n","     56     2      0.00865      0.00863     2.47e-05       0.0535       0.0719       0.0422       0.0761       0.0592       0.0549       0.0972       0.0761          0.3      0.00312\n","     56     3      0.00805      0.00802     2.79e-05        0.052       0.0693       0.0411       0.0737       0.0574       0.0528       0.0939       0.0734        0.311      0.00324\n","     56     4      0.00849      0.00843     5.43e-05       0.0529        0.071       0.0418        0.075       0.0584       0.0539       0.0966       0.0752        0.473      0.00493\n","     56     5      0.00792      0.00787      4.6e-05       0.0518       0.0686       0.0418        0.072       0.0569       0.0544       0.0906       0.0725        0.409      0.00426\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              56  178.559    0.005       0.0085     0.000163      0.00866       0.0541       0.0713       0.0438       0.0747       0.0592       0.0561       0.0947       0.0754         0.75      0.00781\n","! Validation         56  178.559    0.005      0.00832     3.91e-05      0.00836       0.0529       0.0706        0.042       0.0747       0.0583       0.0544        0.095       0.0747        0.383      0.00399\n","Wall time: 178.5593598380001\n","! Best model       56    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     57     1      0.00853      0.00833       0.0002       0.0541       0.0706       0.0441       0.0743       0.0592       0.0558       0.0934       0.0746         1.01       0.0105\n","     57     2      0.00815      0.00795     0.000199       0.0526        0.069       0.0432       0.0715       0.0573       0.0547        0.091       0.0729        0.978       0.0102\n","     57     3      0.00674      0.00669     4.98e-05       0.0479       0.0633       0.0383       0.0671       0.0527       0.0484       0.0856        0.067        0.432       0.0045\n","     57     4      0.00804      0.00759     0.000444       0.0505       0.0674       0.0405       0.0706       0.0555       0.0523       0.0904       0.0713         1.53       0.0159\n","     57     5      0.00812       0.0081     1.83e-05       0.0532       0.0696       0.0425       0.0744       0.0585        0.054       0.0933       0.0737        0.265      0.00276\n","     57     6      0.00987       0.0095     0.000373       0.0582       0.0754        0.046       0.0825       0.0643       0.0576        0.102       0.0798         1.38       0.0143\n","     57     7      0.00901      0.00885      0.00016       0.0544       0.0728       0.0446       0.0741       0.0594        0.058       0.0957       0.0769        0.856      0.00891\n","     57     8      0.00825      0.00818     6.93e-05       0.0524         0.07       0.0416        0.074       0.0578       0.0546       0.0934        0.074        0.489      0.00509\n","     57     9      0.00769       0.0074     0.000292       0.0499       0.0665       0.0399         0.07        0.055       0.0521       0.0886       0.0704         1.11       0.0116\n","     57    10      0.00774      0.00767     6.58e-05       0.0519       0.0678       0.0425       0.0708       0.0567       0.0541        0.089       0.0716         0.45      0.00469\n","     57    11      0.00741      0.00737     3.98e-05       0.0503       0.0664         0.04       0.0708       0.0554       0.0516        0.089       0.0703        0.439      0.00458\n","     57    12      0.00762      0.00734     0.000281       0.0491       0.0663       0.0374       0.0727        0.055       0.0476        0.093       0.0703          1.2       0.0125\n","     57    13      0.00716      0.00711     4.75e-05       0.0496       0.0652       0.0398        0.069       0.0544       0.0513       0.0867        0.069        0.483      0.00503\n","     57    14      0.00794      0.00778     0.000165       0.0521       0.0682        0.041       0.0745       0.0577       0.0515       0.0931       0.0723        0.862      0.00898\n","     57    15      0.00838      0.00818     0.000202       0.0532         0.07       0.0447       0.0702       0.0575       0.0568       0.0908       0.0738        0.937      0.00976\n","     57    16      0.00815      0.00809     5.98e-05       0.0526       0.0696       0.0441       0.0697       0.0569       0.0559        0.091       0.0734        0.444      0.00463\n","     57    17      0.00966      0.00951     0.000158       0.0567       0.0754       0.0445        0.081       0.0627       0.0578        0.102       0.0799        0.851      0.00886\n","     57    18      0.00833      0.00831     1.23e-05       0.0534       0.0705       0.0419       0.0763       0.0591       0.0537       0.0957       0.0747        0.201      0.00209\n","     57    19       0.0106       0.0105     0.000117       0.0595       0.0793       0.0484       0.0817        0.065       0.0626        0.105       0.0838        0.752      0.00783\n","     57    20       0.0101      0.00999      8.7e-05       0.0589       0.0773       0.0486       0.0794        0.064       0.0616        0.102       0.0817        0.563      0.00586\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     57     1      0.00862      0.00858     4.27e-05       0.0541       0.0717       0.0429       0.0765       0.0597       0.0556       0.0961       0.0758        0.426      0.00444\n","     57     2      0.00859      0.00856     2.47e-05       0.0533       0.0716        0.042        0.076        0.059       0.0546        0.097       0.0758        0.298       0.0031\n","     57     3        0.008      0.00797     2.76e-05       0.0518       0.0691       0.0409       0.0735       0.0572       0.0525       0.0937       0.0731        0.308       0.0032\n","     57     4      0.00842      0.00836      5.4e-05       0.0526       0.0708       0.0416       0.0747       0.0582       0.0536       0.0962       0.0749        0.471      0.00491\n","     57     5      0.00785      0.00781     4.55e-05       0.0516       0.0683       0.0415       0.0718       0.0566       0.0541       0.0903       0.0722        0.407      0.00424\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              57  181.648    0.005      0.00822     0.000152      0.00837        0.053       0.0701       0.0427       0.0737       0.0582       0.0547       0.0937       0.0742        0.762      0.00793\n","! Validation         57  181.648    0.005      0.00826     3.89e-05       0.0083       0.0527       0.0703       0.0418       0.0745       0.0581       0.0541       0.0947       0.0744        0.382      0.00398\n","Wall time: 181.64871443599986\n","! Best model       57    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     58     1      0.00772       0.0076     0.000122       0.0512       0.0674       0.0398       0.0741        0.057       0.0506       0.0923       0.0715        0.787       0.0082\n","     58     2      0.00704       0.0069     0.000144       0.0485       0.0643       0.0392       0.0672       0.0532         0.05        0.086        0.068        0.787       0.0082\n","     58     3      0.00946      0.00935      0.00011       0.0565       0.0748       0.0465       0.0763       0.0614       0.0597       0.0982        0.079        0.696      0.00725\n","     58     4      0.00872      0.00869     3.13e-05       0.0549       0.0721        0.045       0.0745       0.0598       0.0574        0.095       0.0762        0.325      0.00339\n","     58     5      0.00855      0.00852     2.92e-05       0.0539       0.0714       0.0429       0.0759       0.0594       0.0547       0.0965       0.0756         0.36      0.00375\n","     58     6      0.00763      0.00758     5.49e-05       0.0513       0.0673        0.041        0.072       0.0565       0.0525         0.09       0.0712        0.474      0.00494\n","     58     7      0.00669      0.00667     2.11e-05       0.0486       0.0632       0.0395       0.0668       0.0531        0.049       0.0847       0.0668        0.252      0.00263\n","     58     8      0.00786      0.00778     8.72e-05       0.0519       0.0682       0.0425       0.0708       0.0566        0.055        0.089        0.072        0.628      0.00654\n","     58     9      0.00819      0.00799     0.000197       0.0524       0.0691       0.0411        0.075        0.058       0.0524        0.094       0.0732        0.958      0.00998\n","     58    10       0.0107       0.0107      1.9e-05       0.0618       0.0799       0.0519       0.0817       0.0668       0.0659        0.102       0.0841        0.264      0.00275\n","     58    11      0.00939      0.00919     0.000202       0.0568       0.0742       0.0502       0.0699       0.0601       0.0633       0.0922       0.0777        0.961         0.01\n","     58    12      0.00788      0.00775     0.000125       0.0522       0.0681       0.0414       0.0739       0.0576       0.0525       0.0917       0.0721        0.739       0.0077\n","     58    13      0.00855      0.00832     0.000232       0.0529       0.0706       0.0408        0.077       0.0589       0.0528       0.0967       0.0748          1.1       0.0114\n","     58    14      0.00732      0.00718      0.00013       0.0502       0.0656       0.0402       0.0703       0.0552       0.0511       0.0876       0.0694        0.723      0.00753\n","     58    15      0.00868      0.00863     5.11e-05       0.0541       0.0719       0.0439       0.0744       0.0592       0.0572       0.0947       0.0759        0.362      0.00377\n","     58    16      0.00829      0.00794     0.000347       0.0521       0.0689       0.0418       0.0726       0.0572       0.0529       0.0931        0.073          1.3       0.0135\n","     58    17      0.00804      0.00793      0.00011       0.0521       0.0689       0.0411       0.0743       0.0577       0.0519       0.0941        0.073        0.633      0.00659\n","     58    18      0.00826      0.00762     0.000634       0.0506       0.0675       0.0401       0.0717       0.0559       0.0515       0.0916       0.0715         1.85       0.0193\n","     58    19      0.00712      0.00705     6.62e-05       0.0487        0.065       0.0391       0.0678       0.0535       0.0498       0.0878       0.0688        0.581      0.00605\n","     58    20       0.0075      0.00738     0.000128       0.0499       0.0664       0.0392       0.0711       0.0552       0.0509       0.0898       0.0703        0.638      0.00664\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     58     1      0.00856      0.00851     4.25e-05       0.0539       0.0714       0.0427       0.0762       0.0595       0.0553       0.0958       0.0755        0.423       0.0044\n","     58     2      0.00852       0.0085     2.47e-05       0.0531       0.0713       0.0418       0.0758       0.0588       0.0543       0.0967       0.0755          0.3      0.00312\n","     58     3      0.00794      0.00792     2.81e-05       0.0516       0.0688       0.0407       0.0733        0.057       0.0523       0.0935       0.0729        0.311      0.00324\n","     58     4      0.00835      0.00829     5.44e-05       0.0524       0.0705       0.0414       0.0745       0.0579       0.0533        0.096       0.0746        0.473      0.00493\n","     58     5      0.00779      0.00774     4.61e-05       0.0514       0.0681       0.0413       0.0715       0.0564       0.0538       0.0901       0.0719        0.409      0.00426\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              58  184.736    0.005      0.00804     0.000142      0.00818       0.0525       0.0694       0.0424       0.0729       0.0576       0.0542       0.0925       0.0733        0.721      0.00751\n","! Validation         58  184.736    0.005      0.00819     3.92e-05      0.00823       0.0525         0.07       0.0416       0.0743       0.0579       0.0538       0.0944       0.0741        0.383      0.00399\n","Wall time: 184.73636057900057\n","! Best model       58    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     59     1      0.00689      0.00672     0.000167       0.0474       0.0634       0.0379       0.0664       0.0522       0.0483        0.086       0.0672        0.932      0.00971\n","     59     2      0.00718      0.00714     3.69e-05       0.0493       0.0654       0.0385       0.0709       0.0547       0.0488       0.0898       0.0693        0.415      0.00432\n","     59     3      0.00922      0.00895     0.000269       0.0561       0.0732       0.0462       0.0758        0.061        0.059       0.0955       0.0772         1.16       0.0121\n","     59     4      0.00842      0.00839      2.8e-05        0.054       0.0709       0.0446       0.0729       0.0588       0.0567       0.0929       0.0748        0.305      0.00317\n","     59     5      0.00828      0.00828        4e-06        0.052       0.0704         0.04        0.076        0.058       0.0526       0.0966       0.0746        0.121      0.00126\n","     59     6      0.00751      0.00744     7.31e-05        0.051       0.0667        0.041       0.0711        0.056       0.0519       0.0892       0.0706        0.537       0.0056\n","     59     7      0.00748      0.00745     3.06e-05       0.0514       0.0668       0.0422       0.0699        0.056       0.0532       0.0878       0.0705        0.378      0.00394\n","     59     8      0.00865      0.00854     0.000114       0.0535       0.0715        0.041       0.0784       0.0597       0.0529       0.0986       0.0758        0.695      0.00724\n","     59     9      0.00732      0.00724     8.03e-05       0.0495       0.0658       0.0398        0.069       0.0544       0.0512        0.088       0.0696        0.538      0.00561\n","     59    10      0.00787      0.00784     3.43e-05       0.0522       0.0685       0.0422       0.0722       0.0572       0.0544       0.0903       0.0724        0.397      0.00414\n","     59    11      0.00708      0.00684     0.000245       0.0491        0.064         0.04       0.0671       0.0536       0.0504       0.0848       0.0676         1.15       0.0119\n","     59    12      0.00865      0.00859     5.57e-05       0.0536       0.0717       0.0426       0.0754        0.059       0.0547       0.0972       0.0759        0.365       0.0038\n","     59    13      0.00776      0.00764     0.000119         0.05       0.0676       0.0393       0.0713       0.0553       0.0504        0.093       0.0717        0.787       0.0082\n","     59    14      0.00744      0.00735     8.33e-05       0.0503       0.0663        0.039       0.0729        0.056       0.0498       0.0908       0.0703        0.559      0.00582\n","     59    15       0.0071      0.00708     2.64e-05        0.049       0.0651        0.039        0.069        0.054       0.0491       0.0888       0.0689        0.298       0.0031\n","     59    16      0.00784      0.00774     9.59e-05       0.0516       0.0681       0.0404        0.074       0.0572       0.0522       0.0919       0.0721        0.599      0.00624\n","     59    17       0.0075      0.00724     0.000258       0.0507       0.0658       0.0419       0.0685       0.0552       0.0524       0.0867       0.0695         1.05       0.0109\n","     59    18      0.00815      0.00813     1.68e-05       0.0532       0.0698        0.042       0.0756       0.0588       0.0533       0.0944       0.0739        0.199      0.00208\n","     59    19      0.00844      0.00821      0.00023       0.0533       0.0701       0.0437       0.0724        0.058       0.0568        0.091       0.0739          1.1       0.0115\n","     59    20       0.0097      0.00967     3.06e-05       0.0589       0.0761       0.0497       0.0772       0.0635        0.063        0.097         0.08        0.336       0.0035\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     59     1      0.00848      0.00844     4.29e-05       0.0536       0.0711       0.0424        0.076       0.0592       0.0549       0.0955       0.0752        0.429      0.00447\n","     59     2      0.00845      0.00842     2.46e-05       0.0529        0.071       0.0416       0.0755       0.0585        0.054       0.0964       0.0752        0.298       0.0031\n","     59     3      0.00789      0.00786     2.76e-05       0.0514       0.0686       0.0405       0.0731       0.0568        0.052       0.0934       0.0727        0.307       0.0032\n","     59     4      0.00828      0.00823     5.39e-05       0.0522       0.0702       0.0411       0.0743       0.0577        0.053       0.0957       0.0743         0.47       0.0049\n","     59     5      0.00772      0.00767     4.55e-05       0.0512       0.0678       0.0411       0.0713       0.0562       0.0535       0.0897       0.0716        0.407      0.00424\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              59  187.825    0.005      0.00782     9.99e-05      0.00792       0.0518       0.0684       0.0416       0.0723       0.0569       0.0532       0.0916       0.0724        0.596      0.00621\n","! Validation         59  187.825    0.005      0.00812     3.89e-05      0.00816       0.0522       0.0697       0.0414        0.074       0.0577       0.0535       0.0942       0.0738        0.382      0.00398\n","Wall time: 187.82529963399975\n","! Best model       59    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     60     1       0.0109       0.0109     2.97e-05       0.0626       0.0806       0.0512       0.0853       0.0682       0.0655        0.104        0.085        0.341      0.00355\n","     60     2       0.0115       0.0114     0.000121       0.0633       0.0825        0.052       0.0861        0.069       0.0658        0.109       0.0872        0.723      0.00753\n","     60     3      0.00909      0.00904     4.38e-05       0.0562       0.0736       0.0459       0.0769       0.0614       0.0583       0.0972       0.0777        0.427      0.00445\n","     60     4       0.0081      0.00804     5.56e-05       0.0518       0.0694       0.0411       0.0733       0.0572       0.0534       0.0935       0.0734        0.503      0.00524\n","     60     5      0.00755      0.00743      0.00012       0.0505       0.0667       0.0426       0.0662       0.0544       0.0544       0.0862       0.0703        0.629      0.00655\n","     60     6      0.00852      0.00841     0.000109        0.055       0.0709       0.0468       0.0714       0.0591       0.0594       0.0897       0.0745        0.724      0.00754\n","     60     7       0.0078      0.00776     3.39e-05       0.0507       0.0682       0.0397       0.0729       0.0563       0.0517       0.0927       0.0722        0.378      0.00394\n","     60     8      0.00815      0.00803     0.000116       0.0528       0.0693       0.0432        0.072       0.0576       0.0539       0.0928       0.0733        0.733      0.00763\n","     60     9       0.0094      0.00934     6.24e-05       0.0579       0.0748       0.0496       0.0745        0.062       0.0627       0.0944       0.0785        0.509       0.0053\n","     60    10      0.00801      0.00797      4.6e-05       0.0533        0.069       0.0434       0.0729       0.0582       0.0542       0.0918        0.073        0.487      0.00507\n","     60    11      0.00822       0.0081     0.000124        0.053       0.0696       0.0409       0.0773       0.0591       0.0514       0.0962       0.0738        0.611      0.00636\n","     60    12      0.00696      0.00692     4.22e-05       0.0489       0.0644       0.0385       0.0697       0.0541       0.0485       0.0878       0.0682        0.396      0.00413\n","     60    13      0.00784       0.0078     4.18e-05       0.0516       0.0683       0.0407       0.0733        0.057       0.0519       0.0928       0.0724        0.385      0.00401\n","     60    14      0.00838      0.00821     0.000178       0.0538       0.0701       0.0437        0.074       0.0588       0.0543       0.0941       0.0742        0.966       0.0101\n","     60    15       0.0107       0.0106     6.98e-05       0.0609       0.0797       0.0512       0.0805       0.0658       0.0648        0.103        0.084          0.5      0.00521\n","     60    16       0.0112       0.0112     7.53e-06       0.0617       0.0819       0.0496        0.086       0.0678       0.0649        0.108       0.0865        0.164       0.0017\n","     60    17      0.00921      0.00899     0.000221       0.0556       0.0734       0.0453        0.076       0.0607       0.0573       0.0978       0.0776         1.04       0.0108\n","     60    18      0.00855      0.00844     0.000108       0.0532       0.0711       0.0438       0.0721       0.0579       0.0567       0.0934        0.075        0.707      0.00736\n","     60    19       0.0087       0.0085     0.000195       0.0533       0.0713       0.0415       0.0768       0.0591       0.0545       0.0966       0.0755            1       0.0104\n","     60    20       0.0104       0.0103     0.000154       0.0605       0.0784       0.0525       0.0764       0.0645       0.0674       0.0968       0.0821        0.819      0.00853\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     60     1      0.00842      0.00837     4.25e-05       0.0534       0.0708       0.0422       0.0758        0.059       0.0546       0.0952       0.0749        0.422      0.00439\n","     60     2      0.00838      0.00836     2.48e-05       0.0527       0.0707       0.0413       0.0753       0.0583       0.0537       0.0961       0.0749        0.301      0.00314\n","     60     3      0.00784      0.00781     2.83e-05       0.0512       0.0684       0.0403       0.0729       0.0566       0.0517       0.0932       0.0724        0.312      0.00325\n","     60     4      0.00822      0.00817     5.44e-05        0.052       0.0699       0.0409       0.0741       0.0575       0.0527       0.0955       0.0741        0.473      0.00493\n","     60     5      0.00766      0.00761     4.64e-05        0.051       0.0675       0.0409       0.0711        0.056       0.0532       0.0895       0.0713        0.411      0.00428\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              60  190.924    0.005      0.00887     9.39e-05      0.00896       0.0553       0.0728       0.0452       0.0757       0.0604       0.0578       0.0961        0.077        0.602      0.00627\n","! Validation         60  190.924    0.005      0.00806     3.93e-05       0.0081        0.052       0.0695       0.0411       0.0738       0.0575       0.0532       0.0939       0.0736        0.384        0.004\n","Wall time: 190.9245019660002\n","! Best model       60    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     61     1       0.0126       0.0124     0.000178       0.0672       0.0862       0.0585       0.0845       0.0715       0.0732        0.108       0.0904        0.961         0.01\n","     61     2      0.00898      0.00892     5.85e-05       0.0556       0.0731       0.0453       0.0762       0.0607       0.0581       0.0963       0.0772        0.448      0.00467\n","     61     3      0.00712      0.00677     0.000341       0.0478       0.0637       0.0372       0.0691       0.0532       0.0476       0.0874       0.0675         1.31       0.0137\n","     61     4      0.00745      0.00732     0.000123       0.0503       0.0662       0.0397       0.0713       0.0555         0.05       0.0903       0.0701        0.766      0.00798\n","     61     5      0.00765      0.00753      0.00012       0.0514       0.0671       0.0431       0.0681       0.0556       0.0535       0.0883       0.0709        0.786      0.00818\n","     61     6      0.00717      0.00668     0.000487       0.0481       0.0632       0.0394       0.0654       0.0524       0.0499       0.0837       0.0668         1.58       0.0165\n","     61     7      0.00743      0.00731     0.000116         0.05       0.0661       0.0396       0.0708       0.0552       0.0509       0.0891         0.07        0.581      0.00605\n","     61     8      0.00804      0.00775     0.000285       0.0523       0.0681       0.0428       0.0714       0.0571       0.0542       0.0896       0.0719         1.18       0.0122\n","     61     9      0.00888      0.00876     0.000123       0.0557       0.0724       0.0466       0.0737       0.0602       0.0586       0.0941       0.0764        0.729      0.00759\n","     61    10       0.0078      0.00762     0.000185       0.0511       0.0675         0.04       0.0732       0.0566       0.0508       0.0923       0.0715        0.949      0.00989\n","     61    11      0.00781      0.00757     0.000244       0.0505       0.0673       0.0414       0.0688       0.0551       0.0536       0.0886       0.0711         1.09       0.0114\n","     61    12      0.00983       0.0098     2.89e-05       0.0579       0.0766       0.0465       0.0808       0.0636       0.0598        0.102        0.081        0.328      0.00341\n","     61    13      0.00983      0.00973     0.000104       0.0594       0.0763        0.051       0.0764       0.0637       0.0634       0.0971       0.0802        0.643       0.0067\n","     61    14      0.00961      0.00932      0.00029       0.0565       0.0747       0.0466       0.0761       0.0614       0.0595       0.0983       0.0789         1.23       0.0129\n","     61    15      0.00808      0.00792     0.000157        0.052       0.0689       0.0399       0.0763       0.0581       0.0515       0.0945        0.073        0.887      0.00924\n","     61    16      0.00922      0.00872     0.000496       0.0557       0.0723       0.0474       0.0722       0.0598       0.0604       0.0915       0.0759         1.63       0.0169\n","     61    17       0.0103       0.0103     4.21e-05       0.0606       0.0783       0.0518       0.0781        0.065       0.0653       0.0994       0.0824        0.377      0.00393\n","     61    18      0.00959      0.00922     0.000367       0.0565       0.0743       0.0452       0.0791       0.0621       0.0572          0.1       0.0786         1.34        0.014\n","     61    19      0.00884      0.00864     0.000203       0.0541       0.0719       0.0415       0.0793       0.0604       0.0534       0.0991       0.0762        0.992       0.0103\n","     61    20      0.00745      0.00721     0.000236       0.0497       0.0657       0.0405        0.068       0.0542        0.052       0.0868       0.0694         1.12       0.0116\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     61     1      0.00835      0.00831     4.25e-05       0.0532       0.0705        0.042       0.0755       0.0587       0.0543       0.0949       0.0746         0.42      0.00438\n","     61     2      0.00832       0.0083     2.48e-05       0.0524       0.0705       0.0411       0.0751       0.0581       0.0534       0.0958       0.0746        0.302      0.00314\n","     61     3      0.00778      0.00775     2.84e-05        0.051       0.0681       0.0401       0.0727       0.0564       0.0514       0.0929       0.0722        0.313      0.00326\n","     61     4      0.00816       0.0081     5.43e-05       0.0518       0.0696       0.0407       0.0739       0.0573       0.0523       0.0952       0.0738        0.473      0.00492\n","     61     5       0.0076      0.00755     4.65e-05       0.0507       0.0672       0.0407       0.0709       0.0558       0.0529       0.0892       0.0711        0.411      0.00429\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              61  194.022    0.005      0.00847     0.000209      0.00868       0.0541       0.0712       0.0442       0.0739       0.0591       0.0565        0.094       0.0752        0.946      0.00986\n","! Validation         61  194.022    0.005        0.008     3.93e-05      0.00804       0.0518       0.0692       0.0409       0.0736       0.0573       0.0529       0.0937       0.0733        0.384        0.004\n","Wall time: 194.02298653300022\n","! Best model       61    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     62     1      0.00733      0.00695     0.000386       0.0495       0.0645       0.0391       0.0703       0.0547       0.0492       0.0874       0.0683         1.44        0.015\n","     62     2      0.00777      0.00772     4.38e-05       0.0513        0.068       0.0415        0.071       0.0562       0.0535       0.0902       0.0719         0.39      0.00407\n","     62     3      0.00754      0.00717     0.000369       0.0493       0.0655       0.0388       0.0705       0.0546       0.0503       0.0884       0.0693          1.4       0.0146\n","     62     4      0.00692      0.00665     0.000276        0.047       0.0631       0.0355       0.0701       0.0528       0.0453       0.0885       0.0669         1.22       0.0127\n","     62     5      0.00855      0.00849     5.39e-05       0.0538       0.0713       0.0428       0.0757       0.0593        0.055       0.0959       0.0755         0.48        0.005\n","     62     6      0.00792      0.00735      0.00057       0.0499       0.0663       0.0391       0.0716       0.0553       0.0495       0.0911       0.0703         1.73        0.018\n","     62     7      0.00721      0.00714     6.78e-05       0.0505       0.0654       0.0411       0.0693       0.0552       0.0515       0.0867       0.0691        0.594      0.00619\n","     62     8      0.00737      0.00726     0.000109       0.0499       0.0659       0.0403       0.0689       0.0546       0.0515       0.0879       0.0697        0.707      0.00736\n","     62     9      0.00824      0.00809     0.000154       0.0535       0.0696       0.0454       0.0697       0.0576       0.0567         0.09       0.0733         0.83      0.00864\n","     62    10      0.00998      0.00994     3.43e-05       0.0591       0.0771       0.0491       0.0793       0.0642        0.063       0.0996       0.0813        0.407      0.00424\n","     62    11      0.00745      0.00726     0.000186       0.0496       0.0659       0.0379       0.0731       0.0555       0.0474       0.0925       0.0699        0.981       0.0102\n","     62    12      0.00851       0.0084     0.000113       0.0528       0.0709       0.0414       0.0756       0.0585       0.0537       0.0965       0.0751        0.618      0.00644\n","     62    13      0.00808        0.008     8.05e-05       0.0519       0.0692       0.0427       0.0705       0.0566       0.0553       0.0908       0.0731        0.531      0.00554\n","     62    14      0.00821      0.00805     0.000162       0.0512       0.0694       0.0397        0.074       0.0569        0.051       0.0962       0.0736        0.932       0.0097\n","     62    15      0.00803        0.008     2.76e-05       0.0519       0.0692       0.0413       0.0731       0.0572       0.0541       0.0923       0.0732        0.297      0.00309\n","     62    16       0.0078      0.00745     0.000351       0.0504       0.0668       0.0398       0.0716       0.0557       0.0509       0.0905       0.0707         1.28       0.0133\n","     62    17      0.00806      0.00802     3.77e-05       0.0523       0.0693       0.0427       0.0715       0.0571        0.055       0.0913       0.0732        0.364      0.00379\n","     62    18      0.00913      0.00902     0.000106       0.0561       0.0735       0.0476       0.0732       0.0604       0.0603       0.0945       0.0774        0.688      0.00717\n","     62    19      0.00696      0.00674     0.000215       0.0484       0.0635       0.0387       0.0679       0.0533       0.0484       0.0862       0.0673        0.981       0.0102\n","     62    20      0.00762      0.00756      6.4e-05       0.0521       0.0672       0.0431       0.0699       0.0565       0.0545       0.0873       0.0709        0.483      0.00504\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     62     1      0.00829      0.00825     4.31e-05       0.0529       0.0703       0.0418       0.0753       0.0585        0.054       0.0947       0.0744         0.43      0.00448\n","     62     2      0.00827      0.00824     2.45e-05       0.0523       0.0702       0.0409       0.0749       0.0579       0.0532       0.0956       0.0744        0.298       0.0031\n","     62     3      0.00774      0.00771     2.76e-05       0.0508       0.0679         0.04       0.0726       0.0563       0.0512       0.0927        0.072        0.306      0.00319\n","     62     4       0.0081      0.00804     5.37e-05       0.0516       0.0694       0.0405       0.0737       0.0571       0.0521        0.095       0.0735        0.469      0.00489\n","     62     5      0.00754       0.0075     4.55e-05       0.0505        0.067       0.0405       0.0707       0.0556       0.0526        0.089       0.0708        0.408      0.00425\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              62  197.134    0.005      0.00776      0.00017      0.00793       0.0515       0.0682       0.0414       0.0718       0.0566        0.053       0.0913       0.0721        0.818      0.00852\n","! Validation         62  197.134    0.005      0.00795     3.89e-05      0.00799       0.0516        0.069       0.0407       0.0734       0.0571       0.0526       0.0934        0.073        0.382      0.00398\n","Wall time: 197.13528321400008\n","! Best model       62    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     63     1      0.00836      0.00827     8.46e-05       0.0525       0.0704       0.0417       0.0743        0.058       0.0542       0.0947       0.0745        0.601      0.00626\n","     63     2      0.00822      0.00783     0.000394       0.0523       0.0684       0.0409       0.0753       0.0581       0.0508       0.0943       0.0725         1.42       0.0148\n","     63     3      0.00927      0.00924     3.06e-05       0.0557       0.0744       0.0434       0.0804       0.0619       0.0561        0.101       0.0788        0.348      0.00363\n","     63     4      0.00849      0.00837     0.000119        0.055       0.0708       0.0478       0.0694       0.0586       0.0606       0.0876       0.0741        0.681      0.00709\n","     63     5      0.00967      0.00948     0.000189       0.0578       0.0753       0.0486       0.0764       0.0625       0.0616       0.0972       0.0794        0.986       0.0103\n","     63     6      0.00772      0.00759     0.000127       0.0516       0.0674       0.0413       0.0723       0.0568       0.0523       0.0904       0.0713        0.776      0.00809\n","     63     7      0.00776      0.00772     3.33e-05       0.0509        0.068       0.0403       0.0721       0.0562       0.0529       0.0909       0.0719        0.348      0.00363\n","     63     8         0.01      0.00998     3.14e-05       0.0594       0.0773       0.0497       0.0788       0.0643       0.0625        0.101       0.0815        0.298      0.00311\n","     63     9       0.0123       0.0123     2.95e-05       0.0677       0.0857       0.0618       0.0797       0.0707       0.0759        0.102       0.0892        0.306      0.00319\n","     63    10      0.00818      0.00802     0.000161       0.0528       0.0693       0.0435       0.0715       0.0575       0.0547       0.0918       0.0732        0.767      0.00799\n","     63    11      0.00703      0.00699     3.49e-05       0.0483       0.0647       0.0377       0.0693       0.0535       0.0487       0.0884       0.0686        0.368      0.00384\n","     63    12      0.00955      0.00951     3.86e-05       0.0582       0.0754       0.0479       0.0789       0.0634       0.0606       0.0986       0.0796        0.364      0.00379\n","     63    13       0.0107       0.0107     3.24e-05       0.0632         0.08       0.0544       0.0809       0.0676       0.0672        0.101       0.0841        0.366      0.00381\n","     63    14       0.0103       0.0102     4.84e-05       0.0606       0.0783        0.052       0.0778       0.0649        0.065       0.0997       0.0823        0.451       0.0047\n","     63    15      0.00761      0.00744     0.000178       0.0508       0.0667        0.042       0.0683       0.0551       0.0536       0.0872       0.0704        0.957      0.00997\n","     63    16      0.00756      0.00752     4.25e-05       0.0506       0.0671       0.0396       0.0727       0.0562       0.0505       0.0916       0.0711        0.397      0.00414\n","     63    17       0.0103      0.00994     0.000318       0.0596       0.0771       0.0514        0.076       0.0637       0.0648       0.0972        0.081         1.29       0.0135\n","     63    18       0.0125       0.0124     9.86e-05       0.0674       0.0862       0.0572       0.0879       0.0725       0.0718         0.11       0.0907        0.628      0.00655\n","     63    19       0.0106       0.0105     7.09e-05       0.0603       0.0793       0.0515       0.0781       0.0648       0.0651        0.102       0.0835        0.602      0.00627\n","     63    20      0.00686       0.0068     6.11e-05       0.0482       0.0638       0.0389       0.0667       0.0528       0.0486       0.0865       0.0675        0.544      0.00566\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     63     1      0.00823      0.00819     4.33e-05       0.0527         0.07       0.0415       0.0751       0.0583       0.0538       0.0944       0.0741        0.433      0.00451\n","     63     2      0.00821      0.00819     2.45e-05       0.0521         0.07       0.0407       0.0747       0.0577       0.0529       0.0954       0.0741        0.298      0.00311\n","     63     3      0.00769      0.00767     2.73e-05       0.0507       0.0677       0.0398       0.0724       0.0561        0.051       0.0926       0.0718        0.304      0.00317\n","     63     4      0.00804      0.00799     5.35e-05       0.0514       0.0691       0.0403       0.0736       0.0569       0.0518       0.0947       0.0733        0.468      0.00488\n","     63     5      0.00748      0.00744     4.53e-05       0.0503       0.0667       0.0403       0.0705       0.0554       0.0523       0.0887       0.0705        0.407      0.00424\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              63  200.251    0.005      0.00904     0.000106      0.00915       0.0562       0.0736       0.0466       0.0753        0.061       0.0594       0.0959       0.0776        0.625      0.00651\n","! Validation         63  200.251    0.005      0.00789     3.88e-05      0.00793       0.0514       0.0687       0.0405       0.0733       0.0569       0.0524       0.0932       0.0728        0.382      0.00398\n","Wall time: 200.25206204900041\n","! Best model       63    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     64     1      0.00857      0.00844     0.000138       0.0532       0.0711       0.0427       0.0742       0.0585       0.0555       0.0948       0.0751        0.864        0.009\n","     64     2      0.00963      0.00944     0.000186       0.0588       0.0752       0.0495       0.0773       0.0634       0.0611       0.0973       0.0792        0.962         0.01\n","     64     3      0.00893      0.00869     0.000243       0.0547       0.0721       0.0452       0.0737       0.0595       0.0579       0.0944       0.0761         1.01       0.0106\n","     64     4      0.00735      0.00732     3.23e-05       0.0501       0.0662       0.0399       0.0707       0.0553       0.0501       0.0902       0.0701        0.379      0.00395\n","     64     5      0.00821      0.00797      0.00024       0.0518        0.069        0.042       0.0715       0.0567       0.0537       0.0924        0.073         1.14       0.0119\n","     64     6       0.0077      0.00767     2.96e-05       0.0504       0.0678       0.0398       0.0717       0.0558        0.051       0.0927       0.0718        0.295      0.00307\n","     64     7      0.00761      0.00754     6.58e-05       0.0503       0.0672       0.0395        0.072       0.0558       0.0518       0.0905       0.0711        0.495      0.00515\n","     64     8      0.00776      0.00769     6.69e-05        0.051       0.0679       0.0416       0.0699       0.0557       0.0538       0.0896       0.0717        0.578      0.00602\n","     64     9      0.00717       0.0071     7.03e-05       0.0487       0.0652       0.0394       0.0673       0.0533       0.0507       0.0872        0.069        0.453      0.00472\n","     64    10      0.00819      0.00815     3.38e-05       0.0527       0.0699       0.0416       0.0748       0.0582       0.0537       0.0941       0.0739        0.421      0.00439\n","     64    11       0.0066      0.00656     3.74e-05       0.0474       0.0627       0.0382       0.0658        0.052       0.0483       0.0843       0.0663          0.4      0.00416\n","     64    12      0.00814      0.00812     2.57e-05       0.0519       0.0697       0.0393       0.0772       0.0582       0.0498       0.0981       0.0739        0.341      0.00356\n","     64    13      0.00846      0.00841     4.28e-05       0.0526        0.071       0.0421       0.0736       0.0578       0.0536       0.0968       0.0752        0.318      0.00331\n","     64    14      0.00778      0.00774     4.36e-05       0.0526       0.0681       0.0447       0.0682       0.0565       0.0564       0.0868       0.0716        0.438      0.00457\n","     64    15      0.00736      0.00731     5.37e-05       0.0498       0.0661       0.0411        0.067       0.0541       0.0526       0.0871       0.0698        0.446      0.00464\n","     64    16      0.00808      0.00803     5.27e-05       0.0528       0.0693       0.0414       0.0754       0.0584       0.0534       0.0934       0.0734        0.449      0.00467\n","     64    17      0.00796      0.00793     2.86e-05        0.052       0.0689       0.0412       0.0735       0.0574       0.0535       0.0923       0.0729         0.26       0.0027\n","     64    18      0.00792       0.0078      0.00012         0.05       0.0683       0.0378       0.0744       0.0561       0.0504       0.0945       0.0725        0.693      0.00721\n","     64    19      0.00852      0.00849     3.23e-05       0.0535       0.0713       0.0399       0.0808       0.0604       0.0511          0.1       0.0756        0.353      0.00368\n","     64    20      0.00737      0.00722      0.00015       0.0498       0.0657       0.0404       0.0688       0.0546       0.0516       0.0874       0.0695         0.75      0.00781\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     64     1      0.00817      0.00813     4.33e-05       0.0525       0.0697       0.0413       0.0748       0.0581       0.0535       0.0942       0.0738        0.433      0.00451\n","     64     2      0.00816      0.00814     2.45e-05       0.0519       0.0698       0.0405       0.0746       0.0576       0.0527       0.0952       0.0739        0.298      0.00311\n","     64     3      0.00765      0.00762     2.74e-05       0.0505       0.0675       0.0396       0.0723       0.0559       0.0508       0.0924       0.0716        0.305      0.00317\n","     64     4      0.00798      0.00793     5.35e-05       0.0512       0.0689       0.0401       0.0733       0.0567       0.0515       0.0945        0.073        0.468      0.00487\n","     64     5      0.00744      0.00739     4.54e-05       0.0502       0.0665       0.0401       0.0703       0.0552       0.0521       0.0886       0.0703        0.408      0.00425\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              64  203.383    0.005      0.00788     8.46e-05      0.00797       0.0517       0.0687       0.0414       0.0724       0.0569       0.0531       0.0923       0.0727        0.553      0.00576\n","! Validation         64  203.383    0.005      0.00784     3.88e-05      0.00788       0.0512       0.0685       0.0403       0.0731       0.0567       0.0521        0.093       0.0726        0.382      0.00398\n","Wall time: 203.38373119400057\n","! Best model       64    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     65     1      0.00789      0.00784        5e-05       0.0512       0.0685         0.04       0.0734       0.0567        0.052        0.093       0.0725         0.42      0.00437\n","     65     2      0.00785      0.00782     3.53e-05       0.0513       0.0684       0.0415       0.0709       0.0562       0.0529       0.0918       0.0724        0.324      0.00338\n","     65     3      0.00866      0.00861     4.53e-05       0.0555       0.0718       0.0476       0.0713       0.0594         0.06       0.0909       0.0755        0.389      0.00405\n","     65     4      0.00747      0.00739     7.98e-05       0.0499       0.0665       0.0403       0.0691       0.0547       0.0508         0.09       0.0704         0.59      0.00615\n","     65     5       0.0105       0.0105      3.9e-05       0.0626       0.0793       0.0578       0.0722        0.065       0.0725       0.0913       0.0819        0.432       0.0045\n","     65     6      0.00938      0.00935     3.63e-05       0.0588       0.0748        0.054       0.0683       0.0612       0.0671       0.0882       0.0777        0.423      0.00441\n","     65     7      0.00808      0.00806      2.1e-05       0.0521       0.0694       0.0401       0.0762       0.0581       0.0506       0.0967       0.0736        0.297      0.00309\n","     65     8      0.00743      0.00738     5.24e-05       0.0512       0.0665       0.0426       0.0683       0.0555       0.0535       0.0868       0.0701          0.4      0.00417\n","     65     9       0.0104       0.0103     6.12e-05       0.0597       0.0787       0.0479       0.0833       0.0656       0.0612        0.105       0.0832        0.496      0.00517\n","     65    10      0.00997      0.00966     0.000308       0.0571        0.076       0.0459       0.0797       0.0628       0.0586        0.102       0.0805         1.27       0.0133\n","     65    11      0.00863      0.00861     2.64e-05       0.0564       0.0718       0.0483       0.0724       0.0604       0.0607         0.09       0.0753        0.353      0.00368\n","     65    12      0.00795      0.00786     8.79e-05       0.0523       0.0686       0.0426       0.0718       0.0572        0.054        0.091       0.0725        0.429      0.00447\n","     65    13      0.00864      0.00846     0.000185        0.055       0.0712       0.0481       0.0689       0.0585       0.0601       0.0893       0.0747        0.949      0.00989\n","     65    14      0.00803      0.00795     8.51e-05       0.0526        0.069       0.0419       0.0739       0.0579        0.054       0.0919       0.0729        0.661      0.00689\n","     65    15      0.00835       0.0082     0.000145       0.0534       0.0701       0.0444       0.0713       0.0579       0.0571       0.0907       0.0739        0.769      0.00801\n","     65    16      0.00814      0.00812     2.08e-05       0.0542       0.0697       0.0461       0.0705       0.0583        0.058       0.0886       0.0733        0.277      0.00289\n","     65    17      0.00841      0.00805     0.000352       0.0529       0.0694       0.0428        0.073       0.0579       0.0538       0.0931       0.0735         1.36       0.0142\n","     65    18      0.00747      0.00743     4.47e-05       0.0503       0.0667       0.0408       0.0693        0.055       0.0526       0.0883       0.0705        0.439      0.00457\n","     65    19      0.00835       0.0083     4.43e-05        0.053       0.0705       0.0412       0.0765       0.0588       0.0524       0.0971       0.0747        0.423       0.0044\n","     65    20      0.00842      0.00828     0.000138       0.0541       0.0704       0.0443       0.0738        0.059       0.0552       0.0936       0.0744        0.833      0.00867\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     65     1      0.00813      0.00809     4.33e-05       0.0523       0.0696       0.0412       0.0747       0.0579       0.0533        0.094       0.0737        0.432       0.0045\n","     65     2      0.00811      0.00808     2.45e-05       0.0517       0.0696       0.0404       0.0744       0.0574       0.0524       0.0949       0.0737        0.299      0.00311\n","     65     3      0.00761      0.00758     2.75e-05       0.0503       0.0674       0.0394       0.0721       0.0558       0.0505       0.0922       0.0714        0.306      0.00318\n","     65     4      0.00794      0.00788     5.34e-05        0.051       0.0687       0.0399       0.0732       0.0566       0.0513       0.0943       0.0728        0.467      0.00487\n","     65     5      0.00739      0.00734     4.55e-05         0.05       0.0663       0.0399       0.0701        0.055       0.0518       0.0884       0.0701        0.409      0.00426\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              65  206.508    0.005      0.00841     9.29e-05       0.0085       0.0542       0.0709       0.0449       0.0727       0.0588       0.0571       0.0926       0.0749        0.577      0.00601\n","! Validation         65  206.508    0.005      0.00779     3.89e-05      0.00783       0.0511       0.0683       0.0402       0.0729       0.0565       0.0519       0.0928       0.0723        0.382      0.00398\n","Wall time: 206.50884402700012\n","! Best model       65    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     66     1      0.00849      0.00844      5.4e-05        0.056       0.0711       0.0484       0.0712       0.0598       0.0608       0.0881       0.0744        0.527      0.00549\n","     66     2      0.00703       0.0069      0.00013       0.0482       0.0642        0.038       0.0688       0.0534       0.0477       0.0885       0.0681        0.729       0.0076\n","     66     3      0.00856      0.00854      1.5e-05       0.0555       0.0715       0.0458       0.0748       0.0603       0.0577       0.0932       0.0754        0.284      0.00296\n","     66     4      0.00676      0.00671     4.97e-05       0.0475       0.0634       0.0373        0.068       0.0526       0.0484       0.0858       0.0671        0.432       0.0045\n","     66     5      0.00766      0.00763     3.08e-05       0.0513       0.0676       0.0404        0.073       0.0567       0.0515       0.0917       0.0716        0.278      0.00289\n","     66     6      0.00798      0.00794     3.72e-05       0.0531       0.0689       0.0424       0.0744       0.0584        0.054       0.0918       0.0729        0.397      0.00414\n","     66     7      0.00808      0.00808     3.02e-06       0.0522       0.0695       0.0409       0.0748       0.0579        0.052       0.0953       0.0737        0.114      0.00119\n","     66     8      0.00793      0.00788     5.81e-05        0.053       0.0687        0.045       0.0689        0.057       0.0576       0.0866       0.0721        0.496      0.00516\n","     66     9      0.00798      0.00796     2.07e-05        0.053        0.069        0.045        0.069        0.057       0.0571       0.0882       0.0726        0.225      0.00234\n","     66    10      0.00701      0.00697     3.73e-05       0.0489       0.0646       0.0384         0.07       0.0542       0.0483       0.0887       0.0685        0.362      0.00377\n","     66    11      0.00827      0.00813     0.000143        0.053       0.0698       0.0414        0.076       0.0587       0.0522       0.0956       0.0739        0.796       0.0083\n","     66    12      0.00783      0.00778     4.99e-05       0.0527       0.0682       0.0437       0.0707       0.0572       0.0556       0.0882       0.0719        0.417      0.00435\n","     66    13      0.00893      0.00887     5.44e-05       0.0567       0.0729       0.0475       0.0749       0.0612       0.0604       0.0929       0.0767        0.456      0.00475\n","     66    14      0.00707       0.0069     0.000171       0.0485       0.0643       0.0387       0.0681       0.0534       0.0494       0.0867        0.068        0.804      0.00837\n","     66    15      0.00918      0.00913     4.31e-05       0.0555       0.0739       0.0453       0.0758       0.0606       0.0584       0.0978       0.0781        0.377      0.00392\n","     66    16      0.00688      0.00685     3.73e-05       0.0477        0.064       0.0369       0.0695       0.0532        0.047       0.0888       0.0679        0.408      0.00426\n","     66    17      0.00777      0.00771     5.79e-05       0.0514       0.0679       0.0408       0.0727       0.0567       0.0524       0.0914       0.0719        0.487      0.00507\n","     66    18       0.0076      0.00755     5.57e-05        0.049       0.0672       0.0384       0.0702       0.0543       0.0492       0.0933       0.0713        0.497      0.00518\n","     66    19       0.0079      0.00789     6.83e-06       0.0508       0.0687       0.0397       0.0729       0.0563       0.0506       0.0951       0.0729        0.156      0.00163\n","     66    20      0.00793      0.00789     3.45e-05       0.0524       0.0687       0.0448       0.0676       0.0562        0.057       0.0876       0.0723        0.326      0.00339\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     66     1      0.00807      0.00803      4.3e-05       0.0521       0.0693        0.041       0.0744       0.0577        0.053       0.0938       0.0734        0.428      0.00446\n","     66     2      0.00806      0.00803     2.45e-05       0.0515       0.0693       0.0402       0.0742       0.0572       0.0522       0.0947       0.0735        0.299      0.00312\n","     66     3      0.00757      0.00754     2.79e-05       0.0502       0.0672       0.0393        0.072       0.0556       0.0503       0.0921       0.0712        0.308      0.00321\n","     66     4      0.00788      0.00783     5.36e-05       0.0508       0.0685       0.0397        0.073       0.0564        0.051       0.0941       0.0726        0.468      0.00488\n","     66     5      0.00734      0.00729     4.59e-05       0.0498       0.0661       0.0397         0.07       0.0548       0.0516       0.0881       0.0699         0.41      0.00427\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              66  209.639    0.005      0.00779     5.45e-05      0.00784       0.0518       0.0683       0.0419       0.0716       0.0568       0.0535       0.0908       0.0722        0.428      0.00446\n","! Validation         66  209.639    0.005      0.00774      3.9e-05      0.00778       0.0509       0.0681         0.04       0.0727       0.0563       0.0516       0.0926       0.0721        0.383      0.00399\n","Wall time: 209.63951680900027\n","! Best model       66    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     67     1      0.00758      0.00754     3.91e-05       0.0511       0.0672       0.0414       0.0703       0.0559        0.053        0.089        0.071        0.374       0.0039\n","     67     2      0.00792      0.00783     9.26e-05       0.0509       0.0685       0.0401       0.0723       0.0562       0.0515       0.0936       0.0725        0.674      0.00702\n","     67     3      0.00714      0.00704     0.000101       0.0498       0.0649       0.0406        0.068       0.0543       0.0503        0.087       0.0687        0.708      0.00738\n","     67     4      0.00837      0.00834     3.12e-05       0.0532       0.0706       0.0407       0.0781       0.0594       0.0522       0.0976       0.0749        0.243      0.00254\n","     67     5      0.00874      0.00871     2.72e-05       0.0546       0.0722       0.0438       0.0761       0.0599       0.0555       0.0974       0.0764        0.297      0.00309\n","     67     6      0.00795      0.00792     3.86e-05       0.0521       0.0688       0.0414       0.0737       0.0575       0.0531       0.0926       0.0728        0.432       0.0045\n","     67     7      0.00921       0.0091     0.000107       0.0552       0.0738       0.0433       0.0792       0.0612       0.0552        0.101       0.0782        0.739      0.00769\n","     67     8        0.012       0.0119     2.35e-05       0.0663       0.0845       0.0619        0.075       0.0685       0.0774       0.0973       0.0874         0.31      0.00323\n","     67     9       0.0128       0.0126     0.000188       0.0684       0.0868       0.0612       0.0827       0.0719       0.0761        0.105       0.0906        0.895      0.00932\n","     67    10       0.0108       0.0106     0.000178       0.0614       0.0796       0.0499       0.0844       0.0672       0.0624        0.106       0.0841        0.901      0.00939\n","     67    11        0.006      0.00592     8.08e-05       0.0452       0.0595       0.0353        0.065       0.0501       0.0441       0.0821       0.0631        0.538      0.00561\n","     67    12       0.0108       0.0105      0.00028       0.0606       0.0794       0.0476       0.0865        0.067       0.0599        0.108       0.0842         1.22       0.0127\n","     67    13       0.0118       0.0118     3.94e-05       0.0654        0.084       0.0556       0.0851       0.0703       0.0696        0.107       0.0884        0.377      0.00393\n","     67    14      0.00905      0.00879     0.000251       0.0572       0.0726       0.0532       0.0651       0.0591       0.0668       0.0829       0.0748          1.1       0.0115\n","     67    15      0.00778      0.00778     5.65e-06       0.0514       0.0682       0.0396       0.0751       0.0573       0.0513       0.0933       0.0723        0.156      0.00163\n","     67    16       0.0119       0.0119     2.61e-05       0.0681       0.0844       0.0665       0.0713       0.0689       0.0811       0.0905       0.0858        0.359      0.00374\n","     67    17       0.0113       0.0112     8.09e-05       0.0648       0.0819       0.0569       0.0805       0.0687       0.0709          0.1       0.0857         0.65      0.00677\n","     67    18      0.00912       0.0091     2.08e-05       0.0551       0.0738       0.0422       0.0809       0.0615       0.0548        0.102       0.0782        0.273      0.00284\n","     67    19      0.00851      0.00845     5.73e-05       0.0541       0.0711       0.0453       0.0719       0.0586       0.0577       0.0923        0.075        0.539      0.00561\n","     67    20       0.0123       0.0123     2.74e-05       0.0652       0.0857       0.0502       0.0953       0.0727       0.0627        0.119       0.0908        0.365       0.0038\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     67     1      0.00802      0.00798      4.3e-05       0.0519       0.0691       0.0408       0.0743       0.0575       0.0527       0.0936       0.0732        0.428      0.00446\n","     67     2      0.00801      0.00799     2.45e-05       0.0514       0.0691         0.04       0.0741       0.0571        0.052       0.0945       0.0733        0.299      0.00312\n","     67     3      0.00752       0.0075     2.79e-05         0.05        0.067       0.0391       0.0718       0.0555       0.0501       0.0919        0.071        0.308      0.00321\n","     67     4      0.00784      0.00778     5.35e-05       0.0506       0.0683       0.0395       0.0729       0.0562       0.0508       0.0939       0.0723        0.468      0.00487\n","     67     5      0.00729      0.00724     4.59e-05       0.0496       0.0658       0.0395       0.0698       0.0546       0.0513        0.088       0.0696         0.41      0.00427\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              67  212.752    0.005      0.00947     8.48e-05      0.00955       0.0575       0.0753       0.0478       0.0768       0.0623       0.0611       0.0976       0.0794        0.558      0.00581\n","! Validation         67  212.752    0.005       0.0077      3.9e-05      0.00774       0.0507       0.0679       0.0398       0.0726       0.0562       0.0514       0.0924       0.0719        0.383      0.00399\n","Wall time: 212.7524711599999\n","! Best model       67    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     68     1       0.0104       0.0104     2.48e-05       0.0605       0.0788       0.0518        0.078       0.0649       0.0658          0.1       0.0829        0.346       0.0036\n","     68     2      0.00859      0.00853     5.62e-05       0.0548       0.0715       0.0443       0.0758       0.0601       0.0566       0.0944       0.0755        0.399      0.00416\n","     68     3      0.00932      0.00923     9.01e-05        0.057       0.0743       0.0485       0.0742       0.0613       0.0608       0.0958       0.0783        0.676      0.00705\n","     68     4        0.015       0.0149       0.0001       0.0755       0.0943       0.0726       0.0815        0.077       0.0889        0.104       0.0966        0.557       0.0058\n","     68     5       0.0146       0.0145      4.4e-05       0.0731       0.0932       0.0604       0.0985       0.0794       0.0746        0.122       0.0984        0.393      0.00409\n","     68     6      0.00833      0.00831     1.87e-05       0.0534       0.0705       0.0425       0.0753       0.0589       0.0534       0.0959       0.0747        0.253      0.00264\n","     68     7      0.00712      0.00706     6.16e-05       0.0493        0.065       0.0391       0.0697       0.0544       0.0492       0.0885       0.0689        0.457      0.00476\n","     68     8       0.0101      0.00994      0.00018       0.0584       0.0771       0.0483       0.0786       0.0634       0.0604        0.103       0.0816        0.851      0.00886\n","     68     9      0.00912      0.00898     0.000142       0.0562       0.0733       0.0487       0.0714         0.06       0.0619       0.0921        0.077        0.785      0.00818\n","     68    10      0.00743      0.00741     1.77e-05       0.0493       0.0666       0.0396       0.0689       0.0542       0.0521       0.0887       0.0704        0.251      0.00262\n","     68    11      0.00914      0.00889     0.000243       0.0574        0.073       0.0504       0.0714       0.0609       0.0632       0.0893       0.0763         1.11       0.0116\n","     68    12      0.00796      0.00794     2.77e-05       0.0518       0.0689       0.0411       0.0732       0.0572       0.0528       0.0932        0.073        0.316      0.00329\n","     68    13      0.00899      0.00893     5.94e-05       0.0572       0.0731       0.0485       0.0747       0.0616       0.0605       0.0934       0.0769        0.512      0.00533\n","     68    14      0.00921      0.00913     8.35e-05       0.0572       0.0739       0.0468       0.0779       0.0624       0.0591       0.0969        0.078        0.536      0.00558\n","     68    15      0.00976      0.00971     4.44e-05       0.0574       0.0762        0.045       0.0822       0.0636       0.0575        0.104       0.0808         0.38      0.00396\n","     68    16      0.00694      0.00691     2.97e-05       0.0488       0.0643       0.0388       0.0687       0.0538       0.0486       0.0877       0.0681        0.377      0.00393\n","     68    17      0.00823      0.00821      2.7e-05       0.0527       0.0701       0.0404       0.0773       0.0589       0.0517       0.0969       0.0743        0.341      0.00356\n","     68    18      0.00751      0.00749      2.5e-05       0.0505       0.0669       0.0411       0.0694       0.0552       0.0521       0.0895       0.0708        0.312      0.00325\n","     68    19      0.00712      0.00709     3.87e-05       0.0494       0.0651       0.0404       0.0674       0.0539       0.0519       0.0857       0.0688        0.395      0.00411\n","     68    20       0.0069      0.00685     4.79e-05       0.0485        0.064       0.0391       0.0672       0.0532       0.0501       0.0853       0.0677        0.372      0.00388\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     68     1      0.00798      0.00794      4.3e-05       0.0518       0.0689       0.0406       0.0741       0.0574       0.0525       0.0935        0.073        0.428      0.00445\n","     68     2      0.00798      0.00795     2.43e-05       0.0513        0.069       0.0399        0.074       0.0569       0.0518       0.0944       0.0731        0.299      0.00311\n","     68     3      0.00749      0.00747     2.79e-05       0.0499       0.0668        0.039       0.0717       0.0554       0.0499       0.0917       0.0708        0.308       0.0032\n","     68     4      0.00779      0.00774     5.34e-05       0.0505       0.0681       0.0393       0.0728        0.056       0.0505       0.0938       0.0721        0.467      0.00487\n","     68     5      0.00726      0.00721     4.59e-05       0.0494       0.0657       0.0393       0.0697       0.0545       0.0511       0.0879       0.0695         0.41      0.00427\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              68  215.860    0.005      0.00902      6.8e-05      0.00909       0.0559       0.0735       0.0464       0.0751       0.0607       0.0593       0.0957       0.0775        0.481      0.00501\n","! Validation         68  215.860    0.005      0.00766     3.89e-05       0.0077       0.0506       0.0677       0.0396       0.0725        0.056       0.0512       0.0923       0.0717        0.382      0.00398\n","Wall time: 215.860531069\n","! Best model       68    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     69     1      0.00764      0.00746     0.000185       0.0514       0.0668       0.0431       0.0679       0.0555       0.0548       0.0859       0.0703        0.947      0.00986\n","     69     2      0.00655       0.0065     4.77e-05       0.0463       0.0624       0.0362       0.0666       0.0514       0.0459       0.0864       0.0661        0.424      0.00441\n","     69     3      0.00693      0.00674     0.000183       0.0478       0.0635        0.038       0.0674       0.0527       0.0485       0.0861       0.0673        0.915      0.00953\n","     69     4      0.00781      0.00779     1.64e-05       0.0514       0.0683       0.0398       0.0745       0.0571       0.0508        0.094       0.0724        0.282      0.00294\n","     69     5      0.00724      0.00716     7.86e-05       0.0493       0.0655       0.0388       0.0702       0.0545       0.0506       0.0879       0.0693        0.516      0.00538\n","     69     6      0.00842      0.00841     8.45e-06       0.0543        0.071       0.0443       0.0744       0.0593       0.0572       0.0926       0.0749        0.172      0.00179\n","     69     7      0.00871      0.00871     2.43e-06       0.0552       0.0722       0.0452       0.0752       0.0602       0.0576       0.0948       0.0762        0.103      0.00107\n","     69     8      0.00602      0.00598     4.43e-05       0.0448       0.0598       0.0346       0.0653       0.0499       0.0438       0.0831       0.0634        0.398      0.00415\n","     69     9      0.00795      0.00788     7.33e-05       0.0526       0.0687       0.0421       0.0737       0.0579       0.0531       0.0923       0.0727         0.55      0.00573\n","     69    10       0.0085      0.00847     2.52e-05       0.0554       0.0712       0.0459       0.0743       0.0601       0.0567       0.0937       0.0752        0.306      0.00319\n","     69    11      0.00814      0.00811     2.41e-05       0.0528       0.0697       0.0425       0.0733       0.0579       0.0538       0.0937       0.0737        0.313      0.00326\n","     69    12      0.00635      0.00628     7.07e-05       0.0461       0.0613       0.0367       0.0648       0.0508       0.0465       0.0833       0.0649        0.551      0.00574\n","     69    13      0.00929      0.00927     2.22e-05       0.0582       0.0745       0.0505       0.0737       0.0621       0.0628       0.0936       0.0782         0.32      0.00333\n","     69    14       0.0102       0.0102     3.34e-05       0.0604       0.0782       0.0522       0.0769       0.0645       0.0656       0.0987       0.0821        0.386      0.00402\n","     69    15      0.00728      0.00726     2.35e-05       0.0505       0.0659       0.0421       0.0671       0.0546       0.0533       0.0857       0.0695        0.303      0.00316\n","     69    16      0.00777      0.00775     2.65e-05       0.0521       0.0681       0.0431       0.0702       0.0566       0.0545       0.0893       0.0719        0.355       0.0037\n","     69    17       0.0129       0.0129     6.28e-05       0.0685       0.0877       0.0577         0.09       0.0739       0.0723        0.112       0.0923        0.474      0.00494\n","     69    18       0.0135       0.0134     6.46e-05       0.0705       0.0896       0.0606       0.0902       0.0754       0.0763        0.112       0.0939        0.461       0.0048\n","     69    19      0.00857      0.00855     2.56e-05       0.0541       0.0715       0.0432       0.0759       0.0596       0.0561       0.0951       0.0756        0.281      0.00292\n","     69    20       0.0086      0.00857     2.79e-05       0.0542       0.0716       0.0444       0.0738       0.0591       0.0566       0.0948       0.0757        0.368      0.00383\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     69     1      0.00795       0.0079     4.33e-05       0.0516       0.0688       0.0405        0.074       0.0572       0.0524       0.0933       0.0728        0.431      0.00449\n","     69     2      0.00794      0.00791     2.43e-05       0.0511       0.0688       0.0398       0.0739       0.0568       0.0516       0.0942       0.0729        0.298      0.00311\n","     69     3      0.00746      0.00743     2.76e-05       0.0498       0.0667       0.0388       0.0716       0.0552       0.0498       0.0916       0.0707        0.305      0.00318\n","     69     4      0.00775       0.0077     5.32e-05       0.0503       0.0679       0.0392       0.0726       0.0559       0.0503       0.0936        0.072        0.466      0.00485\n","     69     5      0.00721      0.00717     4.57e-05       0.0493       0.0655       0.0392       0.0695       0.0544       0.0509       0.0877       0.0693        0.409      0.00426\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              69  218.983    0.005      0.00837     5.23e-05      0.00842       0.0538       0.0708        0.044       0.0733       0.0587       0.0564       0.0931       0.0747        0.421      0.00439\n","! Validation         69  218.983    0.005      0.00762     3.88e-05      0.00766       0.0504       0.0675       0.0395       0.0723       0.0559        0.051       0.0921       0.0716        0.382      0.00398\n","Wall time: 218.9840986830004\n","! Best model       69    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     70     1        0.011       0.0109     2.12e-05       0.0643        0.081       0.0593       0.0742       0.0667       0.0732       0.0945       0.0839        0.299      0.00312\n","     70     2      0.00814      0.00811     3.07e-05       0.0522       0.0697       0.0421       0.0724       0.0573       0.0548       0.0924       0.0736        0.373      0.00389\n","     70     3      0.00832      0.00829     3.51e-05       0.0547       0.0704       0.0485        0.067       0.0578       0.0611       0.0861       0.0736        0.355       0.0037\n","     70     4      0.00965       0.0096     4.91e-05       0.0588       0.0758       0.0512       0.0738       0.0625       0.0644       0.0946       0.0795        0.461       0.0048\n","     70     5      0.00725      0.00721     3.28e-05       0.0487       0.0657       0.0372       0.0716       0.0544       0.0486       0.0907       0.0697         0.33      0.00344\n","     70     6      0.00892       0.0089     2.35e-05       0.0567        0.073       0.0483       0.0735       0.0609       0.0604       0.0931       0.0768         0.29      0.00302\n","     70     7       0.0115       0.0115     2.08e-05       0.0643       0.0831        0.053        0.087         0.07       0.0658         0.11       0.0877        0.294      0.00307\n","     70     8      0.00786      0.00776     0.000101       0.0509       0.0682       0.0402       0.0723       0.0562       0.0513       0.0931       0.0722        0.652      0.00679\n","     70     9      0.00725      0.00721     4.61e-05       0.0489       0.0657       0.0375       0.0717       0.0546       0.0481       0.0912       0.0696        0.438      0.00456\n","     70    10       0.0111        0.011     9.75e-05       0.0621       0.0811       0.0521        0.082       0.0671       0.0659        0.105       0.0855        0.694      0.00723\n","     70    11      0.00755      0.00744     0.000117       0.0509       0.0667       0.0414       0.0698       0.0556       0.0525       0.0885       0.0705        0.671      0.00699\n","     70    12      0.00655      0.00647      7.9e-05       0.0474       0.0622       0.0366       0.0689       0.0528       0.0471       0.0847       0.0659          0.6      0.00625\n","     70    13      0.00958      0.00954     4.27e-05       0.0596       0.0756       0.0524       0.0739       0.0632       0.0657       0.0921       0.0789        0.464      0.00483\n","     70    14      0.00794      0.00771     0.000235        0.052       0.0679       0.0429       0.0703       0.0566       0.0544        0.089       0.0717         1.05       0.0109\n","     70    15      0.00825       0.0082     5.17e-05       0.0542         0.07       0.0456       0.0713       0.0584       0.0576         0.09       0.0738        0.489      0.00509\n","     70    16       0.0116       0.0115     0.000143       0.0656       0.0828       0.0609        0.075       0.0679       0.0756       0.0957       0.0856        0.763      0.00795\n","     70    17      0.00924      0.00916     8.17e-05       0.0561        0.074       0.0454       0.0775       0.0614       0.0579       0.0987       0.0783        0.595       0.0062\n","     70    18      0.00702      0.00691     0.000113       0.0489       0.0643       0.0389       0.0688       0.0538       0.0492        0.087       0.0681        0.671      0.00699\n","     70    19       0.0078      0.00774     5.98e-05       0.0517       0.0681       0.0413       0.0725       0.0569       0.0523       0.0918        0.072        0.501      0.00522\n","     70    20      0.00802      0.00786     0.000155       0.0514       0.0686       0.0385       0.0771       0.0578       0.0485       0.0971       0.0728        0.864        0.009\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     70     1      0.00791      0.00787     4.37e-05       0.0515       0.0686       0.0403       0.0738       0.0571       0.0522       0.0931       0.0727        0.436      0.00454\n","     70     2       0.0079      0.00788     2.42e-05        0.051       0.0687       0.0397       0.0737       0.0567       0.0515       0.0941       0.0728        0.297       0.0031\n","     70     3      0.00743       0.0074     2.72e-05       0.0496       0.0665       0.0387       0.0716       0.0551       0.0496       0.0915       0.0705        0.302      0.00315\n","     70     4      0.00772      0.00766      5.3e-05       0.0502       0.0677        0.039       0.0725       0.0558       0.0502       0.0934       0.0718        0.464      0.00483\n","     70     5      0.00717      0.00713     4.51e-05       0.0491       0.0653        0.039       0.0694       0.0542       0.0507       0.0875       0.0691        0.407      0.00424\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              70  222.108    0.005      0.00865     7.68e-05      0.00873        0.055        0.072       0.0457       0.0735       0.0596       0.0583       0.0934       0.0759        0.543      0.00565\n","! Validation         70  222.108    0.005      0.00759     3.87e-05      0.00763       0.0503       0.0674       0.0393       0.0722       0.0558       0.0508        0.092       0.0714        0.381      0.00397\n","Wall time: 222.10925635200056\n","! Best model       70    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     71     1      0.00776      0.00773     3.26e-05       0.0506        0.068        0.039       0.0738       0.0564       0.0512        0.093       0.0721        0.407      0.00424\n","     71     2       0.0075      0.00739     0.000102       0.0495       0.0665       0.0381       0.0723       0.0552       0.0487       0.0924       0.0705        0.665      0.00692\n","     71     3      0.00721      0.00713     8.07e-05       0.0493       0.0653       0.0392       0.0695       0.0544       0.0503        0.088       0.0692        0.607      0.00632\n","     71     4      0.00808      0.00798     9.74e-05       0.0528       0.0691       0.0416       0.0754       0.0585       0.0522       0.0943       0.0732        0.638      0.00665\n","     71     5      0.00786      0.00776     0.000103       0.0513       0.0681       0.0426       0.0687       0.0557       0.0549       0.0889       0.0719        0.718      0.00748\n","     71     6      0.00892      0.00883     9.31e-05       0.0555       0.0727       0.0458       0.0751       0.0604       0.0582       0.0952       0.0767        0.604       0.0063\n","     71     7       0.0064      0.00637     3.22e-05       0.0461       0.0617       0.0363       0.0658        0.051       0.0459        0.085       0.0654         0.31      0.00323\n","     71     8      0.00707      0.00705     1.84e-05       0.0497        0.065         0.04       0.0692       0.0546       0.0511       0.0863       0.0687        0.284      0.00296\n","     71     9      0.00751      0.00748     2.29e-05       0.0488       0.0669       0.0368       0.0728       0.0548       0.0484       0.0936        0.071        0.301      0.00313\n","     71    10      0.00652      0.00639     0.000136       0.0477       0.0618       0.0382       0.0667       0.0525       0.0476       0.0832       0.0654        0.822      0.00856\n","     71    11      0.00712      0.00705     7.38e-05       0.0489       0.0649       0.0384       0.0698       0.0541       0.0489       0.0887       0.0688        0.534      0.00556\n","     71    12      0.00764      0.00748     0.000161       0.0502       0.0669       0.0393       0.0722       0.0557       0.0507        0.091       0.0709         0.93      0.00968\n","     71    13       0.0073      0.00723     7.62e-05       0.0486       0.0658       0.0379         0.07        0.054       0.0486       0.0908       0.0697        0.546      0.00569\n","     71    14       0.0067      0.00655     0.000149       0.0472       0.0626       0.0375       0.0666       0.0521       0.0486       0.0839       0.0663        0.642      0.00669\n","     71    15      0.00744      0.00734     9.84e-05       0.0501       0.0663       0.0386        0.073       0.0558       0.0486        0.092       0.0703        0.653       0.0068\n","     71    16      0.00693      0.00689     3.67e-05       0.0476       0.0642       0.0378       0.0674       0.0526       0.0482       0.0879       0.0681        0.362      0.00377\n","     71    17      0.00771      0.00757     0.000142       0.0516       0.0673        0.042       0.0708       0.0564       0.0529       0.0893       0.0711        0.787       0.0082\n","     71    18      0.00675      0.00674      1.8e-05       0.0485       0.0635       0.0389       0.0676       0.0533       0.0491       0.0853       0.0672         0.26      0.00271\n","     71    19      0.00718      0.00715     3.18e-05       0.0489       0.0654       0.0389       0.0689       0.0539       0.0495       0.0891       0.0693         0.39      0.00406\n","     71    20       0.0064      0.00631     9.39e-05       0.0466       0.0614       0.0369       0.0659       0.0514       0.0473       0.0827        0.065        0.679      0.00707\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     71     1      0.00787      0.00783     4.33e-05       0.0513       0.0684       0.0402       0.0736       0.0569        0.052       0.0929       0.0725        0.431      0.00449\n","     71     2      0.00786      0.00784     2.42e-05       0.0509       0.0685       0.0395       0.0736       0.0566       0.0513       0.0939       0.0726        0.298      0.00311\n","     71     3      0.00739      0.00737     2.77e-05       0.0495       0.0664       0.0385       0.0715        0.055       0.0494       0.0914       0.0704        0.306      0.00319\n","     71     4      0.00767      0.00762     5.32e-05       0.0501       0.0675       0.0389       0.0723       0.0556         0.05       0.0932       0.0716        0.465      0.00485\n","     71     5      0.00713      0.00709     4.57e-05        0.049       0.0651       0.0389       0.0692       0.0541       0.0505       0.0873       0.0689         0.41      0.00427\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              71  225.224    0.005      0.00722        8e-05       0.0073       0.0495       0.0657       0.0392       0.0701       0.0546       0.0501       0.0891       0.0696        0.557       0.0058\n","! Validation         71  225.224    0.005      0.00755     3.88e-05      0.00759       0.0502       0.0672       0.0392       0.0721       0.0556       0.0506       0.0918       0.0712        0.382      0.00398\n","Wall time: 225.2244337359998\n","! Best model       71    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     72     1      0.00655      0.00651     3.96e-05       0.0469       0.0624       0.0374        0.066       0.0517       0.0483       0.0838        0.066        0.382      0.00398\n","     72     2      0.00646      0.00641     5.15e-05        0.046        0.062       0.0363       0.0655       0.0509       0.0468       0.0844       0.0656        0.505      0.00526\n","     72     3      0.00671      0.00669     1.93e-05       0.0479       0.0633       0.0366       0.0706       0.0536       0.0457       0.0886       0.0671        0.228      0.00237\n","     72     4      0.00757      0.00748     8.45e-05       0.0501       0.0669       0.0399       0.0706       0.0552       0.0518       0.0898       0.0708        0.574      0.00598\n","     72     5      0.00708      0.00707     1.28e-05       0.0493        0.065       0.0386       0.0708       0.0547       0.0487       0.0891       0.0689        0.228      0.00238\n","     72     6      0.00854      0.00848     6.32e-05       0.0539       0.0712       0.0428       0.0761       0.0595       0.0549       0.0959       0.0754        0.543      0.00566\n","     72     7      0.00684      0.00677     7.48e-05       0.0484       0.0637       0.0383       0.0688       0.0535       0.0483       0.0865       0.0674        0.552      0.00575\n","     72     8       0.0064       0.0063     9.74e-05       0.0465       0.0614       0.0368       0.0659       0.0513       0.0459       0.0843       0.0651        0.676      0.00704\n","     72     9      0.00717      0.00715     2.44e-05       0.0479       0.0654       0.0363       0.0712       0.0537       0.0469       0.0918       0.0694         0.28      0.00292\n","     72    10       0.0076      0.00758     2.48e-05       0.0508       0.0674       0.0401        0.072       0.0561       0.0516        0.091       0.0713        0.341      0.00355\n","     72    11      0.00736       0.0073     6.04e-05       0.0493       0.0661       0.0384       0.0712       0.0548       0.0491       0.0911       0.0701        0.468      0.00487\n","     72    12      0.00718      0.00712     5.24e-05       0.0485       0.0653       0.0377       0.0699       0.0538       0.0476       0.0909       0.0692        0.501      0.00522\n","     72    13      0.00635      0.00626     8.83e-05       0.0466       0.0612       0.0368       0.0662       0.0515       0.0465       0.0832       0.0649        0.599      0.00624\n","     72    14      0.00689      0.00685     3.58e-05       0.0479        0.064       0.0369       0.0699       0.0534       0.0472       0.0886       0.0679        0.399      0.00416\n","     72    15       0.0086      0.00854     5.74e-05       0.0542       0.0715       0.0428       0.0771       0.0599       0.0543       0.0972       0.0757        0.494      0.00514\n","     72    16      0.00846      0.00843     2.89e-05       0.0543        0.071       0.0454       0.0722       0.0588       0.0578       0.0919       0.0749        0.291      0.00303\n","     72    17      0.00722      0.00712     9.75e-05       0.0498       0.0653       0.0393       0.0708        0.055       0.0506       0.0876       0.0691        0.677      0.00705\n","     72    18      0.00672      0.00666     5.84e-05       0.0477       0.0631        0.038       0.0671       0.0525       0.0478       0.0859       0.0669        0.491      0.00511\n","     72    19      0.00737      0.00727     9.99e-05       0.0503        0.066       0.0415        0.068       0.0547       0.0523       0.0871       0.0697        0.627      0.00654\n","     72    20      0.00746      0.00742     4.39e-05       0.0499       0.0666       0.0388       0.0719       0.0554       0.0502        0.091       0.0706        0.421      0.00439\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     72     1      0.00782      0.00778     4.38e-05       0.0512       0.0682       0.0401       0.0734       0.0567       0.0518       0.0927       0.0723        0.437      0.00455\n","     72     2      0.00781      0.00779     2.42e-05       0.0507       0.0683       0.0394       0.0735       0.0564        0.051       0.0937       0.0723        0.298       0.0031\n","     72     3      0.00736      0.00733     2.74e-05       0.0494       0.0662       0.0384       0.0713       0.0549       0.0492       0.0912       0.0702        0.303      0.00316\n","     72     4      0.00763      0.00758     5.31e-05       0.0499       0.0674       0.0388       0.0721       0.0555       0.0498        0.093       0.0714        0.464      0.00484\n","     72     5      0.00709      0.00705     4.54e-05       0.0489        0.065       0.0388       0.0691       0.0539       0.0503       0.0871       0.0687        0.409      0.00426\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              72  228.344    0.005      0.00717     5.58e-05      0.00723       0.0493       0.0655       0.0389       0.0701       0.0545       0.0497       0.0891       0.0694        0.464      0.00483\n","! Validation         72  228.344    0.005       0.0075     3.88e-05      0.00754         0.05        0.067       0.0391       0.0719       0.0555       0.0504       0.0916        0.071        0.382      0.00398\n","Wall time: 228.34483463800007\n","! Best model       72    0.008\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     73     1      0.00716      0.00709     6.49e-05       0.0488       0.0652       0.0386        0.069       0.0538       0.0488       0.0893        0.069        0.499      0.00519\n","     73     2      0.00759      0.00756      2.5e-05        0.051       0.0673       0.0416       0.0699       0.0558       0.0534       0.0888       0.0711        0.294      0.00306\n","     73     3      0.00885       0.0087     0.000152       0.0545       0.0721       0.0434       0.0767       0.0601       0.0548        0.098       0.0764        0.772      0.00804\n","     73     4      0.00803      0.00798     5.53e-05       0.0519       0.0691       0.0411       0.0736       0.0574       0.0518       0.0946       0.0732        0.502      0.00523\n","     73     5       0.0073      0.00721      9.1e-05       0.0486       0.0657       0.0378         0.07       0.0539       0.0494       0.0898       0.0696         0.62      0.00646\n","     73     6      0.00901      0.00897     4.03e-05       0.0561       0.0733       0.0459       0.0765       0.0612        0.058       0.0968       0.0774        0.387      0.00404\n","     73     7      0.00971       0.0097     1.45e-05       0.0593       0.0762       0.0488       0.0803       0.0646       0.0609       0.0999       0.0804        0.229      0.00238\n","     73     8      0.00826       0.0082     5.47e-05        0.053       0.0701       0.0422       0.0744       0.0583       0.0541       0.0942       0.0742        0.404      0.00421\n","     73     9      0.00734      0.00733     1.32e-05       0.0487       0.0662       0.0373       0.0716       0.0544        0.049       0.0914       0.0702        0.222      0.00231\n","     73    10      0.00774       0.0077     3.69e-05       0.0507       0.0679       0.0403       0.0716       0.0559       0.0515       0.0924       0.0719        0.352      0.00367\n","     73    11      0.00922      0.00921     8.61e-06       0.0576       0.0742       0.0467       0.0792        0.063       0.0574       0.0997       0.0786        0.184      0.00192\n","     73    12      0.00691      0.00689      2.4e-05       0.0494       0.0642       0.0391         0.07       0.0546       0.0495       0.0864        0.068        0.287      0.00299\n","     73    13      0.00691      0.00688     3.25e-05       0.0481       0.0642       0.0379       0.0683       0.0531       0.0488       0.0871        0.068        0.383      0.00399\n","     73    14      0.00911      0.00909     1.67e-05       0.0566       0.0738       0.0468       0.0761       0.0615       0.0589       0.0968       0.0779        0.265      0.00277\n","     73    15      0.00851      0.00848     3.24e-05       0.0544       0.0712       0.0443       0.0744       0.0594       0.0567       0.0938       0.0753        0.338      0.00352\n","     73    16      0.00704      0.00699     5.54e-05       0.0486       0.0647       0.0378       0.0702        0.054       0.0481        0.089       0.0685        0.433      0.00451\n","     73    17      0.00603      0.00602     1.09e-05       0.0457         0.06       0.0363       0.0644       0.0504       0.0457       0.0814       0.0636         0.21      0.00218\n","     73    18      0.00943      0.00922     0.000212       0.0567       0.0743       0.0441       0.0819        0.063       0.0564        0.101       0.0787         1.06        0.011\n","     73    19      0.00969      0.00965     4.79e-05       0.0585        0.076       0.0488        0.078       0.0634       0.0614       0.0989       0.0801        0.421      0.00439\n","     73    20      0.00825      0.00823     2.24e-05       0.0535       0.0702       0.0435       0.0735       0.0585       0.0551       0.0933       0.0742        0.306      0.00319\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     73     1      0.00777      0.00773     4.35e-05        0.051        0.068       0.0399       0.0733       0.0566       0.0516       0.0925       0.0721        0.432       0.0045\n","     73     2      0.00776      0.00774     2.43e-05       0.0506        0.068       0.0392       0.0733       0.0563       0.0508       0.0935       0.0721        0.299      0.00312\n","     73     3      0.00732      0.00729     2.79e-05       0.0492       0.0661       0.0382       0.0712       0.0547        0.049       0.0911         0.07        0.307       0.0032\n","     73     4      0.00759      0.00754     5.34e-05       0.0498       0.0672       0.0386        0.072       0.0553       0.0496       0.0928       0.0712        0.466      0.00485\n","     73     5      0.00705        0.007      4.6e-05       0.0487       0.0647       0.0386        0.069       0.0538       0.0501       0.0869       0.0685        0.411      0.00428\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              73  231.456    0.005      0.00805     5.06e-05       0.0081       0.0526       0.0694       0.0421       0.0735       0.0578       0.0537       0.0933       0.0735        0.408      0.00425\n","! Validation         73  231.456    0.005      0.00746      3.9e-05       0.0075       0.0499       0.0668       0.0389       0.0718       0.0553       0.0502       0.0914       0.0708        0.383      0.00399\n","Wall time: 231.45667280999987\n","! Best model       73    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     74     1      0.00671      0.00666     5.86e-05       0.0469       0.0631       0.0363       0.0683       0.0523       0.0468        0.087       0.0669        0.534      0.00556\n","     74     2       0.0081      0.00806     4.53e-05       0.0537       0.0694       0.0441       0.0727       0.0584       0.0559       0.0907       0.0733         0.41      0.00427\n","     74     3      0.00759      0.00753     5.58e-05       0.0502       0.0671       0.0399       0.0708       0.0553       0.0508       0.0914       0.0711        0.493      0.00513\n","     74     4      0.00701      0.00696     5.55e-05       0.0486       0.0645       0.0376       0.0707       0.0541        0.048       0.0888       0.0684        0.473      0.00493\n","     74     5      0.00841      0.00837      4.4e-05       0.0541       0.0708        0.043       0.0763       0.0596       0.0547        0.095       0.0749        0.464      0.00483\n","     74     6      0.00789      0.00787     2.43e-05       0.0514       0.0686       0.0404       0.0734       0.0569       0.0515        0.094       0.0727         0.28      0.00291\n","     74     7      0.00741      0.00735     5.22e-05         0.05       0.0663       0.0394       0.0713       0.0553       0.0499       0.0907       0.0703         0.48        0.005\n","     74     8      0.00783      0.00769     0.000137       0.0502       0.0679       0.0394       0.0719       0.0557       0.0516       0.0921       0.0719        0.636      0.00662\n","     74     9      0.00799      0.00794     4.71e-05       0.0525        0.069       0.0419       0.0739       0.0579       0.0536       0.0923       0.0729        0.468      0.00487\n","     74    10      0.00778      0.00772     5.97e-05       0.0516        0.068       0.0416       0.0717       0.0566       0.0536       0.0902       0.0719        0.511      0.00532\n","     74    11      0.00638      0.00623     0.000143       0.0454       0.0611       0.0352       0.0656       0.0504       0.0452       0.0844       0.0648        0.811      0.00845\n","     74    12      0.00636      0.00629      6.9e-05        0.046       0.0614       0.0358       0.0663       0.0511       0.0452       0.0849       0.0651        0.547       0.0057\n","     74    13      0.00798      0.00773     0.000247       0.0516        0.068       0.0425       0.0698       0.0562       0.0547       0.0888       0.0718        0.987       0.0103\n","     74    14      0.00772      0.00765     7.56e-05       0.0507       0.0676       0.0379       0.0763       0.0571       0.0488       0.0947       0.0717        0.543      0.00566\n","     74    15      0.00732      0.00726     6.44e-05       0.0499       0.0659       0.0391       0.0716       0.0554       0.0493       0.0904       0.0698        0.502      0.00523\n","     74    16      0.00667      0.00658     8.99e-05       0.0482       0.0628       0.0392       0.0661       0.0527        0.049       0.0837       0.0664        0.602      0.00627\n","     74    17      0.00681      0.00674     6.87e-05       0.0472       0.0635        0.037       0.0676       0.0523       0.0479       0.0867       0.0673        0.548      0.00571\n","     74    18      0.00686      0.00683     3.23e-05       0.0469       0.0639       0.0359       0.0689       0.0524        0.047       0.0886       0.0678        0.354      0.00369\n","     74    19      0.00819      0.00808     0.000105       0.0525       0.0695       0.0416       0.0743        0.058        0.054       0.0932       0.0736        0.677      0.00705\n","     74    20      0.00814       0.0081     4.11e-05       0.0545       0.0696       0.0452       0.0731       0.0591       0.0562       0.0907       0.0735        0.468      0.00487\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     74     1      0.00773      0.00769     4.39e-05       0.0509       0.0678       0.0398       0.0731       0.0564       0.0514       0.0923       0.0719        0.437      0.00455\n","     74     2      0.00772      0.00769     2.43e-05       0.0504       0.0679        0.039       0.0732       0.0561       0.0506       0.0933       0.0719        0.299      0.00311\n","     74     3      0.00728      0.00725     2.75e-05       0.0491       0.0659       0.0381       0.0711       0.0546       0.0488       0.0909       0.0698        0.303      0.00316\n","     74     4      0.00754      0.00749     5.31e-05       0.0496        0.067       0.0385       0.0718       0.0552       0.0493       0.0926        0.071        0.464      0.00483\n","     74     5      0.00701      0.00696     4.55e-05       0.0486       0.0646       0.0385       0.0689       0.0537       0.0499       0.0868       0.0683        0.409      0.00427\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              74  234.555    0.005      0.00738     7.58e-05      0.00746       0.0501       0.0665       0.0397        0.071       0.0553       0.0508         0.09       0.0704        0.539      0.00562\n","! Validation         74  234.555    0.005      0.00742     3.89e-05      0.00746       0.0497       0.0666       0.0388       0.0716       0.0552         0.05       0.0912       0.0706        0.383      0.00398\n","Wall time: 234.55539452500034\n","! Best model       74    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     75     1      0.00718      0.00707     0.000115       0.0505        0.065       0.0412       0.0693       0.0552       0.0513       0.0861       0.0687        0.709      0.00738\n","     75     2      0.00732      0.00729     3.84e-05       0.0493        0.066       0.0391       0.0696       0.0544       0.0505       0.0893       0.0699        0.357      0.00372\n","     75     3      0.00918      0.00913     4.29e-05       0.0557       0.0739       0.0454       0.0762       0.0608       0.0589       0.0973       0.0781        0.433      0.00451\n","     75     4      0.00923      0.00915     7.26e-05       0.0579        0.074       0.0509       0.0718       0.0613       0.0637       0.0913       0.0775        0.509      0.00531\n","     75     5      0.00628      0.00604      0.00024       0.0458       0.0601       0.0373       0.0628         0.05       0.0468       0.0804       0.0636         1.06       0.0111\n","     75     6       0.0094      0.00916     0.000243       0.0571        0.074       0.0496       0.0722       0.0609       0.0634       0.0916       0.0775         1.06       0.0111\n","     75     7        0.011       0.0109     5.33e-05       0.0642       0.0808       0.0573       0.0779       0.0676       0.0708       0.0977       0.0843        0.472      0.00491\n","     75     8      0.00917      0.00914     2.76e-05       0.0559        0.074        0.046       0.0759       0.0609       0.0577       0.0987       0.0782        0.361      0.00376\n","     75     9      0.00661      0.00653     7.82e-05       0.0469       0.0625       0.0362       0.0684       0.0523       0.0456        0.087       0.0663        0.506      0.00527\n","     75    10      0.00845       0.0084     5.29e-05       0.0545       0.0709       0.0461       0.0714       0.0587        0.057       0.0926       0.0748        0.418      0.00436\n","     75    11       0.0106       0.0105     3.37e-05       0.0608       0.0794       0.0508       0.0807       0.0658       0.0638        0.104       0.0838        0.393       0.0041\n","     75    12      0.00816      0.00815     1.06e-05        0.053       0.0698       0.0431       0.0728       0.0579       0.0556        0.092       0.0738        0.219      0.00228\n","     75    13      0.00729      0.00726     3.44e-05       0.0486       0.0659       0.0391       0.0675       0.0533       0.0512       0.0882       0.0697        0.362      0.00377\n","     75    14         0.01         0.01     1.29e-05       0.0599       0.0774       0.0497       0.0805       0.0651       0.0622        0.101       0.0817        0.206      0.00214\n","     75    15      0.00923      0.00921     1.27e-05        0.058       0.0743       0.0496       0.0749       0.0622       0.0618       0.0944       0.0781        0.215      0.00224\n","     75    16      0.00705      0.00687     0.000171       0.0489       0.0641       0.0394       0.0678       0.0536       0.0498        0.086       0.0679         0.95       0.0099\n","     75    17      0.00653      0.00649      3.7e-05       0.0466       0.0623       0.0365       0.0667       0.0516       0.0472       0.0848        0.066        0.364      0.00379\n","     75    18      0.00786      0.00773     0.000131       0.0513        0.068       0.0415       0.0711       0.0563       0.0536       0.0902       0.0719        0.787       0.0082\n","     75    19      0.00893      0.00891     2.17e-05       0.0545        0.073       0.0408       0.0819       0.0614       0.0527        0.102       0.0775        0.251      0.00262\n","     75    20      0.00687      0.00682     5.08e-05       0.0475       0.0639       0.0365       0.0697       0.0531       0.0473       0.0881       0.0677         0.47      0.00489\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     75     1      0.00769      0.00765     4.37e-05       0.0507       0.0677       0.0396       0.0729       0.0563       0.0512       0.0922       0.0717        0.434      0.00452\n","     75     2      0.00768      0.00766     2.43e-05       0.0503       0.0677       0.0389       0.0731        0.056       0.0504       0.0931       0.0717          0.3      0.00312\n","     75     3      0.00725      0.00722     2.78e-05        0.049       0.0657       0.0379        0.071       0.0545       0.0486       0.0908       0.0697        0.305      0.00318\n","     75     4      0.00751      0.00746     5.34e-05       0.0495       0.0668       0.0383       0.0718        0.055       0.0491       0.0925       0.0708        0.466      0.00485\n","     75     5      0.00697      0.00692     4.59e-05       0.0484       0.0644       0.0383       0.0687       0.0535       0.0496       0.0866       0.0681        0.411      0.00428\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              75  237.670    0.005      0.00824      7.4e-05      0.00831       0.0533       0.0702       0.0438       0.0725       0.0581        0.056       0.0924       0.0742        0.505      0.00526\n","! Validation         75  237.670    0.005      0.00738      3.9e-05      0.00742       0.0496       0.0665       0.0386       0.0715       0.0551       0.0498       0.0911       0.0704        0.383      0.00399\n","Wall time: 237.67088495100052\n","! Best model       75    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     76     1      0.00674      0.00672     2.33e-05       0.0476       0.0634       0.0377       0.0673       0.0525       0.0488       0.0855       0.0671        0.288        0.003\n","     76     2      0.00764      0.00758     5.38e-05       0.0509       0.0674       0.0404        0.072       0.0562       0.0508       0.0919       0.0714        0.448      0.00467\n","     76     3      0.00726      0.00725     1.21e-05       0.0493       0.0659       0.0395        0.069       0.0543       0.0498       0.0898       0.0698         0.23       0.0024\n","     76     4      0.00774      0.00767     7.22e-05       0.0508       0.0677       0.0388       0.0749       0.0569       0.0495       0.0942       0.0718        0.501      0.00522\n","     76     5      0.00737      0.00736     8.72e-06       0.0502       0.0664         0.04       0.0708       0.0554       0.0516       0.0889       0.0702        0.196      0.00204\n","     76     6      0.00671       0.0066     0.000115       0.0473       0.0628        0.036       0.0699       0.0529       0.0457       0.0876       0.0666        0.677      0.00706\n","     76     7      0.00687      0.00684     2.24e-05       0.0481        0.064       0.0373       0.0698       0.0536       0.0473       0.0884       0.0678        0.307      0.00319\n","     76     8      0.00637       0.0062     0.000166       0.0447       0.0609       0.0339       0.0663       0.0501       0.0437       0.0855       0.0646        0.912       0.0095\n","     76     9      0.00627      0.00623     3.84e-05       0.0464       0.0611       0.0353       0.0688        0.052       0.0443       0.0852       0.0647        0.399      0.00416\n","     76    10      0.00735      0.00729     6.29e-05       0.0499       0.0661       0.0386       0.0724       0.0555       0.0494       0.0906         0.07        0.533      0.00556\n","     76    11      0.00734      0.00731     3.65e-05       0.0501       0.0661       0.0403       0.0699       0.0551       0.0518        0.088       0.0699        0.443      0.00461\n","     76    12      0.00809      0.00798     0.000105        0.054       0.0691       0.0452       0.0717       0.0584       0.0564       0.0893       0.0728        0.714      0.00744\n","     76    13      0.00775      0.00768     6.94e-05        0.052       0.0678       0.0421       0.0717       0.0569       0.0525        0.091       0.0718         0.49       0.0051\n","     76    14      0.00713      0.00709     3.86e-05       0.0492       0.0652       0.0397       0.0682       0.0539       0.0502       0.0877        0.069        0.415      0.00432\n","     76    15      0.00716      0.00697      0.00019       0.0478       0.0646       0.0378       0.0679       0.0529        0.049       0.0878       0.0684        0.959      0.00999\n","     76    16      0.00893      0.00872      0.00021       0.0543       0.0723       0.0433       0.0763       0.0598       0.0552       0.0978       0.0765         1.02       0.0107\n","     76    17      0.00757      0.00738     0.000189       0.0497       0.0665       0.0394       0.0702       0.0548        0.051       0.0897       0.0704        0.992       0.0103\n","     76    18      0.00734      0.00697     0.000375       0.0485       0.0646        0.038       0.0695       0.0537       0.0483       0.0885       0.0684          1.4       0.0146\n","     76    19      0.00783      0.00781     2.65e-05        0.051       0.0684        0.041       0.0711       0.0561       0.0536        0.091       0.0723        0.373      0.00388\n","     76    20      0.00706       0.0069     0.000156       0.0488       0.0643       0.0397        0.067       0.0534       0.0501       0.0859        0.068        0.872      0.00909\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     76     1      0.00765      0.00761      4.4e-05       0.0506       0.0675       0.0395       0.0728       0.0561        0.051        0.092       0.0715        0.437      0.00456\n","     76     2      0.00765      0.00762     2.43e-05       0.0502       0.0675       0.0387        0.073       0.0559       0.0502        0.093       0.0716          0.3      0.00312\n","     76     3      0.00721      0.00719     2.75e-05       0.0488       0.0656       0.0378       0.0709       0.0544       0.0484       0.0907       0.0695        0.303      0.00316\n","     76     4      0.00747      0.00741     5.32e-05       0.0493       0.0666       0.0382       0.0716       0.0549       0.0489       0.0923       0.0706        0.464      0.00484\n","     76     5      0.00693      0.00688     4.56e-05       0.0483       0.0642       0.0381       0.0686       0.0534       0.0494       0.0865       0.0679         0.41      0.00427\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              76  240.787    0.005      0.00723     9.85e-05      0.00733       0.0495       0.0658       0.0392       0.0702       0.0547       0.0501       0.0893       0.0697        0.609      0.00634\n","! Validation         76  240.787    0.005      0.00734     3.89e-05      0.00738       0.0494       0.0663       0.0385       0.0714       0.0549       0.0496       0.0909       0.0703        0.383      0.00399\n","Wall time: 240.78817802899994\n","! Best model       76    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     77     1      0.00665      0.00651     0.000137       0.0471       0.0624       0.0362       0.0688       0.0525       0.0457       0.0867       0.0662        0.767      0.00799\n","     77     2      0.00858      0.00851     6.64e-05       0.0541       0.0714       0.0447       0.0729       0.0588       0.0566       0.0943       0.0754        0.563      0.00587\n","     77     3      0.00694      0.00681     0.000131       0.0485       0.0639       0.0404       0.0647       0.0525       0.0511       0.0837       0.0674        0.776      0.00809\n","     77     4      0.00629      0.00619     9.63e-05       0.0452       0.0609       0.0352        0.065       0.0501       0.0449       0.0841       0.0645        0.652      0.00679\n","     77     5      0.00794      0.00791     2.79e-05       0.0516       0.0688       0.0423       0.0702       0.0563       0.0543       0.0911       0.0727        0.377      0.00393\n","     77     6      0.00832      0.00819      0.00013       0.0533         0.07       0.0415       0.0767       0.0591       0.0526       0.0958       0.0742        0.746      0.00777\n","     77     7      0.00643      0.00635     8.87e-05        0.046       0.0616       0.0355        0.067       0.0512       0.0455       0.0851       0.0653        0.638      0.00665\n","     77     8      0.00752      0.00742     0.000103       0.0505       0.0666       0.0392       0.0729       0.0561       0.0502        0.091       0.0706        0.607      0.00632\n","     77     9      0.00896      0.00874     0.000223       0.0554       0.0723       0.0443       0.0776        0.061       0.0561       0.0969       0.0765          1.1       0.0114\n","     77    10      0.00883      0.00881     1.89e-05       0.0548       0.0726       0.0431       0.0783       0.0607       0.0545       0.0994       0.0769        0.257      0.00268\n","     77    11      0.00749      0.00729     0.000204       0.0496       0.0661       0.0397       0.0695       0.0546       0.0513       0.0884       0.0699            1       0.0104\n","     77    12      0.00674      0.00662     0.000123       0.0476        0.063       0.0371       0.0688       0.0529       0.0468       0.0867       0.0667        0.747      0.00778\n","     77    13      0.00645       0.0064     5.05e-05       0.0466       0.0619        0.036       0.0678       0.0519       0.0466       0.0846       0.0656        0.498      0.00519\n","     77    14      0.00689      0.00652     0.000375       0.0476       0.0625       0.0381       0.0666       0.0524       0.0482        0.084       0.0661         1.41       0.0147\n","     77    15      0.00712       0.0071      1.8e-05       0.0487       0.0652       0.0386       0.0687       0.0537       0.0502       0.0878        0.069        0.274      0.00285\n","     77    16      0.00686      0.00669     0.000174       0.0481       0.0633       0.0379       0.0684       0.0531       0.0477       0.0864        0.067        0.889      0.00926\n","     77    17      0.00662      0.00655     6.93e-05       0.0479       0.0626       0.0378       0.0679       0.0529       0.0479       0.0847       0.0663        0.587      0.00612\n","     77    18      0.00666       0.0066     6.66e-05       0.0484       0.0628       0.0407       0.0637       0.0522       0.0505       0.0821       0.0663        0.465      0.00484\n","     77    19       0.0076      0.00759     1.01e-05       0.0509       0.0674       0.0405       0.0717       0.0561       0.0522       0.0905       0.0713        0.205      0.00213\n","     77    20       0.0076      0.00746     0.000136        0.051       0.0668       0.0403       0.0724       0.0564       0.0508       0.0907       0.0708        0.767      0.00799\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     77     1      0.00761      0.00756     4.38e-05       0.0504       0.0673       0.0393       0.0726        0.056       0.0508       0.0918       0.0713        0.434      0.00452\n","     77     2       0.0076      0.00758     2.44e-05         0.05       0.0673       0.0386       0.0728       0.0557         0.05       0.0927       0.0714          0.3      0.00313\n","     77     3      0.00719      0.00716     2.79e-05       0.0487       0.0655       0.0377       0.0709       0.0543       0.0482       0.0906       0.0694        0.306      0.00319\n","     77     4      0.00743      0.00737     5.35e-05       0.0492       0.0664       0.0381       0.0714       0.0548       0.0487       0.0922       0.0704        0.466      0.00485\n","     77     5      0.00689      0.00684      4.6e-05       0.0482        0.064        0.038       0.0685       0.0532       0.0492       0.0863       0.0677        0.412      0.00429\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              77  243.902    0.005      0.00721     0.000113      0.00733       0.0496       0.0657       0.0395         0.07       0.0547       0.0503       0.0888       0.0696        0.666      0.00694\n","! Validation         77  243.902    0.005       0.0073     3.91e-05      0.00734       0.0493       0.0661       0.0383       0.0712       0.0548       0.0494       0.0907       0.0701        0.384        0.004\n","Wall time: 243.90276226700007\n","! Best model       77    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     78     1      0.00809      0.00803     6.55e-05       0.0531       0.0693       0.0446       0.0701       0.0574       0.0561       0.0902       0.0731        0.587      0.00612\n","     78     2      0.00897      0.00892     5.52e-05       0.0561       0.0731       0.0452        0.078       0.0616       0.0562       0.0984       0.0773        0.476      0.00496\n","     78     3      0.00745      0.00737      7.3e-05         0.05       0.0664       0.0391       0.0718       0.0554         0.05       0.0908       0.0704        0.561      0.00584\n","     78     4      0.00738      0.00734     4.32e-05       0.0493       0.0663       0.0385        0.071       0.0547       0.0494       0.0911       0.0703        0.434      0.00452\n","     78     5      0.00804      0.00791      0.00013       0.0522       0.0688       0.0425       0.0716        0.057       0.0542       0.0912       0.0727        0.803      0.00836\n","     78     6      0.00903      0.00897     6.45e-05        0.057       0.0733         0.05       0.0708       0.0604       0.0624       0.0911       0.0768        0.585      0.00609\n","     78     7      0.00716      0.00708     7.38e-05       0.0486       0.0651       0.0373       0.0713       0.0543       0.0481       0.0899        0.069        0.589      0.00614\n","     78     8      0.00938      0.00933     4.87e-05       0.0584       0.0747       0.0518       0.0716       0.0617       0.0653       0.0907        0.078        0.435      0.00453\n","     78     9      0.00805      0.00801     3.86e-05       0.0537       0.0692       0.0464       0.0682       0.0573       0.0584        0.087       0.0727        0.375      0.00391\n","     78    10      0.00679      0.00664     0.000149       0.0477        0.063       0.0375        0.068       0.0527       0.0477       0.0858       0.0668        0.854       0.0089\n","     78    11      0.00671      0.00663      8.1e-05       0.0476        0.063       0.0384       0.0659       0.0522       0.0481       0.0853       0.0667         0.53      0.00552\n","     78    12      0.00957      0.00923     0.000341       0.0554       0.0743       0.0423       0.0815       0.0619        0.054        0.104       0.0788         1.36       0.0142\n","     78    13      0.00845      0.00842     3.13e-05       0.0537        0.071       0.0439       0.0733       0.0586       0.0566       0.0933        0.075        0.295      0.00308\n","     78    14      0.00787      0.00754     0.000326       0.0502       0.0672       0.0395       0.0716       0.0556       0.0496       0.0929       0.0712         1.24       0.0129\n","     78    15      0.00901      0.00898     3.22e-05       0.0559       0.0733       0.0446       0.0785       0.0615       0.0561       0.0991       0.0776        0.398      0.00415\n","     78    16       0.0109       0.0107     0.000132       0.0621       0.0801       0.0577        0.071       0.0643       0.0729       0.0928       0.0829        0.786      0.00819\n","     78    17      0.00724      0.00708     0.000161       0.0485       0.0651       0.0372       0.0712       0.0542       0.0487       0.0893        0.069        0.847      0.00883\n","     78    18      0.00801      0.00797     3.79e-05       0.0544       0.0691       0.0489       0.0654       0.0571       0.0608       0.0831        0.072        0.353      0.00367\n","     78    19       0.0101      0.00966     0.000433       0.0603        0.076       0.0528       0.0755       0.0641       0.0653       0.0938       0.0796          1.5       0.0156\n","     78    20       0.0102       0.0101     1.59e-05       0.0585       0.0779       0.0455       0.0845        0.065       0.0575        0.108       0.0826        0.262      0.00273\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     78     1      0.00757      0.00753      4.4e-05       0.0503       0.0671       0.0392       0.0725       0.0558       0.0506       0.0916       0.0711        0.437      0.00455\n","     78     2      0.00756      0.00753     2.43e-05       0.0499       0.0671       0.0385       0.0727       0.0556       0.0498       0.0925       0.0712          0.3      0.00312\n","     78     3      0.00715      0.00712     2.77e-05       0.0486       0.0653       0.0375       0.0707       0.0541        0.048       0.0904       0.0692        0.305      0.00317\n","     78     4      0.00739      0.00734     5.34e-05       0.0491       0.0663       0.0379       0.0714       0.0546       0.0485        0.092       0.0703        0.465      0.00484\n","     78     5      0.00685      0.00681     4.58e-05        0.048       0.0638       0.0379       0.0683       0.0531        0.049       0.0861       0.0676        0.411      0.00428\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              78  247.026    0.005       0.0083     0.000117      0.00842       0.0536       0.0705       0.0442       0.0725       0.0584       0.0563       0.0926       0.0744        0.664      0.00691\n","! Validation         78  247.026    0.005      0.00727      3.9e-05       0.0073       0.0492       0.0659       0.0382       0.0711       0.0546       0.0492       0.0906       0.0699        0.383      0.00399\n","Wall time: 247.02675580899995\n","! Best model       78    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     79     1      0.00751       0.0072     0.000306       0.0489       0.0657       0.0387       0.0692        0.054       0.0496       0.0895       0.0696         1.23       0.0128\n","     79     2      0.00937      0.00933     4.17e-05       0.0562       0.0747       0.0446       0.0795        0.062       0.0558        0.103       0.0792        0.368      0.00384\n","     79     3      0.00984      0.00982     2.16e-05       0.0592       0.0767       0.0492       0.0793       0.0642       0.0615          0.1       0.0809        0.236      0.00246\n","     79     4       0.0076      0.00746     0.000135       0.0514       0.0668       0.0425       0.0693       0.0559        0.054       0.0871       0.0705        0.809      0.00843\n","     79     5      0.00662      0.00653     9.52e-05       0.0472       0.0625       0.0377       0.0663        0.052       0.0484       0.0838       0.0661        0.579      0.00603\n","     79     6      0.00879      0.00872     7.58e-05       0.0552       0.0722       0.0481       0.0694       0.0588       0.0618       0.0895       0.0757        0.489      0.00509\n","     79     7      0.00766      0.00747     0.000187       0.0511       0.0669       0.0428       0.0679       0.0553       0.0546       0.0864       0.0705            1       0.0104\n","     79     8      0.00646      0.00643     2.96e-05       0.0464        0.062        0.036       0.0671       0.0515       0.0454       0.0862       0.0658        0.331      0.00345\n","     79     9      0.00756      0.00742     0.000141       0.0498       0.0666       0.0384       0.0726       0.0555       0.0497       0.0916       0.0706        0.779      0.00812\n","     79    10       0.0092      0.00897     0.000221       0.0558       0.0733        0.044       0.0795       0.0618       0.0549          0.1       0.0777        0.953      0.00992\n","     79    11      0.00761      0.00749     0.000115       0.0508        0.067       0.0412         0.07       0.0556       0.0529       0.0886       0.0708        0.643       0.0067\n","     79    12      0.00668      0.00641     0.000269       0.0468       0.0619       0.0365       0.0674       0.0519       0.0469       0.0844       0.0656         1.21       0.0126\n","     79    13      0.00696      0.00694     2.09e-05       0.0497       0.0644       0.0398       0.0695       0.0547         0.05       0.0864       0.0682        0.293      0.00305\n","     79    14      0.00877      0.00869     7.88e-05       0.0554       0.0721       0.0464       0.0733       0.0598       0.0588       0.0931        0.076        0.629      0.00656\n","     79    15      0.00759      0.00752     7.08e-05       0.0503       0.0671       0.0392       0.0727       0.0559       0.0499       0.0923       0.0711        0.506      0.00527\n","     79    16      0.00703        0.007     3.29e-05        0.048       0.0647       0.0375       0.0689       0.0532       0.0471       0.0902       0.0686        0.381      0.00397\n","     79    17       0.0106       0.0102     0.000361       0.0606       0.0782       0.0501       0.0816       0.0658       0.0624        0.103       0.0826         1.38       0.0144\n","     79    18       0.0102       0.0102     1.75e-05       0.0609        0.078       0.0503       0.0821       0.0662       0.0631        0.101       0.0822         0.26       0.0027\n","     79    19      0.00663      0.00637      0.00026       0.0462       0.0618       0.0379        0.063       0.0504        0.048       0.0827       0.0653         1.11       0.0116\n","     79    20      0.00732      0.00721     0.000108       0.0503       0.0657       0.0406       0.0697       0.0552       0.0515       0.0874       0.0695        0.595       0.0062\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     79     1      0.00753      0.00749     4.38e-05       0.0501       0.0669        0.039       0.0723       0.0557       0.0504       0.0915       0.0709        0.434      0.00453\n","     79     2      0.00752       0.0075     2.43e-05       0.0498        0.067       0.0384       0.0725       0.0555       0.0497       0.0924        0.071          0.3      0.00313\n","     79     3      0.00712      0.00709      2.8e-05       0.0485       0.0652       0.0374       0.0707        0.054       0.0478       0.0903       0.0691        0.306      0.00319\n","     79     4      0.00736      0.00731     5.35e-05       0.0489       0.0661       0.0378       0.0713       0.0545       0.0483       0.0919       0.0701        0.465      0.00485\n","     79     5      0.00682      0.00678     4.62e-05       0.0479       0.0637       0.0377       0.0682        0.053       0.0488        0.086       0.0674        0.413       0.0043\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              79  250.120    0.005      0.00787     0.000129        0.008        0.052       0.0686       0.0421       0.0719        0.057       0.0536       0.0916       0.0726        0.689      0.00718\n","! Validation         79  250.120    0.005      0.00723     3.91e-05      0.00727        0.049       0.0658       0.0381        0.071       0.0545        0.049       0.0905       0.0697        0.384        0.004\n","Wall time: 250.12083244899986\n","! Best model       79    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     80     1      0.00965      0.00938     0.000269       0.0587       0.0749       0.0511       0.0738       0.0625       0.0629       0.0945       0.0787          1.2       0.0125\n","     80     2      0.00782      0.00771     0.000109       0.0514       0.0679       0.0404       0.0734       0.0569       0.0513       0.0927        0.072        0.669      0.00696\n","     80     3      0.00736      0.00733     3.12e-05       0.0498       0.0662       0.0395       0.0705        0.055       0.0498       0.0906       0.0702        0.365      0.00381\n","     80     4      0.00703      0.00672     0.000312       0.0494       0.0634       0.0413       0.0655       0.0534       0.0516       0.0821       0.0668         1.18       0.0123\n","     80     5      0.00631      0.00627     4.45e-05       0.0464       0.0613       0.0378       0.0637       0.0507       0.0479       0.0816       0.0648         0.45      0.00469\n","     80     6      0.00647       0.0064     6.73e-05       0.0463       0.0619       0.0363       0.0662       0.0513       0.0468       0.0844       0.0656        0.459      0.00479\n","     80     7      0.00907      0.00902     5.25e-05        0.057       0.0735       0.0484       0.0743       0.0614       0.0609       0.0937       0.0773        0.451       0.0047\n","     80     8      0.00841      0.00839     1.33e-05       0.0538       0.0709       0.0439       0.0736       0.0588       0.0562       0.0936       0.0749        0.239      0.00249\n","     80     9       0.0067      0.00661     9.12e-05       0.0467       0.0629       0.0347       0.0707       0.0527       0.0452       0.0882       0.0667        0.618      0.00644\n","     80    10      0.00819      0.00816     3.36e-05       0.0531       0.0699       0.0424       0.0746       0.0585       0.0535       0.0945        0.074        0.381      0.00397\n","     80    11      0.00858      0.00844     0.000142       0.0545       0.0711       0.0445       0.0746       0.0596       0.0557       0.0946       0.0751        0.823      0.00857\n","     80    12      0.00755      0.00747     8.06e-05         0.05       0.0668         0.04       0.0701        0.055       0.0514       0.0901       0.0708        0.621      0.00646\n","     80    13      0.00704      0.00699      4.5e-05       0.0497       0.0647       0.0412       0.0666       0.0539       0.0517       0.0849       0.0683        0.469      0.00488\n","     80    14      0.00895      0.00893     1.86e-05       0.0544       0.0731       0.0438       0.0756       0.0597       0.0568       0.0979       0.0774        0.256      0.00266\n","     80    15      0.00789      0.00778     0.000111       0.0512       0.0683       0.0396       0.0744        0.057       0.0517       0.0929       0.0723        0.716      0.00746\n","     80    16      0.00716      0.00708     7.26e-05       0.0501       0.0651       0.0398       0.0707       0.0553       0.0495       0.0884        0.069        0.562      0.00585\n","     80    17      0.00795      0.00774     0.000208       0.0534       0.0681       0.0462       0.0676       0.0569       0.0582       0.0845       0.0713        0.979       0.0102\n","     80    18      0.00864      0.00829     0.000354       0.0546       0.0704       0.0473       0.0692       0.0582       0.0601       0.0875       0.0738         1.29       0.0134\n","     80    19      0.00718      0.00717     1.38e-05       0.0479       0.0655        0.035       0.0737       0.0543       0.0447       0.0942       0.0695        0.193      0.00201\n","     80    20      0.00761      0.00714      0.00047       0.0494       0.0654       0.0385        0.071       0.0548        0.049       0.0895       0.0693         1.56       0.0163\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     80     1      0.00749      0.00745     4.34e-05         0.05       0.0668       0.0389       0.0722       0.0555       0.0502       0.0913       0.0707        0.429      0.00447\n","     80     2      0.00749      0.00747     2.43e-05       0.0496       0.0669       0.0382       0.0724       0.0553       0.0495       0.0922       0.0709        0.302      0.00315\n","     80     3      0.00709      0.00706     2.84e-05       0.0484        0.065       0.0373       0.0706       0.0539       0.0477       0.0902       0.0689         0.31      0.00323\n","     80     4      0.00733      0.00727     5.37e-05       0.0488        0.066       0.0376       0.0712       0.0544       0.0481       0.0918         0.07        0.467      0.00486\n","     80     5      0.00679      0.00675     4.68e-05       0.0478       0.0635       0.0376       0.0682       0.0529       0.0486       0.0859       0.0673        0.415      0.00432\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              80  253.224    0.005      0.00765     0.000127      0.00778       0.0514       0.0677       0.0416        0.071       0.0563        0.053       0.0901       0.0716        0.674      0.00702\n","! Validation         80  253.224    0.005       0.0072     3.93e-05      0.00724       0.0489       0.0656       0.0379       0.0709       0.0544       0.0488       0.0903       0.0696        0.384        0.004\n","Wall time: 253.22517067599983\n","! Best model       80    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     81     1      0.00647      0.00617     0.000303       0.0457       0.0608       0.0349       0.0673       0.0511       0.0444       0.0844       0.0644         1.23       0.0128\n","     81     2      0.00685      0.00658     0.000264       0.0474       0.0628       0.0364       0.0693       0.0529       0.0463       0.0868       0.0665         1.15        0.012\n","     81     3      0.00684      0.00618     0.000661        0.046       0.0608        0.037       0.0639       0.0505       0.0469       0.0818       0.0643         1.89       0.0197\n","     81     4      0.00638       0.0063     8.26e-05       0.0469       0.0614       0.0371       0.0664       0.0517       0.0465       0.0836        0.065        0.542      0.00564\n","     81     5      0.00821      0.00782     0.000388       0.0522       0.0684       0.0408       0.0748       0.0578       0.0512       0.0939       0.0725         1.42       0.0148\n","     81     6       0.0072      0.00691     0.000283       0.0492       0.0643       0.0395       0.0687       0.0541       0.0491       0.0872       0.0681         1.17       0.0122\n","     81     7      0.00713      0.00678     0.000344       0.0474       0.0637       0.0371        0.068       0.0525       0.0484       0.0866       0.0675         1.36       0.0142\n","     81     8      0.00778      0.00744     0.000334        0.052       0.0667       0.0425       0.0709       0.0567       0.0533       0.0876       0.0705         1.32       0.0138\n","     81     9      0.00708      0.00704     3.82e-05       0.0494       0.0649       0.0403       0.0675       0.0539       0.0506       0.0867       0.0687        0.309      0.00322\n","     81    10      0.00728      0.00719     8.51e-05       0.0482       0.0656       0.0369       0.0708       0.0538        0.048       0.0912       0.0696        0.642      0.00668\n","     81    11       0.0081      0.00791     0.000185       0.0505       0.0688       0.0384       0.0746       0.0565       0.0502       0.0957        0.073        0.892       0.0093\n","     81    12      0.00758      0.00752     6.26e-05       0.0506       0.0671       0.0419        0.068        0.055       0.0535       0.0881       0.0708        0.389      0.00405\n","     81    13      0.00724      0.00701     0.000231       0.0498       0.0648       0.0424       0.0646       0.0535        0.053       0.0834       0.0682         1.11       0.0116\n","     81    14      0.00627      0.00624     3.82e-05       0.0456       0.0611       0.0341       0.0686       0.0514       0.0435       0.0861       0.0648        0.323      0.00337\n","     81    15      0.00721      0.00719     2.04e-05       0.0508       0.0656       0.0405       0.0712       0.0559        0.051       0.0878       0.0694        0.328      0.00341\n","     81    16      0.00718      0.00695     0.000227       0.0481       0.0645       0.0373       0.0697       0.0535       0.0477        0.089       0.0684         1.07       0.0112\n","     81    17       0.0075      0.00749     1.01e-05       0.0509        0.067       0.0405       0.0715        0.056       0.0516       0.0901       0.0709        0.194      0.00202\n","     81    18      0.00828        0.008     0.000279       0.0524       0.0692       0.0427       0.0716       0.0572       0.0541       0.0922       0.0732          1.2       0.0125\n","     81    19      0.00827      0.00805     0.000227       0.0517       0.0694       0.0396       0.0759       0.0577       0.0515       0.0957       0.0736          1.1       0.0114\n","     81    20      0.00766      0.00741     0.000245         0.05       0.0666       0.0382       0.0737        0.056       0.0489       0.0924       0.0706         1.12       0.0116\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     81     1      0.00747      0.00742     4.35e-05       0.0499       0.0666       0.0388        0.072       0.0554       0.0501       0.0912       0.0706        0.429      0.00447\n","     81     2      0.00746      0.00743     2.44e-05       0.0495       0.0667       0.0381       0.0723       0.0552       0.0493       0.0921       0.0707        0.303      0.00315\n","     81     3      0.00706      0.00703     2.86e-05       0.0482       0.0649       0.0371       0.0705       0.0538       0.0475       0.0901       0.0688        0.311      0.00324\n","     81     4       0.0073      0.00724     5.38e-05       0.0487       0.0658       0.0375       0.0711       0.0543        0.048       0.0917       0.0698        0.467      0.00487\n","     81     5      0.00676      0.00672      4.7e-05       0.0477       0.0634       0.0375        0.068       0.0528       0.0485       0.0858       0.0671        0.416      0.00433\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              81  256.338    0.005      0.00711     0.000215      0.00733       0.0492       0.0652       0.0389       0.0699       0.0544       0.0496       0.0886       0.0691        0.938      0.00977\n","! Validation         81  256.338    0.005      0.00717     3.95e-05      0.00721       0.0488       0.0655       0.0378       0.0708       0.0543       0.0487       0.0902       0.0694        0.385      0.00401\n","Wall time: 256.33848957200007\n","! Best model       81    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     82     1      0.00908      0.00866     0.000425       0.0553        0.072       0.0455       0.0749       0.0602       0.0572       0.0948        0.076          1.5       0.0156\n","     82     2      0.00866      0.00864     2.47e-05       0.0529       0.0719       0.0419        0.075       0.0585       0.0543        0.098       0.0762        0.347      0.00361\n","     82     3      0.00628      0.00612     0.000159       0.0455       0.0605       0.0347       0.0672       0.0509       0.0442       0.0842       0.0642        0.785      0.00817\n","     82     4      0.00737      0.00726     0.000107       0.0497       0.0659        0.039        0.071        0.055       0.0498       0.0899       0.0698        0.704      0.00733\n","     82     5      0.00746      0.00743     3.01e-05       0.0507       0.0667       0.0427       0.0668       0.0547       0.0549       0.0854       0.0702        0.385      0.00401\n","     82     6      0.00634      0.00624     0.000101       0.0455       0.0611        0.034       0.0685       0.0512       0.0431       0.0865       0.0648        0.658      0.00686\n","     82     7      0.00695      0.00678     0.000164       0.0476       0.0637       0.0383       0.0663       0.0523       0.0498        0.085       0.0674        0.841      0.00876\n","     82     8      0.00792      0.00789     3.57e-05       0.0517       0.0687        0.042       0.0711       0.0566        0.054       0.0913       0.0726        0.435      0.00453\n","     82     9      0.00821      0.00805     0.000155       0.0511       0.0694         0.04       0.0733       0.0566        0.051       0.0962       0.0736        0.832      0.00867\n","     82    10      0.00605      0.00604     7.35e-06       0.0461       0.0601       0.0362       0.0657        0.051       0.0456       0.0818       0.0637        0.154       0.0016\n","     82    11      0.00785      0.00782     3.59e-05       0.0514       0.0684        0.039       0.0762       0.0576       0.0492       0.0959       0.0726        0.387      0.00403\n","     82    12      0.00852      0.00849     3.48e-05       0.0537       0.0713       0.0425       0.0761       0.0593       0.0542       0.0968       0.0755        0.383      0.00399\n","     82    13      0.00658      0.00652     5.33e-05       0.0485       0.0625       0.0405       0.0647       0.0526       0.0508        0.081       0.0659        0.431      0.00449\n","     82    14      0.00715      0.00712      2.9e-05        0.049       0.0653       0.0374       0.0721       0.0547       0.0475       0.0909       0.0692        0.259       0.0027\n","     82    15      0.00759      0.00751     8.39e-05       0.0522        0.067       0.0446       0.0674        0.056       0.0555       0.0856       0.0705        0.593      0.00618\n","     82    16      0.00667      0.00665     2.59e-05       0.0477       0.0631       0.0374       0.0684       0.0529        0.048       0.0856       0.0668        0.341      0.00355\n","     82    17      0.00684      0.00667      0.00017        0.048       0.0632       0.0391       0.0657       0.0524       0.0506       0.0828       0.0667        0.788       0.0082\n","     82    18       0.0087       0.0086     0.000108       0.0563       0.0717       0.0498       0.0693       0.0595       0.0616       0.0886       0.0751        0.598      0.00623\n","     82    19      0.00993      0.00965     0.000273       0.0581        0.076       0.0468       0.0805       0.0637       0.0591        0.102       0.0804         1.19       0.0124\n","     82    20      0.00746      0.00744     1.93e-05         0.05       0.0667       0.0381       0.0738        0.056       0.0484       0.0931       0.0708        0.237      0.00247\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     82     1      0.00743      0.00739     4.41e-05       0.0498       0.0665       0.0387       0.0719       0.0553       0.0499        0.091       0.0705        0.437      0.00455\n","     82     2      0.00743       0.0074     2.42e-05       0.0494       0.0666        0.038       0.0723       0.0551       0.0492        0.092       0.0706          0.3      0.00313\n","     82     3      0.00703        0.007     2.78e-05       0.0481       0.0647        0.037       0.0704       0.0537       0.0474       0.0899       0.0686        0.305      0.00318\n","     82     4      0.00726      0.00721     5.34e-05       0.0486       0.0657       0.0374        0.071       0.0542       0.0478       0.0915       0.0697        0.464      0.00483\n","     82     5      0.00673      0.00669     4.61e-05       0.0475       0.0633       0.0373       0.0679       0.0526       0.0483       0.0857        0.067        0.413       0.0043\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              82  259.440    0.005      0.00748     0.000102      0.00758       0.0505       0.0669       0.0405       0.0707       0.0556       0.0517         0.09       0.0708        0.593      0.00617\n","! Validation         82  259.440    0.005      0.00714     3.91e-05      0.00718       0.0487       0.0654       0.0377       0.0707       0.0542       0.0485       0.0901       0.0693        0.384        0.004\n","Wall time: 259.4408194490006\n","! Best model       82    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     83     1      0.00771      0.00771     7.49e-06       0.0501       0.0679       0.0379       0.0747       0.0563       0.0477       0.0964        0.072        0.195      0.00204\n","     83     2      0.00911        0.009     0.000113       0.0553       0.0734       0.0422       0.0816       0.0619       0.0527        0.103       0.0778        0.777      0.00809\n","     83     3      0.00838       0.0083      7.5e-05       0.0553       0.0705       0.0482       0.0696       0.0589       0.0605       0.0871       0.0738        0.495      0.00515\n","     83     4      0.00721      0.00716     4.07e-05       0.0501       0.0655       0.0401       0.0701       0.0551       0.0506        0.088       0.0693        0.407      0.00424\n","     83     5      0.00711      0.00687     0.000233       0.0485       0.0641       0.0398       0.0658       0.0528       0.0509       0.0846       0.0678         1.09       0.0113\n","     83     6      0.00833      0.00827      5.9e-05       0.0541       0.0704       0.0454       0.0715       0.0584       0.0581         0.09       0.0741         0.47       0.0049\n","     83     7      0.00738      0.00723     0.000148       0.0494       0.0658       0.0374       0.0732       0.0553       0.0482       0.0913       0.0698        0.739       0.0077\n","     83     8      0.00663       0.0066     2.57e-05       0.0483       0.0629       0.0392       0.0665       0.0529       0.0495       0.0834       0.0665        0.281      0.00292\n","     83     9      0.00718      0.00703     0.000153       0.0484       0.0649       0.0379       0.0692       0.0536       0.0483       0.0892       0.0688        0.815      0.00849\n","     83    10      0.00776      0.00764     0.000119       0.0502       0.0676       0.0382       0.0742       0.0562       0.0488       0.0946       0.0717        0.784      0.00816\n","     83    11       0.0065      0.00635     0.000154       0.0468       0.0616        0.037       0.0663       0.0517       0.0462       0.0844       0.0653        0.846      0.00881\n","     83    12       0.0069      0.00676     0.000145       0.0463       0.0636       0.0345       0.0699       0.0522       0.0449         0.09       0.0675        0.858      0.00894\n","     83    13      0.00781      0.00777     3.91e-05        0.051       0.0682       0.0391       0.0747       0.0569        0.051       0.0936       0.0723         0.37      0.00386\n","     83    14      0.00789      0.00773     0.000159       0.0512        0.068       0.0406       0.0724       0.0565       0.0525       0.0915        0.072        0.852      0.00888\n","     83    15       0.0071      0.00688     0.000214       0.0478       0.0642       0.0375       0.0685        0.053       0.0473       0.0888       0.0681         1.07       0.0112\n","     83    16      0.00583      0.00569     0.000134       0.0438       0.0584       0.0346       0.0623       0.0484       0.0445       0.0791       0.0618        0.723      0.00753\n","     83    17      0.00636      0.00632     4.34e-05       0.0465       0.0615       0.0368       0.0659       0.0514       0.0474       0.0828       0.0651        0.365      0.00381\n","     83    18      0.00636      0.00628     7.76e-05       0.0471       0.0613       0.0385       0.0644       0.0515        0.048       0.0816       0.0648        0.582      0.00606\n","     83    19      0.00646       0.0064      5.8e-05       0.0463       0.0619       0.0356       0.0678       0.0517       0.0456       0.0856       0.0656        0.434      0.00452\n","     83    20      0.00735      0.00731     4.39e-05       0.0497       0.0661       0.0374       0.0744       0.0559        0.048       0.0923       0.0701        0.388      0.00404\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     83     1      0.00741      0.00736     4.42e-05       0.0497       0.0664       0.0386       0.0718       0.0552       0.0498       0.0909       0.0703        0.438      0.00456\n","     83     2       0.0074      0.00737     2.42e-05       0.0493       0.0664       0.0379       0.0722        0.055        0.049       0.0918       0.0704          0.3      0.00313\n","     83     3        0.007      0.00697     2.77e-05        0.048       0.0646       0.0369       0.0703       0.0536       0.0472       0.0898       0.0685        0.304      0.00317\n","     83     4      0.00724      0.00718     5.33e-05       0.0485       0.0656       0.0373       0.0709       0.0541       0.0477       0.0914       0.0695        0.464      0.00483\n","     83     5       0.0067      0.00666     4.59e-05       0.0474       0.0631       0.0372       0.0678       0.0525       0.0481       0.0856       0.0668        0.413       0.0043\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              83  262.551    0.005      0.00717     0.000102      0.00727       0.0493       0.0655       0.0389       0.0702       0.0545       0.0497        0.089       0.0694        0.627      0.00653\n","! Validation         83  262.551    0.005      0.00711     3.91e-05      0.00715       0.0486       0.0652       0.0376       0.0706       0.0541       0.0484       0.0899       0.0691        0.384        0.004\n","Wall time: 262.5516927810004\n","! Best model       83    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     84     1       0.0072      0.00716     4.28e-05       0.0485       0.0655       0.0375       0.0704       0.0539        0.048       0.0908       0.0694        0.339      0.00353\n","     84     2      0.00715      0.00712     2.65e-05       0.0491       0.0653       0.0393       0.0688        0.054       0.0501       0.0881       0.0691         0.36      0.00375\n","     84     3      0.00624      0.00621     2.21e-05       0.0456        0.061       0.0354        0.066       0.0507        0.045       0.0843       0.0647        0.213      0.00222\n","     84     4      0.00641      0.00625     0.000155       0.0461       0.0612       0.0359       0.0665       0.0512       0.0461       0.0835       0.0648        0.816      0.00849\n","     84     5      0.00719      0.00716        3e-05       0.0479       0.0655       0.0353        0.073       0.0542       0.0467       0.0922       0.0694        0.356      0.00371\n","     84     6      0.00706        0.007     5.45e-05       0.0497       0.0647       0.0406        0.068       0.0543       0.0514       0.0854       0.0684        0.522      0.00543\n","     84     7      0.00697      0.00696     8.95e-06       0.0482       0.0645       0.0372       0.0702       0.0537       0.0475       0.0893       0.0684         0.22      0.00229\n","     84     8      0.00617      0.00616     1.16e-05        0.045       0.0607       0.0346       0.0657       0.0502       0.0443       0.0845       0.0644        0.197      0.00205\n","     84     9      0.00619      0.00615      3.9e-05       0.0457       0.0607       0.0363       0.0646       0.0504       0.0456        0.083       0.0643        0.405      0.00422\n","     84    10      0.00704      0.00703     1.38e-05        0.049       0.0649       0.0377       0.0715       0.0546       0.0479       0.0897       0.0688        0.208      0.00216\n","     84    11      0.00716       0.0071     6.04e-05       0.0495       0.0652        0.039       0.0703       0.0547       0.0494       0.0887       0.0691         0.49      0.00511\n","     84    12      0.00578      0.00565     0.000126       0.0444       0.0582       0.0354       0.0624       0.0489       0.0446       0.0786       0.0616        0.692      0.00721\n","     84    13      0.00783      0.00769     0.000134       0.0515       0.0679       0.0409       0.0727       0.0568       0.0516       0.0921       0.0719        0.739       0.0077\n","     84    14      0.00783       0.0078     3.57e-05       0.0532       0.0683       0.0434       0.0727        0.058       0.0541       0.0902       0.0722        0.389      0.00406\n","     84    15      0.00669      0.00666     2.49e-05       0.0484       0.0631       0.0383       0.0685       0.0534       0.0486       0.0851       0.0668        0.318      0.00331\n","     84    16      0.00658      0.00655      2.2e-05       0.0473       0.0626       0.0366       0.0686       0.0526       0.0469       0.0858       0.0664        0.261      0.00272\n","     84    17      0.00611      0.00609     2.29e-05       0.0455       0.0604       0.0349       0.0666       0.0507       0.0438       0.0842        0.064          0.3      0.00312\n","     84    18      0.00722       0.0072     1.85e-05       0.0493       0.0657       0.0385       0.0708       0.0546       0.0493       0.0898       0.0696        0.285      0.00297\n","     84    19      0.00678       0.0067     7.21e-05       0.0468       0.0633       0.0374       0.0656       0.0515       0.0481       0.0861       0.0671        0.561      0.00584\n","     84    20      0.00698      0.00693     5.25e-05       0.0482       0.0644        0.037       0.0705       0.0538       0.0475       0.0891       0.0683        0.491      0.00511\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     84     1      0.00737      0.00733     4.43e-05       0.0496       0.0662       0.0385       0.0717       0.0551       0.0496       0.0907       0.0702        0.439      0.00457\n","     84     2      0.00736      0.00733     2.42e-05       0.0492       0.0662       0.0377        0.072       0.0549       0.0488       0.0917       0.0702        0.301      0.00313\n","     84     3      0.00698      0.00695     2.78e-05       0.0479       0.0645       0.0368       0.0702       0.0535        0.047       0.0897       0.0684        0.304      0.00317\n","     84     4       0.0072      0.00715     5.34e-05       0.0484       0.0654       0.0372       0.0707        0.054       0.0475       0.0912       0.0694        0.464      0.00483\n","     84     5      0.00667      0.00662      4.6e-05       0.0473        0.063       0.0371       0.0677       0.0524       0.0479       0.0854       0.0667        0.413       0.0043\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              84  265.657    0.005      0.00678     4.87e-05      0.00683       0.0479       0.0637       0.0376       0.0687       0.0531       0.0479       0.0871       0.0675        0.408      0.00425\n","! Validation         84  265.657    0.005      0.00708     3.91e-05      0.00712       0.0485       0.0651       0.0375       0.0705        0.054       0.0482       0.0898        0.069        0.384        0.004\n","Wall time: 265.65813654500016\n","! Best model       84    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     85     1      0.00667      0.00661     6.01e-05       0.0473       0.0629        0.037       0.0678       0.0524        0.048       0.0852       0.0666        0.563      0.00586\n","     85     2      0.00696      0.00685     0.000102       0.0481        0.064       0.0377       0.0688       0.0532       0.0482       0.0875       0.0679        0.603      0.00628\n","     85     3      0.00794      0.00781     0.000129       0.0508       0.0684       0.0389       0.0745       0.0567       0.0507       0.0943       0.0725        0.806       0.0084\n","     85     4      0.00613      0.00601     0.000116       0.0454         0.06       0.0355       0.0652       0.0503        0.045       0.0821       0.0636        0.667      0.00695\n","     85     5       0.0057      0.00563     6.19e-05       0.0433       0.0581       0.0332       0.0634       0.0483       0.0418       0.0814       0.0616        0.495      0.00515\n","     85     6      0.00665       0.0066     5.03e-05       0.0467       0.0629       0.0359       0.0682        0.052       0.0452       0.0882       0.0667        0.377      0.00393\n","     85     7       0.0067      0.00668     1.75e-05       0.0473       0.0632       0.0359       0.0702        0.053       0.0451        0.089       0.0671        0.249      0.00259\n","     85     8      0.00617      0.00611     6.46e-05       0.0449       0.0605       0.0337       0.0675       0.0506       0.0428       0.0855       0.0641        0.582      0.00606\n","     85     9      0.00604      0.00594     9.85e-05       0.0447       0.0596        0.035       0.0639       0.0495       0.0449       0.0814       0.0632        0.655      0.00682\n","     85    10      0.00646      0.00641     4.99e-05       0.0473       0.0619       0.0376       0.0666       0.0521       0.0478       0.0833       0.0656        0.475      0.00495\n","     85    11      0.00694      0.00677     0.000173       0.0473       0.0636       0.0364       0.0692       0.0528       0.0464       0.0886       0.0675        0.919      0.00957\n","     85    12      0.00556      0.00552     3.24e-05       0.0433       0.0575       0.0333       0.0634       0.0484       0.0416       0.0804        0.061        0.394       0.0041\n","     85    13       0.0068      0.00679     1.11e-05       0.0472       0.0638       0.0368       0.0679       0.0524       0.0476       0.0876       0.0676        0.238      0.00248\n","     85    14      0.00685      0.00672     0.000134       0.0472       0.0634       0.0365       0.0686       0.0526       0.0477       0.0866       0.0672        0.773      0.00805\n","     85    15      0.00648      0.00647     1.06e-05       0.0471       0.0622       0.0369       0.0674       0.0522       0.0466       0.0853       0.0659        0.225      0.00234\n","     85    16      0.00643      0.00636     6.13e-05       0.0463       0.0617       0.0356       0.0676       0.0516       0.0448       0.0861       0.0655         0.52      0.00542\n","     85    17      0.00713      0.00705     7.56e-05       0.0494        0.065       0.0392       0.0697       0.0544       0.0494       0.0882       0.0688         0.55      0.00572\n","     85    18      0.00724      0.00711     0.000132       0.0492       0.0652       0.0381       0.0714       0.0547       0.0485       0.0898       0.0692        0.751      0.00783\n","     85    19      0.00641      0.00638     3.06e-05       0.0466       0.0618       0.0359       0.0678       0.0519       0.0463       0.0847       0.0655        0.323      0.00336\n","     85    20      0.00683      0.00681     1.86e-05       0.0478       0.0638       0.0361       0.0713       0.0537       0.0466       0.0888       0.0677        0.255      0.00265\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     85     1      0.00733      0.00729     4.44e-05       0.0494        0.066       0.0384       0.0715        0.055       0.0494       0.0905         0.07        0.439      0.00457\n","     85     2      0.00732      0.00729     2.43e-05        0.049       0.0661       0.0376       0.0719       0.0548       0.0486       0.0915         0.07        0.301      0.00314\n","     85     3      0.00694      0.00692     2.79e-05       0.0478       0.0643       0.0366       0.0701       0.0534       0.0469       0.0896       0.0682        0.305      0.00318\n","     85     4      0.00717      0.00712     5.35e-05       0.0483       0.0653       0.0371       0.0706       0.0538       0.0473       0.0911       0.0692        0.464      0.00483\n","     85     5      0.00664       0.0066     4.62e-05       0.0472       0.0628        0.037       0.0676       0.0523       0.0478       0.0853       0.0665        0.414      0.00431\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              85  268.790    0.005      0.00653     7.15e-05       0.0066       0.0468       0.0625       0.0363        0.068       0.0521       0.0463       0.0863       0.0663        0.521      0.00543\n","! Validation         85  268.790    0.005      0.00704     3.93e-05      0.00708       0.0483       0.0649       0.0373       0.0704       0.0538        0.048       0.0896       0.0688        0.385      0.00401\n","Wall time: 268.7906311080005\n","! Best model       85    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     86     1      0.00626       0.0062     5.98e-05       0.0459       0.0609       0.0351       0.0677       0.0514       0.0439       0.0854       0.0646        0.538       0.0056\n","     86     2      0.00672      0.00669     3.79e-05       0.0469       0.0633       0.0352       0.0704       0.0528       0.0445       0.0897       0.0671        0.385      0.00401\n","     86     3       0.0073       0.0073     7.81e-06       0.0495       0.0661       0.0393         0.07       0.0546       0.0506       0.0893         0.07        0.175      0.00182\n","     86     4      0.00657      0.00649     8.83e-05       0.0467       0.0623       0.0362       0.0676       0.0519       0.0459       0.0862       0.0661        0.624       0.0065\n","     86     5      0.00672      0.00671     1.68e-05       0.0473       0.0633       0.0359       0.0702        0.053       0.0461       0.0883       0.0672        0.235      0.00244\n","     86     6      0.00736      0.00728      7.7e-05       0.0488        0.066        0.038       0.0705       0.0542       0.0488       0.0911         0.07        0.567      0.00591\n","     86     7      0.00683      0.00677        6e-05       0.0477       0.0637       0.0374       0.0682       0.0528       0.0484       0.0865       0.0674        0.438      0.00456\n","     86     8      0.00568      0.00553     0.000147       0.0437       0.0575       0.0335       0.0641       0.0488       0.0419       0.0801        0.061        0.752      0.00783\n","     86     9      0.00667      0.00665     1.83e-05       0.0478       0.0631       0.0376       0.0681       0.0528       0.0478       0.0859       0.0668        0.266      0.00278\n","     86    10      0.00725      0.00675     0.000508       0.0481       0.0635       0.0373       0.0697       0.0535       0.0474       0.0873       0.0673         1.57       0.0164\n","     86    11      0.00623      0.00619     4.34e-05       0.0467       0.0609       0.0371       0.0661       0.0516       0.0466       0.0822       0.0644        0.388      0.00404\n","     86    12      0.00667      0.00652     0.000151       0.0473       0.0625       0.0375       0.0668       0.0522       0.0477       0.0846       0.0661        0.902       0.0094\n","     86    13      0.00671      0.00646     0.000249       0.0465       0.0622        0.036       0.0675       0.0518       0.0459        0.086       0.0659         1.08       0.0112\n","     86    14      0.00709      0.00705     4.04e-05         0.05       0.0649       0.0425       0.0652       0.0538       0.0529        0.084       0.0684        0.401      0.00418\n","     86    15      0.00717      0.00704     0.000131       0.0485       0.0649        0.037       0.0715       0.0543       0.0476         0.09       0.0688        0.773      0.00806\n","     86    16      0.00758      0.00756     2.01e-05       0.0509       0.0673       0.0398        0.073       0.0564       0.0509       0.0916       0.0712        0.253      0.00264\n","     86    17      0.00735      0.00731     4.31e-05       0.0498       0.0661       0.0385       0.0722       0.0554       0.0497       0.0904       0.0701        0.361      0.00376\n","     86    18      0.00771      0.00764     6.47e-05        0.051       0.0676       0.0423       0.0683       0.0553        0.054       0.0888       0.0714        0.554      0.00577\n","     86    19      0.00697      0.00695     2.14e-05       0.0476       0.0645       0.0367       0.0694        0.053       0.0487       0.0879       0.0683        0.297      0.00309\n","     86    20      0.00771      0.00768     3.12e-05       0.0515       0.0678       0.0414       0.0716       0.0565       0.0515       0.0922       0.0718        0.379      0.00395\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     86     1       0.0073      0.00725     4.45e-05       0.0493       0.0659       0.0382       0.0714       0.0548       0.0493       0.0904       0.0698         0.44      0.00458\n","     86     2      0.00728      0.00725     2.43e-05       0.0489       0.0659       0.0375       0.0718       0.0546       0.0484       0.0913       0.0699        0.302      0.00315\n","     86     3      0.00692      0.00689      2.8e-05       0.0477       0.0642       0.0365         0.07       0.0533       0.0467       0.0895       0.0681        0.305      0.00318\n","     86     4      0.00714      0.00708     5.36e-05       0.0481       0.0651       0.0369       0.0705       0.0537       0.0471        0.091        0.069        0.464      0.00484\n","     86     5      0.00661      0.00656     4.62e-05       0.0471       0.0627       0.0368       0.0675       0.0522       0.0476       0.0852       0.0664        0.414      0.00432\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              86  271.905    0.005      0.00684     9.08e-05      0.00693       0.0481        0.064       0.0377       0.0689       0.0533       0.0481       0.0874       0.0678        0.547       0.0057\n","! Validation         86  271.905    0.005      0.00701     3.93e-05      0.00705       0.0482       0.0648       0.0372       0.0702       0.0537       0.0478       0.0895       0.0687        0.385      0.00401\n","Wall time: 271.90556707500036\n","! Best model       86    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     87     1      0.00609      0.00604     5.25e-05       0.0454       0.0601       0.0363       0.0636         0.05       0.0467       0.0805       0.0636        0.468      0.00488\n","     87     2      0.00745      0.00742     3.08e-05       0.0493       0.0666        0.038       0.0719        0.055       0.0481       0.0933       0.0707        0.338      0.00352\n","     87     3      0.00661      0.00652     9.74e-05       0.0466       0.0624       0.0366       0.0667       0.0516       0.0472       0.0851       0.0661        0.693      0.00722\n","     87     4      0.00862      0.00857     4.69e-05       0.0551       0.0716       0.0481       0.0691       0.0586       0.0615       0.0885        0.075        0.465      0.00484\n","     87     5      0.00705      0.00693     0.000122       0.0492       0.0644       0.0395       0.0686        0.054       0.0495       0.0868       0.0681         0.69      0.00719\n","     87     6        0.007      0.00696     4.29e-05       0.0491       0.0645       0.0383       0.0706       0.0545       0.0477       0.0891       0.0684        0.425      0.00442\n","     87     7      0.00678      0.00675     3.49e-05       0.0486       0.0635       0.0373       0.0711       0.0542       0.0464       0.0884       0.0674        0.333      0.00347\n","     87     8      0.00777      0.00772     4.66e-05       0.0526        0.068       0.0421       0.0735       0.0578       0.0538       0.0899       0.0718        0.468      0.00488\n","     87     9      0.00747      0.00742     5.07e-05       0.0501       0.0667       0.0386        0.073       0.0558        0.049       0.0923       0.0707        0.447      0.00466\n","     87    10      0.00735       0.0073     4.48e-05       0.0502       0.0661       0.0402       0.0704       0.0553        0.051       0.0889         0.07        0.424      0.00442\n","     87    11       0.0079      0.00782     7.99e-05       0.0521       0.0684       0.0438       0.0688       0.0563       0.0556       0.0887       0.0721        0.651      0.00678\n","     87    12      0.00765      0.00763     2.07e-05       0.0509       0.0676       0.0388       0.0752        0.057       0.0492       0.0942       0.0717        0.308      0.00321\n","     87    13      0.00846      0.00844     2.32e-05       0.0532       0.0711       0.0395       0.0806         0.06       0.0501        0.101       0.0754        0.279       0.0029\n","     87    14      0.00671      0.00669     1.34e-05        0.047       0.0633       0.0373       0.0663       0.0518        0.048       0.0861        0.067        0.244      0.00254\n","     87    15      0.00732      0.00721     0.000113       0.0498       0.0657       0.0386       0.0722       0.0554       0.0483        0.091       0.0696        0.751      0.00783\n","     87    16      0.00623      0.00621     1.53e-05       0.0456        0.061       0.0351       0.0667       0.0509       0.0445       0.0848       0.0646        0.276      0.00288\n","     87    17      0.00683      0.00675     7.58e-05       0.0482       0.0636       0.0395       0.0658       0.0526       0.0511       0.0832       0.0671        0.523      0.00544\n","     87    18      0.00729      0.00725     4.73e-05       0.0491       0.0659       0.0382       0.0708       0.0545         0.05       0.0895       0.0698         0.47      0.00489\n","     87    19      0.00656      0.00647     8.44e-05        0.046       0.0622       0.0359       0.0662       0.0511        0.047       0.0849       0.0659        0.544      0.00567\n","     87    20      0.00669      0.00662     7.35e-05       0.0475       0.0629       0.0374       0.0677       0.0525       0.0478       0.0855       0.0667        0.544      0.00567\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     87     1      0.00726      0.00721     4.44e-05       0.0492       0.0657       0.0381       0.0713       0.0547        0.049       0.0902       0.0696        0.438      0.00457\n","     87     2      0.00724      0.00722     2.43e-05       0.0488       0.0657       0.0373       0.0717       0.0545       0.0482       0.0912       0.0697        0.302      0.00315\n","     87     3      0.00689      0.00686      2.8e-05       0.0475       0.0641       0.0364       0.0699       0.0531       0.0465       0.0894       0.0679        0.306      0.00318\n","     87     4       0.0071      0.00704     5.36e-05        0.048       0.0649       0.0368       0.0704       0.0536       0.0469       0.0908       0.0689        0.464      0.00484\n","     87     5      0.00657      0.00652     4.63e-05       0.0469       0.0625       0.0367       0.0674        0.052       0.0473        0.085       0.0662        0.415      0.00432\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              87  275.019    0.005      0.00714     5.58e-05      0.00719       0.0493       0.0654        0.039       0.0699       0.0544       0.0498       0.0887       0.0692        0.467      0.00486\n","! Validation         87  275.019    0.005      0.00697     3.93e-05      0.00701       0.0481       0.0646       0.0371       0.0701       0.0536       0.0476       0.0893       0.0685        0.385      0.00401\n","Wall time: 275.0193444690003\n","! Best model       87    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     88     1      0.00766      0.00756     9.68e-05       0.0511       0.0673       0.0406       0.0721       0.0563       0.0516       0.0908       0.0712        0.657      0.00685\n","     88     2      0.00757      0.00751     5.35e-05       0.0507       0.0671       0.0405       0.0711       0.0558       0.0508       0.0912        0.071        0.421      0.00439\n","     88     3      0.00626      0.00621     5.07e-05       0.0464       0.0609       0.0366       0.0662       0.0514       0.0465       0.0825       0.0645        0.488      0.00508\n","     88     4       0.0062      0.00616     4.12e-05       0.0459       0.0607        0.037       0.0635       0.0503       0.0468       0.0818       0.0643        0.322      0.00335\n","     88     5      0.00856       0.0085     5.44e-05       0.0553       0.0713       0.0473       0.0712       0.0593         0.06       0.0898       0.0749        0.515      0.00536\n","     88     6      0.00774      0.00772     2.77e-05       0.0515        0.068       0.0417       0.0711       0.0564       0.0531       0.0906       0.0719        0.388      0.00405\n","     88     7      0.00653      0.00648     4.58e-05       0.0464       0.0623       0.0345       0.0702       0.0524       0.0437       0.0884       0.0661        0.433      0.00451\n","     88     8      0.00685      0.00679     5.85e-05       0.0487       0.0637       0.0404       0.0652       0.0528       0.0509       0.0837       0.0673        0.509       0.0053\n","     88     9      0.00888      0.00881     7.19e-05       0.0552       0.0726       0.0433       0.0791       0.0612       0.0546       0.0993       0.0769        0.549      0.00572\n","     88    10      0.00823      0.00818     4.64e-05        0.054         0.07       0.0425       0.0769       0.0597       0.0522       0.0961       0.0742         0.46      0.00479\n","     88    11      0.00752      0.00749     2.88e-05       0.0517        0.067       0.0428       0.0694       0.0561       0.0541       0.0872       0.0706        0.337      0.00351\n","     88    12      0.00602      0.00598     3.91e-05       0.0446       0.0598        0.035       0.0636       0.0493        0.045       0.0818       0.0634        0.316      0.00329\n","     88    13      0.00704      0.00703     1.71e-05       0.0485       0.0649       0.0368       0.0719       0.0543       0.0471       0.0904       0.0688        0.276      0.00287\n","     88    14      0.00695      0.00693      2.1e-05       0.0488       0.0644       0.0377       0.0711       0.0544       0.0476       0.0889       0.0683        0.316      0.00329\n","     88    15      0.00827      0.00818     8.94e-05       0.0526         0.07       0.0415       0.0749       0.0582       0.0525       0.0958       0.0742         0.61      0.00635\n","     88    16      0.00844      0.00819     0.000251       0.0514         0.07       0.0396       0.0748       0.0572       0.0524        0.096       0.0742         1.16       0.0121\n","     88    17       0.0063      0.00625     5.72e-05       0.0472       0.0611       0.0393        0.063       0.0511       0.0489       0.0802       0.0645         0.48        0.005\n","     88    18      0.00616      0.00601     0.000149       0.0453         0.06       0.0351       0.0656       0.0504       0.0443       0.0828       0.0636        0.844      0.00879\n","     88    19      0.00655      0.00654     1.04e-05       0.0467       0.0626       0.0372       0.0658       0.0515       0.0485       0.0839       0.0662        0.192        0.002\n","     88    20      0.00774      0.00769     5.54e-05       0.0523       0.0678       0.0435         0.07       0.0568        0.055       0.0881       0.0715        0.466      0.00485\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     88     1      0.00722      0.00718     4.48e-05        0.049       0.0655       0.0379       0.0712       0.0546       0.0488       0.0901       0.0695        0.443      0.00461\n","     88     2      0.00721      0.00718     2.44e-05       0.0486       0.0656       0.0372       0.0716       0.0544        0.048        0.091       0.0695        0.302      0.00315\n","     88     3      0.00685      0.00682     2.78e-05       0.0474       0.0639       0.0362       0.0698        0.053       0.0463       0.0892       0.0678        0.303      0.00316\n","     88     4      0.00707      0.00701     5.34e-05       0.0479       0.0648       0.0367       0.0703       0.0535       0.0467       0.0907       0.0687        0.463      0.00482\n","     88     5      0.00654      0.00649      4.6e-05       0.0468       0.0623       0.0365       0.0673       0.0519       0.0471       0.0849        0.066        0.414      0.00431\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              88  278.140    0.005      0.00721     6.33e-05      0.00727       0.0497       0.0657       0.0396       0.0698       0.0547       0.0504       0.0886       0.0695        0.487      0.00507\n","! Validation         88  278.140    0.005      0.00694     3.93e-05      0.00698       0.0479       0.0644       0.0369         0.07       0.0535       0.0474       0.0892       0.0683        0.385      0.00401\n","Wall time: 278.14087382399975\n","! Best model       88    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     89     1      0.00782      0.00778     3.64e-05       0.0521       0.0683       0.0431       0.0703       0.0567       0.0541       0.0901       0.0721         0.37      0.00386\n","     89     2      0.00624      0.00621     2.41e-05       0.0455        0.061       0.0355       0.0655       0.0505       0.0449       0.0844       0.0646        0.292      0.00304\n","     89     3      0.00675      0.00673     2.23e-05       0.0475       0.0635       0.0372       0.0682       0.0527       0.0477       0.0868       0.0672        0.272      0.00283\n","     89     4      0.00515      0.00511     4.58e-05       0.0417       0.0553       0.0321       0.0609       0.0465       0.0402        0.077       0.0586        0.435      0.00453\n","     89     5      0.00596      0.00594     1.79e-05       0.0451       0.0597       0.0344       0.0665       0.0505       0.0437       0.0828       0.0632        0.286      0.00297\n","     89     6       0.0065      0.00645     5.46e-05       0.0462       0.0621       0.0355       0.0676       0.0516       0.0452       0.0865       0.0659        0.503      0.00524\n","     89     7      0.00677      0.00674     2.67e-05       0.0482       0.0635       0.0375       0.0695       0.0535       0.0474       0.0873       0.0673        0.357      0.00372\n","     89     8      0.00706      0.00703        3e-05       0.0477       0.0648       0.0378       0.0675       0.0526       0.0492       0.0882       0.0687        0.305      0.00318\n","     89     9      0.00617      0.00614     2.46e-05       0.0459       0.0606       0.0364       0.0648       0.0506       0.0466       0.0818       0.0642          0.3      0.00312\n","     89    10       0.0072      0.00715     4.85e-05       0.0492       0.0654       0.0385       0.0706       0.0545       0.0488       0.0899       0.0694        0.416      0.00433\n","     89    11      0.00683      0.00681     1.73e-05       0.0481       0.0639       0.0365       0.0712       0.0538       0.0464        0.089       0.0677        0.268      0.00279\n","     89    12      0.00783      0.00781     1.99e-05       0.0512       0.0684       0.0409       0.0718       0.0564       0.0517       0.0932       0.0724        0.247      0.00257\n","     89    13      0.00682      0.00673     9.15e-05       0.0488       0.0635       0.0403       0.0659       0.0531       0.0503       0.0837        0.067        0.654      0.00681\n","     89    14      0.00715      0.00684      0.00031       0.0476        0.064       0.0354       0.0719       0.0537       0.0457       0.0901       0.0679         1.16       0.0121\n","     89    15      0.00679      0.00674     5.42e-05        0.048       0.0635        0.038       0.0679        0.053       0.0491       0.0853       0.0672        0.464      0.00483\n","     89    16       0.0073      0.00712     0.000179       0.0492       0.0653       0.0397       0.0681       0.0539       0.0511        0.087        0.069        0.884      0.00921\n","     89    17      0.00717      0.00699     0.000181       0.0478       0.0647       0.0349       0.0737       0.0543       0.0441       0.0931       0.0686        0.903      0.00941\n","     89    18      0.00655      0.00654      6.3e-06       0.0469       0.0626       0.0358       0.0693       0.0525       0.0452       0.0876       0.0664        0.153       0.0016\n","     89    19      0.00611      0.00593      0.00018       0.0444       0.0596        0.034       0.0653       0.0496       0.0436       0.0828       0.0632        0.978       0.0102\n","     89    20      0.00669      0.00649     0.000196       0.0468       0.0623       0.0364       0.0676        0.052       0.0468       0.0853        0.066         1.02       0.0106\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     89     1      0.00718      0.00714     4.49e-05       0.0489       0.0654       0.0378       0.0711       0.0544       0.0487       0.0899       0.0693        0.443      0.00461\n","     89     2      0.00717      0.00715     2.44e-05       0.0485       0.0654       0.0371       0.0715       0.0543       0.0479       0.0908       0.0694        0.303      0.00315\n","     89     3      0.00682       0.0068     2.78e-05       0.0473       0.0638       0.0361       0.0697       0.0529       0.0461       0.0891       0.0676        0.303      0.00316\n","     89     4      0.00703      0.00698     5.35e-05       0.0478       0.0646       0.0366       0.0702       0.0534       0.0466       0.0905       0.0685        0.463      0.00483\n","     89     5      0.00651      0.00646     4.61e-05       0.0467       0.0622       0.0364       0.0672       0.0518        0.047       0.0848       0.0659        0.414      0.00431\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              89  281.269    0.005      0.00666     7.83e-05      0.00674       0.0474       0.0632        0.037       0.0682       0.0526       0.0472       0.0867       0.0669        0.513      0.00535\n","! Validation         89  281.269    0.005       0.0069     3.93e-05      0.00694       0.0478       0.0643       0.0368       0.0699       0.0534       0.0473       0.0891       0.0682        0.385      0.00401\n","Wall time: 281.2696637650006\n","! Best model       89    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     90     1      0.00733      0.00715     0.000178       0.0482       0.0654       0.0366       0.0712       0.0539       0.0476       0.0911       0.0694        0.857      0.00893\n","     90     2      0.00707      0.00676     0.000307       0.0488       0.0636       0.0381       0.0702       0.0541       0.0479       0.0869       0.0674          1.3       0.0135\n","     90     3      0.00728      0.00726      1.3e-05       0.0494       0.0659       0.0389       0.0703       0.0546       0.0493       0.0904       0.0699         0.23       0.0024\n","     90     4      0.00751      0.00705     0.000453       0.0488        0.065       0.0399       0.0667       0.0533       0.0508       0.0866       0.0687         1.56       0.0163\n","     90     5      0.00648      0.00644     4.13e-05       0.0451       0.0621       0.0346       0.0663       0.0504       0.0453       0.0864       0.0658        0.395      0.00412\n","     90     6      0.00624      0.00613     0.000117       0.0461       0.0606       0.0351       0.0681       0.0516       0.0442       0.0842       0.0642        0.765      0.00797\n","     90     7      0.00697      0.00653     0.000439       0.0474       0.0625        0.038       0.0663       0.0522       0.0483       0.0841       0.0662         1.49       0.0155\n","     90     8      0.00678      0.00663     0.000158       0.0481        0.063       0.0372       0.0698       0.0535       0.0467       0.0868       0.0668        0.781      0.00814\n","     90     9       0.0064      0.00609     0.000305       0.0456       0.0604        0.035       0.0667       0.0509       0.0442       0.0838        0.064         1.23       0.0129\n","     90    10      0.00639      0.00635     4.43e-05       0.0462       0.0616       0.0356       0.0672       0.0514       0.0453       0.0854       0.0653        0.306      0.00318\n","     90    11       0.0079      0.00785     5.09e-05        0.051       0.0685        0.039       0.0751       0.0571       0.0495       0.0958       0.0727        0.458      0.00478\n","     90    12      0.00811      0.00775     0.000351       0.0522       0.0681       0.0433         0.07       0.0567       0.0539         0.09        0.072         1.37       0.0143\n","     90    13      0.00767      0.00765     2.55e-05       0.0518       0.0676       0.0431       0.0691       0.0561       0.0546       0.0881       0.0714        0.338      0.00352\n","     90    14       0.0068      0.00677     2.63e-05       0.0479       0.0636       0.0368       0.0701       0.0534       0.0466       0.0884       0.0675        0.264      0.00275\n","     90    15       0.0071      0.00683     0.000275       0.0472       0.0639       0.0368        0.068       0.0524       0.0477       0.0878       0.0677         1.14       0.0119\n","     90    16      0.00576      0.00572     4.68e-05       0.0445       0.0585        0.035       0.0635       0.0492       0.0436       0.0803        0.062        0.405      0.00421\n","     90    17       0.0072      0.00709     0.000113       0.0492       0.0651       0.0391       0.0693       0.0542       0.0502       0.0877       0.0689        0.765      0.00796\n","     90    18       0.0062      0.00609     0.000117       0.0445       0.0604       0.0338        0.066       0.0499       0.0432       0.0848        0.064        0.667      0.00694\n","     90    19      0.00729      0.00699     0.000296       0.0495       0.0647       0.0393       0.0699       0.0546       0.0491       0.0879       0.0685         1.06       0.0111\n","     90    20      0.00625      0.00614     0.000109       0.0451       0.0606       0.0342        0.067       0.0506       0.0445       0.0841       0.0643        0.736      0.00767\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     90     1      0.00715      0.00711      4.5e-05       0.0488       0.0652       0.0377        0.071       0.0543       0.0485       0.0898       0.0691        0.444      0.00463\n","     90     2      0.00713      0.00711     2.44e-05       0.0484       0.0652       0.0369       0.0713       0.0541       0.0477       0.0906       0.0692        0.304      0.00316\n","     90     3      0.00679      0.00677     2.79e-05       0.0472       0.0636        0.036       0.0697       0.0528        0.046        0.089       0.0675        0.303      0.00316\n","     90     4        0.007      0.00694     5.36e-05       0.0476       0.0645       0.0364         0.07       0.0532       0.0464       0.0904       0.0684        0.464      0.00483\n","     90     5      0.00648      0.00643     4.62e-05       0.0466        0.062       0.0363       0.0671       0.0517       0.0468       0.0847       0.0657        0.415      0.00432\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              90  284.367    0.005      0.00676     0.000173      0.00694       0.0478       0.0636       0.0375       0.0685        0.053       0.0477       0.0871       0.0674        0.807       0.0084\n","! Validation         90  284.367    0.005      0.00687     3.94e-05      0.00691       0.0477       0.0641       0.0367       0.0698       0.0532       0.0471       0.0889        0.068        0.386      0.00402\n","Wall time: 284.36779346000003\n","! Best model       90    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     91     1      0.00818      0.00815     3.17e-05       0.0535       0.0698       0.0455       0.0693       0.0574       0.0583       0.0885       0.0734        0.318      0.00331\n","     91     2      0.00684      0.00662     0.000214       0.0473        0.063       0.0365       0.0688       0.0527       0.0458       0.0878       0.0668         1.02       0.0107\n","     91     3      0.00955      0.00951     3.81e-05       0.0578       0.0754        0.045       0.0832       0.0641       0.0561        0.104         0.08        0.323      0.00336\n","     91     4      0.00882      0.00872     9.75e-05       0.0557       0.0723       0.0464       0.0744       0.0604       0.0591       0.0932       0.0761        0.693      0.00722\n","     91     5      0.00748      0.00738     9.77e-05       0.0519       0.0665       0.0456       0.0645       0.0551       0.0567       0.0826       0.0696        0.572      0.00596\n","     91     6      0.00601      0.00596      4.7e-05       0.0446       0.0597       0.0339        0.066         0.05       0.0435       0.0832       0.0634        0.457      0.00476\n","     91     7      0.00632      0.00628      3.4e-05       0.0466       0.0613       0.0376       0.0648       0.0512       0.0475       0.0822       0.0649        0.423      0.00441\n","     91     8      0.00622      0.00616     5.88e-05       0.0455       0.0607       0.0335       0.0694       0.0515       0.0426       0.0862       0.0644        0.478      0.00497\n","     91     9      0.00665      0.00662     2.68e-05       0.0473       0.0629       0.0377       0.0665       0.0521       0.0476       0.0857       0.0667        0.315      0.00328\n","     91    10      0.00655      0.00645     9.04e-05       0.0464       0.0622       0.0356        0.068       0.0518       0.0448        0.087       0.0659        0.494      0.00515\n","     91    11      0.00788      0.00785      2.6e-05       0.0507       0.0686       0.0377       0.0765       0.0571       0.0486       0.0968       0.0727        0.329      0.00342\n","     91    12      0.00651       0.0065      1.2e-05       0.0471       0.0624       0.0376       0.0661       0.0518       0.0468       0.0853       0.0661        0.222      0.00231\n","     91    13      0.00778      0.00772     6.56e-05       0.0523        0.068        0.045       0.0669       0.0559       0.0567       0.0861       0.0714        0.508      0.00529\n","     91    14      0.00609      0.00607     2.54e-05       0.0456       0.0603       0.0359       0.0651       0.0505        0.046       0.0817       0.0638        0.302      0.00315\n","     91    15      0.00629      0.00625     3.72e-05       0.0461       0.0612       0.0357       0.0668       0.0513       0.0451       0.0846       0.0649        0.385      0.00401\n","     91    16      0.00702        0.007     2.85e-05       0.0487       0.0647        0.039       0.0681       0.0536       0.0492       0.0879       0.0685         0.37      0.00386\n","     91    17      0.00787      0.00786      1.4e-05       0.0506       0.0686       0.0387       0.0743       0.0565       0.0509       0.0945       0.0727        0.211       0.0022\n","     91    18      0.00637      0.00633     3.61e-05       0.0442       0.0616       0.0333        0.066       0.0497       0.0434       0.0872       0.0653        0.337      0.00351\n","     91    19      0.00731      0.00729     1.82e-05       0.0495       0.0661       0.0371       0.0743       0.0557       0.0467       0.0935       0.0701        0.276      0.00288\n","     91    20      0.00904      0.00894     9.98e-05       0.0572       0.0732       0.0485       0.0746       0.0615       0.0605       0.0934        0.077        0.724      0.00754\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     91     1      0.00712      0.00708     4.49e-05       0.0487       0.0651       0.0376       0.0709       0.0542       0.0484       0.0896        0.069        0.442       0.0046\n","     91     2      0.00711      0.00709     2.44e-05       0.0483       0.0651       0.0368       0.0713        0.054       0.0476       0.0906       0.0691        0.303      0.00316\n","     91     3      0.00677      0.00674      2.8e-05       0.0471       0.0635       0.0358       0.0696       0.0527       0.0458       0.0889       0.0674        0.304      0.00317\n","     91     4      0.00697      0.00691     5.36e-05       0.0475       0.0643       0.0363       0.0699       0.0531       0.0462       0.0902       0.0682        0.464      0.00483\n","     91     5      0.00645       0.0064     4.64e-05       0.0464       0.0619       0.0362        0.067       0.0516       0.0466       0.0846       0.0656        0.415      0.00433\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              91  287.476    0.005      0.00718     5.49e-05      0.00724       0.0494       0.0656       0.0393       0.0697       0.0545       0.0501       0.0887       0.0694        0.438      0.00456\n","! Validation         91  287.476    0.005      0.00684     3.95e-05      0.00688       0.0476        0.064       0.0365       0.0697       0.0531       0.0469       0.0888       0.0679        0.386      0.00402\n","Wall time: 287.4769859830003\n","! Best model       91    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     92     1      0.00946      0.00932     0.000142       0.0586       0.0747       0.0534       0.0692       0.0613       0.0658       0.0898       0.0778        0.745      0.00776\n","     92     2       0.0064      0.00636     4.43e-05       0.0461       0.0617       0.0361        0.066       0.0511       0.0456       0.0852       0.0654        0.446      0.00465\n","     92     3      0.00655      0.00651     3.99e-05       0.0482       0.0624       0.0408       0.0631       0.0519       0.0506       0.0809       0.0658        0.378      0.00393\n","     92     4      0.00892      0.00891     9.93e-06       0.0565        0.073       0.0469       0.0758       0.0613       0.0589       0.0953       0.0771        0.192        0.002\n","     92     5      0.00986       0.0097     0.000164       0.0584       0.0762       0.0468       0.0815       0.0642       0.0586        0.103       0.0806        0.901      0.00938\n","     92     6        0.008      0.00796      3.7e-05       0.0519        0.069       0.0415       0.0728       0.0571       0.0521       0.0942       0.0731        0.402      0.00419\n","     92     7       0.0065      0.00644     6.03e-05       0.0469       0.0621       0.0368       0.0671        0.052       0.0467       0.0849       0.0658        0.396      0.00412\n","     92     8      0.00715      0.00711     4.11e-05       0.0487       0.0653       0.0378       0.0707       0.0542       0.0474        0.091       0.0692        0.338      0.00352\n","     92     9      0.00686      0.00682     3.75e-05       0.0499       0.0639       0.0431       0.0634       0.0533       0.0539       0.0802       0.0671        0.379      0.00395\n","     92    10      0.00702      0.00698     4.34e-05       0.0486       0.0646         0.04       0.0658       0.0529       0.0509       0.0857       0.0683        0.412      0.00429\n","     92    11       0.0064      0.00634      6.2e-05       0.0464       0.0616       0.0376        0.064       0.0508       0.0472       0.0832       0.0652        0.495      0.00516\n","     92    12      0.00665      0.00653     0.000117       0.0479       0.0625       0.0391       0.0656       0.0524       0.0497       0.0823        0.066        0.668      0.00696\n","     92    13      0.00718      0.00715      3.8e-05       0.0487       0.0654       0.0382       0.0698        0.054       0.0494       0.0892       0.0693        0.372      0.00388\n","     92    14      0.00719      0.00701      0.00018       0.0487       0.0648       0.0384       0.0693       0.0539        0.049       0.0882       0.0686        0.963         0.01\n","     92    15      0.00622      0.00618      4.7e-05       0.0459       0.0608       0.0346       0.0685       0.0515       0.0437       0.0852       0.0645        0.358      0.00373\n","     92    16      0.00747      0.00737     0.000108       0.0506       0.0664       0.0388        0.074       0.0564       0.0485       0.0924       0.0704        0.672        0.007\n","     92    17      0.00695      0.00694     1.09e-05       0.0485       0.0644       0.0366       0.0722       0.0544       0.0467       0.0899       0.0683        0.222      0.00231\n","     92    18      0.00762      0.00757     4.47e-05       0.0515       0.0673       0.0415       0.0716       0.0565       0.0528       0.0896       0.0712        0.406      0.00423\n","     92    19      0.00671      0.00666     4.65e-05       0.0476       0.0631       0.0374       0.0681       0.0528       0.0469        0.087       0.0669        0.444      0.00462\n","     92    20      0.00685      0.00683     1.84e-05        0.049       0.0639       0.0391       0.0688        0.054       0.0492       0.0862       0.0677        0.279       0.0029\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     92     1       0.0071      0.00705     4.48e-05       0.0486        0.065       0.0375       0.0708       0.0541       0.0482       0.0895       0.0689         0.44      0.00458\n","     92     2      0.00708      0.00706     2.44e-05       0.0482        0.065       0.0367       0.0712       0.0539       0.0474       0.0904       0.0689        0.303      0.00316\n","     92     3      0.00674      0.00672     2.82e-05        0.047       0.0634       0.0357       0.0695       0.0526       0.0457       0.0888       0.0672        0.306      0.00318\n","     92     4      0.00694      0.00688     5.38e-05       0.0474       0.0642       0.0362       0.0699        0.053       0.0461       0.0901       0.0681        0.465      0.00484\n","     92     5      0.00642      0.00637     4.67e-05       0.0463       0.0618        0.036       0.0668       0.0514       0.0464       0.0845       0.0654        0.417      0.00434\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              92  290.578    0.005      0.00723     6.46e-05       0.0073       0.0499       0.0658       0.0402       0.0694       0.0548       0.0509       0.0883       0.0696        0.473      0.00493\n","! Validation         92  290.578    0.005      0.00682     3.96e-05      0.00686       0.0475       0.0639       0.0364       0.0696        0.053       0.0468       0.0887       0.0677        0.386      0.00402\n","Wall time: 290.578468576\n","! Best model       92    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     93     1      0.00653       0.0065     2.98e-05       0.0466       0.0624       0.0361       0.0674       0.0518       0.0466       0.0857       0.0661        0.335      0.00349\n","     93     2       0.0079      0.00782      7.1e-05       0.0545       0.0684       0.0491       0.0653       0.0572       0.0603       0.0823       0.0713        0.498      0.00519\n","     93     3      0.00849      0.00842     7.76e-05       0.0542        0.071       0.0442       0.0741       0.0591       0.0567       0.0931       0.0749        0.617      0.00643\n","     93     4      0.00777      0.00773     3.68e-05       0.0511        0.068       0.0397        0.074       0.0568       0.0497       0.0945       0.0721        0.438      0.00456\n","     93     5      0.00659      0.00651     7.72e-05       0.0462       0.0624       0.0343       0.0701       0.0522       0.0441       0.0883       0.0662        0.586       0.0061\n","     93     6       0.0069      0.00689      1.3e-05       0.0481       0.0642       0.0369       0.0705       0.0537       0.0467       0.0894       0.0681        0.187      0.00195\n","     93     7      0.00759      0.00742     0.000168        0.051       0.0666       0.0428       0.0675       0.0551       0.0547       0.0857       0.0702        0.927      0.00966\n","     93     8      0.00712      0.00708     4.06e-05       0.0484       0.0651       0.0391        0.067       0.0531       0.0498        0.088       0.0689        0.422       0.0044\n","     93     9      0.00699      0.00688     0.000113       0.0484       0.0642        0.037       0.0713       0.0542       0.0471        0.089        0.068        0.706      0.00736\n","     93    10      0.00737      0.00731      5.5e-05       0.0497       0.0662       0.0414       0.0662       0.0538       0.0536       0.0859       0.0698        0.445      0.00464\n","     93    11      0.00772      0.00765     6.55e-05        0.051       0.0677       0.0391       0.0746       0.0569       0.0496       0.0939       0.0717        0.583      0.00607\n","     93    12      0.00748      0.00729      0.00019       0.0496        0.066       0.0384       0.0721       0.0552       0.0477       0.0923         0.07        0.955      0.00995\n","     93    13      0.00591      0.00574     0.000173       0.0445       0.0586       0.0351       0.0634       0.0492       0.0445       0.0796       0.0621        0.799      0.00833\n","     93    14      0.00793      0.00771     0.000219        0.051       0.0679       0.0397       0.0736       0.0566       0.0508       0.0931        0.072        0.999       0.0104\n","     93    15      0.00764      0.00751     0.000125       0.0506       0.0671       0.0407       0.0705       0.0556       0.0517       0.0903        0.071        0.801      0.00834\n","     93    16      0.00698      0.00692     5.07e-05       0.0489       0.0644       0.0404        0.066       0.0532        0.051        0.085        0.068        0.466      0.00485\n","     93    17      0.00568      0.00557     0.000114       0.0439       0.0577       0.0358       0.0601       0.0479       0.0456       0.0763        0.061        0.719      0.00749\n","     93    18      0.00797      0.00784     0.000132       0.0535       0.0685       0.0437        0.073       0.0584       0.0543       0.0904       0.0724        0.835       0.0087\n","     93    19       0.0113        0.011     0.000282       0.0616       0.0812       0.0494       0.0861       0.0677       0.0625        0.109       0.0859         1.24       0.0129\n","     93    20      0.00948      0.00947     1.14e-05       0.0582       0.0753       0.0479       0.0788       0.0634         0.06       0.0991       0.0795        0.217      0.00226\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     93     1      0.00707      0.00703     4.48e-05       0.0484       0.0648       0.0373       0.0707        0.054       0.0481       0.0894       0.0687         0.44      0.00459\n","     93     2      0.00706      0.00703     2.43e-05       0.0481       0.0649       0.0366       0.0711       0.0538       0.0473       0.0903       0.0688        0.303      0.00316\n","     93     3      0.00672      0.00669      2.8e-05       0.0469       0.0633       0.0356       0.0694       0.0525       0.0455       0.0887       0.0671        0.305      0.00317\n","     93     4      0.00691      0.00685     5.36e-05       0.0473       0.0641       0.0361       0.0697       0.0529       0.0459         0.09       0.0679        0.464      0.00483\n","     93     5       0.0064      0.00635     4.64e-05       0.0462       0.0617       0.0359       0.0668       0.0514       0.0463       0.0844       0.0653        0.416      0.00433\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              93  293.686    0.005      0.00746     0.000102      0.00757       0.0506       0.0668       0.0405       0.0706       0.0556       0.0516       0.0898       0.0707        0.639      0.00665\n","! Validation         93  293.686    0.005      0.00679     3.94e-05      0.00683       0.0474       0.0638       0.0363       0.0695       0.0529       0.0466       0.0886       0.0676        0.386      0.00402\n","Wall time: 293.686484457\n","! Best model       93    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     94     1      0.00678      0.00674     3.84e-05       0.0478       0.0635       0.0379       0.0677       0.0528       0.0485        0.086       0.0673        0.335      0.00349\n","     94     2      0.00752      0.00734      0.00018       0.0496       0.0663        0.038       0.0728       0.0554       0.0489       0.0916       0.0703        0.901      0.00939\n","     94     3      0.00781      0.00779     2.47e-05       0.0528       0.0683       0.0438       0.0707       0.0572       0.0549       0.0892        0.072        0.343      0.00358\n","     94     4      0.00799      0.00779     0.000199       0.0538       0.0683       0.0462       0.0691       0.0576       0.0567       0.0869       0.0718        0.949      0.00988\n","     94     5      0.00798      0.00786     0.000111       0.0522       0.0686       0.0413        0.074       0.0577       0.0522       0.0931       0.0727        0.768        0.008\n","     94     6      0.00627       0.0062     7.01e-05       0.0452       0.0609       0.0357       0.0642       0.0499       0.0454       0.0837       0.0646        0.562      0.00586\n","     94     7      0.00733      0.00706     0.000271       0.0487        0.065       0.0379       0.0705       0.0542       0.0491       0.0886       0.0689          1.2       0.0125\n","     94     8       0.0081      0.00799     0.000107       0.0528       0.0691       0.0418       0.0746       0.0582        0.052       0.0945       0.0733        0.664      0.00692\n","     94     9      0.00818       0.0076     0.000577       0.0513       0.0675        0.042       0.0701        0.056       0.0535        0.089       0.0713          1.7       0.0178\n","     94    10      0.00665       0.0064     0.000248       0.0459       0.0619       0.0358       0.0661        0.051       0.0463        0.085       0.0656         0.91      0.00948\n","     94    11      0.00707      0.00686     0.000214       0.0486       0.0641       0.0375       0.0708       0.0542       0.0475       0.0884       0.0679         1.07       0.0111\n","     94    12      0.00781      0.00772     8.12e-05       0.0519        0.068        0.044       0.0678       0.0559       0.0558       0.0875       0.0716         0.66      0.00687\n","     94    13      0.00718      0.00717     7.24e-06       0.0495       0.0655       0.0383       0.0717        0.055       0.0489       0.0899       0.0694        0.176      0.00183\n","     94    14      0.00605      0.00594     0.000107       0.0445       0.0596       0.0348       0.0639       0.0493       0.0442       0.0821       0.0632        0.708      0.00737\n","     94    15      0.00736      0.00734     1.67e-05       0.0508       0.0663       0.0418       0.0688       0.0553       0.0527       0.0874         0.07        0.268      0.00279\n","     94    16      0.00785      0.00782      2.5e-05       0.0519       0.0684       0.0424       0.0709       0.0566       0.0537        0.091       0.0723        0.219      0.00229\n","     94    17      0.00703      0.00701     1.84e-05       0.0475       0.0648       0.0354       0.0715       0.0535        0.046       0.0914       0.0687        0.271      0.00282\n","     94    18      0.00637      0.00628     9.13e-05       0.0461       0.0613       0.0351       0.0683       0.0517       0.0444       0.0857        0.065        0.659      0.00686\n","     94    19      0.00633      0.00624     8.27e-05       0.0468       0.0611       0.0382        0.064       0.0511       0.0481       0.0811       0.0646        0.632      0.00659\n","     94    20      0.00642       0.0062     0.000217       0.0456       0.0609       0.0354        0.066       0.0507       0.0454       0.0837       0.0646         0.99       0.0103\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     94     1      0.00704        0.007     4.52e-05       0.0483       0.0647       0.0372       0.0705       0.0539       0.0479       0.0893       0.0686        0.445      0.00463\n","     94     2      0.00703      0.00701     2.43e-05        0.048       0.0648       0.0365        0.071       0.0538       0.0471       0.0902       0.0687        0.303      0.00316\n","     94     3       0.0067      0.00667     2.77e-05       0.0468       0.0632       0.0355       0.0694       0.0525       0.0454       0.0886        0.067        0.302      0.00314\n","     94     4      0.00688      0.00683     5.35e-05       0.0472       0.0639        0.036       0.0696       0.0528       0.0458       0.0898       0.0678        0.463      0.00482\n","     94     5      0.00637      0.00633     4.61e-05       0.0461       0.0615       0.0358       0.0667       0.0512       0.0461       0.0843       0.0652        0.415      0.00432\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              94  296.775    0.005      0.00707     0.000134       0.0072       0.0492        0.065       0.0392       0.0692       0.0542       0.0499       0.0879       0.0689        0.699      0.00729\n","! Validation         94  296.775    0.005      0.00677     3.93e-05      0.00681       0.0473       0.0636       0.0362       0.0695       0.0528       0.0465       0.0885       0.0675        0.385      0.00401\n","Wall time: 296.77573258699977\n","! Best model       94    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     95     1       0.0067      0.00666     4.49e-05       0.0476       0.0631       0.0372       0.0684       0.0528       0.0474       0.0864       0.0669         0.38      0.00395\n","     95     2      0.00747      0.00729     0.000177       0.0514       0.0661       0.0426       0.0688       0.0557       0.0532       0.0862       0.0697         0.95       0.0099\n","     95     3      0.00639      0.00638     1.17e-05       0.0471       0.0618       0.0386       0.0641       0.0514       0.0482       0.0825       0.0654        0.174      0.00181\n","     95     4      0.00689      0.00684     5.29e-05       0.0474        0.064       0.0363       0.0696       0.0529       0.0473       0.0884       0.0678        0.535      0.00557\n","     95     5      0.00648       0.0064      7.4e-05       0.0467       0.0619       0.0363       0.0675       0.0519       0.0455       0.0858       0.0656        0.517      0.00539\n","     95     6       0.0081      0.00804     5.62e-05       0.0516       0.0694       0.0391       0.0767       0.0579       0.0501        0.097       0.0736        0.446      0.00464\n","     95     7      0.00747      0.00733     0.000143       0.0511       0.0662       0.0427       0.0678       0.0553        0.054       0.0857       0.0698        0.709      0.00738\n","     95     8       0.0065      0.00647     3.32e-05       0.0471       0.0622       0.0362       0.0688       0.0525        0.046       0.0859       0.0659        0.371      0.00387\n","     95     9      0.00721      0.00718     3.68e-05       0.0491       0.0655       0.0384       0.0705       0.0544       0.0485       0.0905       0.0695        0.367      0.00383\n","     95    10      0.00888      0.00881     6.33e-05       0.0568       0.0726        0.051       0.0684       0.0597       0.0647       0.0864       0.0755        0.549      0.00572\n","     95    11      0.00772      0.00766     5.81e-05       0.0514       0.0677         0.04       0.0743       0.0572       0.0505        0.093       0.0718        0.503      0.00524\n","     95    12      0.00574       0.0057     3.76e-05       0.0442       0.0584       0.0339        0.065       0.0494       0.0427       0.0812       0.0619        0.373      0.00389\n","     95    13      0.00638      0.00626     0.000117       0.0461       0.0612       0.0373       0.0636       0.0505       0.0478       0.0817       0.0648        0.659      0.00686\n","     95    14      0.00791      0.00787     3.78e-05       0.0508       0.0686        0.038       0.0765       0.0572       0.0489       0.0967       0.0728        0.401      0.00418\n","     95    15      0.00686      0.00658     0.000279       0.0475       0.0628       0.0369       0.0685       0.0527       0.0472       0.0858       0.0665         1.23       0.0128\n","     95    16      0.00756       0.0075     5.52e-05       0.0502        0.067       0.0388        0.073       0.0559       0.0499       0.0921        0.071         0.45      0.00469\n","     95    17      0.00626      0.00612     0.000136        0.045       0.0605       0.0349       0.0652         0.05        0.045       0.0833       0.0642        0.758       0.0079\n","     95    18      0.00697      0.00692     5.06e-05        0.049       0.0644       0.0397       0.0676       0.0537       0.0504       0.0858       0.0681        0.446      0.00465\n","     95    19      0.00688      0.00684     3.37e-05       0.0461        0.064       0.0344       0.0694       0.0519       0.0448       0.0909       0.0679        0.342      0.00356\n","     95    20      0.00627      0.00623     4.31e-05       0.0458        0.061       0.0351       0.0671       0.0511       0.0449       0.0846       0.0647        0.371      0.00387\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     95     1      0.00702      0.00698     4.49e-05       0.0483       0.0646       0.0372       0.0705       0.0538       0.0478       0.0892       0.0685         0.44      0.00459\n","     95     2      0.00701      0.00698     2.44e-05       0.0479       0.0647       0.0364       0.0709       0.0537        0.047       0.0901       0.0686        0.304      0.00316\n","     95     3      0.00667      0.00664     2.82e-05       0.0467       0.0631       0.0354       0.0693       0.0524       0.0453       0.0885       0.0669        0.306      0.00318\n","     95     4      0.00686      0.00681     5.38e-05       0.0471       0.0638       0.0358       0.0696       0.0527       0.0456       0.0898       0.0677        0.465      0.00484\n","     95     5      0.00635      0.00631     4.67e-05        0.046       0.0614       0.0357       0.0666       0.0512        0.046       0.0842       0.0651        0.417      0.00434\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              95  299.873    0.005      0.00695     7.71e-05      0.00703       0.0486       0.0645       0.0384        0.069       0.0537        0.049       0.0876       0.0683        0.527      0.00549\n","! Validation         95  299.873    0.005      0.00674     3.96e-05      0.00678       0.0472       0.0635       0.0361       0.0694       0.0527       0.0464       0.0884       0.0674        0.386      0.00402\n","Wall time: 299.87385099600033\n","! Best model       95    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     96     1       0.0073      0.00729     1.07e-05       0.0502       0.0661       0.0396       0.0715       0.0556       0.0493       0.0908         0.07        0.219      0.00228\n","     96     2      0.00847      0.00846     1.22e-05       0.0529       0.0711       0.0425       0.0738       0.0581       0.0538        0.097       0.0754        0.223      0.00232\n","     96     3      0.00778      0.00773     5.69e-05       0.0526        0.068       0.0424       0.0729       0.0577       0.0533       0.0905       0.0719        0.444      0.00463\n","     96     4      0.00653      0.00647     6.21e-05       0.0463       0.0622       0.0359        0.067       0.0515       0.0459       0.0861        0.066        0.507      0.00528\n","     96     5      0.00686      0.00684     2.02e-05       0.0478        0.064       0.0386        0.066       0.0523       0.0497       0.0857       0.0677          0.3      0.00312\n","     96     6      0.00751      0.00741     0.000102       0.0509       0.0666       0.0413       0.0699       0.0556       0.0535        0.087       0.0703        0.608      0.00633\n","     96     7      0.00761      0.00754     7.48e-05       0.0497       0.0672       0.0385       0.0721       0.0553       0.0494       0.0929       0.0712         0.51      0.00531\n","     96     8      0.00667      0.00662     5.25e-05        0.047        0.063       0.0372       0.0665       0.0519       0.0474        0.086       0.0667        0.526      0.00548\n","     96     9      0.00654      0.00647     6.25e-05       0.0467       0.0622       0.0377       0.0647       0.0512       0.0483       0.0834       0.0659        0.551      0.00574\n","     96    10      0.00635      0.00633     1.89e-05       0.0452       0.0615       0.0335       0.0685        0.051       0.0431       0.0874       0.0653        0.268      0.00279\n","     96    11      0.00688      0.00684     3.13e-05       0.0483        0.064        0.038       0.0688       0.0534       0.0486        0.087       0.0678        0.284      0.00296\n","     96    12      0.00549      0.00537     0.000123       0.0425       0.0567       0.0324       0.0626       0.0475        0.041       0.0793       0.0601        0.656      0.00684\n","     96    13      0.00635      0.00633     2.09e-05       0.0467       0.0615       0.0375       0.0651       0.0513       0.0473        0.083       0.0651        0.318      0.00332\n","     96    14      0.00604      0.00596     7.61e-05       0.0441       0.0597       0.0327       0.0668       0.0498       0.0415       0.0852       0.0633        0.632      0.00659\n","     96    15      0.00617      0.00614     3.02e-05       0.0458       0.0606        0.035       0.0673       0.0512       0.0441       0.0845       0.0643        0.284      0.00296\n","     96    16      0.00525      0.00517     7.73e-05       0.0416       0.0556       0.0329       0.0589       0.0459        0.042       0.0759        0.059        0.506      0.00528\n","     96    17       0.0065      0.00645     5.18e-05       0.0469       0.0621       0.0373        0.066       0.0517       0.0476        0.084       0.0658        0.438      0.00456\n","     96    18      0.00565      0.00562     3.08e-05       0.0435        0.058       0.0327       0.0652       0.0489       0.0414       0.0816       0.0615        0.367      0.00383\n","     96    19      0.00591      0.00578     0.000132       0.0441       0.0588       0.0339       0.0645       0.0492       0.0439       0.0808       0.0623        0.802      0.00836\n","     96    20      0.00642      0.00637     5.23e-05       0.0463       0.0617       0.0348       0.0694       0.0521       0.0437       0.0873       0.0655        0.496      0.00517\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     96     1      0.00699      0.00695     4.49e-05       0.0482       0.0645       0.0371       0.0703       0.0537       0.0477        0.089       0.0684         0.44      0.00458\n","     96     2      0.00698      0.00696     2.44e-05       0.0478       0.0645       0.0363       0.0708       0.0536       0.0469         0.09       0.0684        0.304      0.00316\n","     96     3      0.00665      0.00663     2.83e-05       0.0466        0.063       0.0353       0.0693       0.0523       0.0452       0.0884       0.0668        0.306      0.00319\n","     96     4      0.00684      0.00678     5.38e-05        0.047       0.0637       0.0358       0.0695       0.0526       0.0455       0.0897       0.0676        0.464      0.00484\n","     96     5      0.00633      0.00629     4.67e-05       0.0459       0.0613       0.0356       0.0665       0.0511       0.0459       0.0842        0.065        0.417      0.00435\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              96  302.996    0.005      0.00656     5.49e-05      0.00661        0.047       0.0627       0.0367       0.0674       0.0521       0.0469       0.0859       0.0664        0.447      0.00466\n","! Validation         96  302.996    0.005      0.00672     3.96e-05      0.00676       0.0471       0.0634        0.036       0.0693       0.0527       0.0462       0.0883       0.0673        0.386      0.00402\n","Wall time: 302.99704891000056\n","! Best model       96    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     97     1      0.00624      0.00614     0.000103       0.0447       0.0606       0.0334       0.0673       0.0504       0.0428       0.0857       0.0643        0.681       0.0071\n","     97     2      0.00715       0.0071     4.76e-05       0.0494       0.0652       0.0398       0.0686       0.0542       0.0504       0.0875        0.069        0.463      0.00483\n","     97     3      0.00645       0.0064     5.21e-05       0.0472       0.0619       0.0384       0.0648       0.0516       0.0484       0.0824       0.0654        0.472      0.00492\n","     97     4      0.00669      0.00663     5.99e-05       0.0459        0.063       0.0349        0.068       0.0514       0.0446       0.0891       0.0668        0.528       0.0055\n","     97     5      0.00656      0.00653     2.72e-05       0.0468       0.0625       0.0364       0.0675        0.052       0.0473       0.0852       0.0662        0.366      0.00381\n","     97     6      0.00585      0.00576     9.14e-05       0.0445       0.0587       0.0345       0.0645       0.0495       0.0432       0.0813       0.0622        0.644       0.0067\n","     97     7      0.00668      0.00659     8.72e-05       0.0457       0.0628       0.0346       0.0677       0.0512        0.045       0.0883       0.0666        0.649      0.00676\n","     97     8       0.0064      0.00631     9.59e-05       0.0465       0.0614        0.037       0.0656       0.0513       0.0472        0.083       0.0651        0.656      0.00683\n","     97     9      0.00653      0.00647     5.96e-05       0.0468       0.0622       0.0376       0.0652       0.0514       0.0481       0.0836       0.0658        0.473      0.00493\n","     97    10      0.00686       0.0067      0.00016       0.0474       0.0633       0.0353       0.0715       0.0534       0.0454       0.0889       0.0671        0.775      0.00807\n","     97    11      0.00767      0.00766     1.05e-05       0.0522       0.0677       0.0433         0.07       0.0567        0.055       0.0878       0.0714        0.204      0.00212\n","     97    12      0.00754      0.00743     0.000101       0.0516       0.0667        0.043        0.069        0.056       0.0541       0.0866       0.0703        0.727      0.00757\n","     97    13      0.00734      0.00725     8.33e-05       0.0489       0.0659       0.0393       0.0682       0.0537        0.051       0.0885       0.0697        0.604      0.00629\n","     97    14      0.00557      0.00555     2.24e-05       0.0429       0.0576       0.0335       0.0617       0.0476       0.0424       0.0798       0.0611        0.288        0.003\n","     97    15      0.00749      0.00747     2.31e-05       0.0485       0.0669        0.036       0.0735       0.0548        0.047       0.0948       0.0709        0.317       0.0033\n","     97    16      0.00804      0.00774       0.0003       0.0525       0.0681       0.0419       0.0735       0.0577        0.052       0.0922       0.0721         1.21       0.0127\n","     97    17       0.0086      0.00847      0.00013       0.0549       0.0712       0.0469       0.0708       0.0589       0.0592       0.0906       0.0749        0.703      0.00733\n","     97    18      0.00766      0.00733     0.000329       0.0493       0.0663       0.0379       0.0721        0.055       0.0489       0.0915       0.0702         1.27       0.0133\n","     97    19      0.00617      0.00616     6.68e-06       0.0466       0.0607       0.0379       0.0639       0.0509        0.048       0.0803       0.0642        0.185      0.00193\n","     97    20      0.00683      0.00666     0.000168       0.0477       0.0632       0.0385        0.066       0.0523       0.0488       0.0849       0.0668        0.926      0.00965\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     97     1      0.00697      0.00693     4.47e-05       0.0481       0.0644        0.037       0.0703       0.0536       0.0476       0.0889       0.0683        0.435      0.00454\n","     97     2      0.00696      0.00693     2.45e-05       0.0477       0.0644       0.0362       0.0708       0.0535       0.0468       0.0899       0.0683        0.306      0.00319\n","     97     3      0.00663       0.0066     2.88e-05       0.0465       0.0629       0.0352       0.0692       0.0522        0.045       0.0883       0.0667         0.31      0.00323\n","     97     4      0.00682      0.00676     5.42e-05       0.0469       0.0636       0.0357       0.0694       0.0526       0.0454       0.0896       0.0675        0.467      0.00486\n","     97     5      0.00631      0.00626     4.74e-05       0.0458       0.0612       0.0355       0.0664        0.051       0.0457        0.084       0.0649         0.42      0.00437\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              97  306.146    0.005      0.00682     9.79e-05      0.00692        0.048       0.0639        0.038        0.068        0.053       0.0486       0.0867       0.0677        0.607      0.00633\n","! Validation         97  306.146    0.005       0.0067     3.99e-05      0.00674        0.047       0.0633       0.0359       0.0692       0.0526       0.0461       0.0882       0.0671        0.387      0.00404\n","Wall time: 306.1463422100005\n","! Best model       97    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     98     1       0.0074      0.00716     0.000246       0.0494       0.0654       0.0386       0.0709       0.0548       0.0489       0.0898       0.0694         1.06       0.0111\n","     98     2      0.00701      0.00695     5.91e-05       0.0491       0.0645       0.0379       0.0715       0.0547       0.0481       0.0886       0.0684         0.47       0.0049\n","     98     3      0.00609      0.00577     0.000317       0.0431       0.0588        0.032       0.0653       0.0486       0.0405       0.0842       0.0623         1.28       0.0134\n","     98     4      0.00723       0.0072     2.38e-05        0.048       0.0657       0.0355       0.0729       0.0542        0.046       0.0932       0.0696        0.268      0.00279\n","     98     5      0.00723      0.00689     0.000342       0.0473       0.0642       0.0359       0.0702        0.053       0.0458       0.0904       0.0681         1.34       0.0139\n","     98     6      0.00601       0.0058     0.000206       0.0444       0.0589        0.033       0.0672       0.0501       0.0417       0.0833       0.0625        0.958      0.00998\n","     98     7      0.00659      0.00624     0.000347       0.0456       0.0611        0.035       0.0668       0.0509       0.0449       0.0846       0.0648         1.34        0.014\n","     98     8      0.00612      0.00581      0.00031       0.0445        0.059       0.0352       0.0631       0.0492       0.0448       0.0801       0.0625         1.19       0.0124\n","     98     9      0.00692      0.00688     4.22e-05       0.0487       0.0642       0.0391       0.0679       0.0535       0.0493       0.0865       0.0679        0.439      0.00458\n","     98    10       0.0073      0.00693      0.00037       0.0482       0.0644       0.0377       0.0692       0.0535       0.0489       0.0876       0.0682         1.38       0.0144\n","     98    11      0.00706      0.00704     2.01e-05       0.0483       0.0649       0.0362       0.0726       0.0544       0.0467        0.091       0.0688        0.282      0.00294\n","     98    12      0.00635      0.00622     0.000125       0.0462        0.061       0.0368       0.0649       0.0509       0.0465       0.0828       0.0646        0.772      0.00804\n","     98    13      0.00585      0.00579     6.75e-05       0.0445       0.0588       0.0339       0.0656       0.0498       0.0428        0.082       0.0624        0.584      0.00609\n","     98    14      0.00632      0.00628     4.14e-05       0.0455       0.0613       0.0357       0.0652       0.0504        0.045       0.0849        0.065        0.393      0.00409\n","     98    15      0.00605      0.00586     0.000191       0.0441       0.0592       0.0341       0.0642       0.0492       0.0429       0.0827       0.0628        0.906      0.00943\n","     98    16        0.005      0.00498     1.84e-05       0.0417       0.0546       0.0334       0.0583       0.0458        0.042       0.0737       0.0578        0.252      0.00263\n","     98    17      0.00774      0.00732     0.000421       0.0489       0.0662       0.0376       0.0716       0.0546       0.0486       0.0917       0.0702         1.45       0.0151\n","     98    18      0.00656      0.00653     2.59e-05       0.0476       0.0625       0.0371       0.0687       0.0529       0.0462       0.0864       0.0663        0.321      0.00334\n","     98    19      0.00663      0.00644     0.000194       0.0468       0.0621       0.0373       0.0659       0.0516       0.0482       0.0832       0.0657         0.98       0.0102\n","     98    20      0.00584      0.00577     6.93e-05       0.0436       0.0588       0.0336       0.0636       0.0486       0.0441       0.0805       0.0623        0.428      0.00446\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     98     1      0.00695       0.0069      4.5e-05        0.048       0.0643       0.0369       0.0702       0.0535       0.0474       0.0888       0.0681         0.44      0.00458\n","     98     2      0.00693      0.00691     2.45e-05       0.0477       0.0643       0.0361       0.0707       0.0534       0.0466       0.0897       0.0682        0.304      0.00317\n","     98     3      0.00661      0.00658     2.85e-05       0.0465       0.0628       0.0351       0.0691       0.0521       0.0449       0.0882       0.0666        0.307       0.0032\n","     98     4      0.00679      0.00674     5.39e-05       0.0468       0.0635       0.0356       0.0694       0.0525       0.0453       0.0895       0.0674        0.465      0.00484\n","     98     5      0.00629      0.00624     4.69e-05       0.0458       0.0611       0.0354       0.0664       0.0509       0.0456        0.084       0.0648        0.418      0.00435\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              98  309.298    0.005      0.00639     0.000172      0.00656       0.0463       0.0619       0.0358       0.0673       0.0515       0.0457       0.0855       0.0656        0.805      0.00838\n","! Validation         98  309.298    0.005      0.00667     3.98e-05      0.00671       0.0469       0.0632       0.0358       0.0691       0.0525        0.046       0.0881        0.067        0.387      0.00403\n","Wall time: 309.29834137000034\n","! Best model       98    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     99     1      0.00649      0.00639     0.000101       0.0463       0.0619       0.0359       0.0671       0.0515       0.0457       0.0855       0.0656        0.688      0.00717\n","     99     2      0.00616      0.00603     0.000131       0.0447       0.0601       0.0356       0.0627       0.0492       0.0461       0.0811       0.0636        0.779      0.00811\n","     99     3      0.00649      0.00646     2.86e-05       0.0462       0.0622       0.0343       0.0701       0.0522       0.0445       0.0874        0.066        0.298      0.00311\n","     99     4      0.00864      0.00859     5.38e-05       0.0548       0.0717       0.0453       0.0737       0.0595       0.0572       0.0943       0.0757        0.507      0.00528\n","     99     5      0.00906        0.009     6.11e-05       0.0562       0.0734       0.0457       0.0773       0.0615       0.0573        0.098       0.0776        0.484      0.00504\n","     99     6      0.00818      0.00811     6.95e-05       0.0545       0.0697        0.044       0.0756       0.0598       0.0537       0.0938       0.0738         0.55      0.00573\n","     99     7      0.00781      0.00727     0.000542       0.0506        0.066       0.0408       0.0701       0.0555       0.0524        0.087       0.0697         1.67       0.0174\n","     99     8      0.00588      0.00583      5.4e-05       0.0432        0.059       0.0333       0.0631       0.0482       0.0425       0.0828       0.0626        0.437      0.00455\n","     99     9      0.00693      0.00677      0.00016       0.0476       0.0637       0.0361       0.0704       0.0533       0.0461       0.0889       0.0675        0.844      0.00879\n","     99    10      0.00701      0.00689     0.000117       0.0481       0.0642       0.0388       0.0666       0.0527       0.0501       0.0858       0.0679        0.679      0.00707\n","     99    11      0.00683       0.0068     3.71e-05       0.0485       0.0638       0.0407       0.0641       0.0524        0.052       0.0824       0.0672        0.292      0.00304\n","     99    12      0.00564      0.00554     9.72e-05       0.0429       0.0576       0.0332       0.0625       0.0478        0.042       0.0801       0.0611         0.57      0.00594\n","     99    13      0.00603      0.00586     0.000162       0.0443       0.0592       0.0329       0.0671         0.05       0.0418       0.0839       0.0628         0.91      0.00948\n","     99    14      0.00713      0.00711     1.97e-05       0.0474       0.0652       0.0361         0.07        0.053       0.0476       0.0908       0.0692        0.289      0.00301\n","     99    15      0.00669      0.00649     0.000194       0.0466       0.0623       0.0359        0.068        0.052       0.0453       0.0869       0.0661        0.964         0.01\n","     99    16      0.00628      0.00626     1.99e-05       0.0453       0.0612       0.0328       0.0703       0.0515       0.0419       0.0879       0.0649        0.245      0.00255\n","     99    17      0.00723      0.00716     7.59e-05       0.0506       0.0654       0.0418       0.0681       0.0549        0.052       0.0862       0.0691        0.515      0.00536\n","     99    18       0.0082      0.00798     0.000219       0.0542       0.0691       0.0464         0.07       0.0582        0.058       0.0872       0.0726         1.05        0.011\n","     99    19      0.00796      0.00792     3.87e-05       0.0518       0.0688       0.0412       0.0732       0.0572       0.0532       0.0925       0.0729        0.348      0.00363\n","     99    20       0.0062      0.00597     0.000229       0.0442       0.0598       0.0332       0.0661       0.0497       0.0426       0.0842       0.0634         1.06        0.011\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","     99     1      0.00692      0.00688     4.47e-05       0.0479       0.0641       0.0368       0.0701       0.0534       0.0473       0.0887        0.068        0.434      0.00452\n","     99     2      0.00691      0.00688     2.46e-05       0.0476       0.0642        0.036       0.0706       0.0533       0.0465       0.0897       0.0681        0.307      0.00319\n","     99     3      0.00659      0.00657      2.9e-05       0.0464       0.0627        0.035       0.0691       0.0521       0.0448       0.0882       0.0665        0.311      0.00324\n","     99     4      0.00677      0.00672     5.43e-05       0.0467       0.0634       0.0355       0.0693       0.0524       0.0451       0.0894       0.0673        0.467      0.00487\n","     99     5      0.00626      0.00621     4.75e-05       0.0456        0.061       0.0353       0.0663       0.0508       0.0454       0.0838       0.0646         0.42      0.00438\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train              99  312.424    0.005      0.00692     0.000121      0.00704       0.0484       0.0644       0.0382       0.0688       0.0535       0.0489       0.0874       0.0682        0.659      0.00687\n","! Validation         99  312.424    0.005      0.00665        4e-05      0.00669       0.0468       0.0631       0.0357       0.0691       0.0524       0.0458        0.088       0.0669        0.388      0.00404\n","Wall time: 312.4248555210006\n","! Best model       99    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","    100     1      0.00622      0.00595     0.000271        0.045       0.0597       0.0352       0.0647         0.05       0.0437       0.0828       0.0633         1.15        0.012\n","    100     2      0.00635      0.00621     0.000136       0.0463        0.061       0.0364       0.0662       0.0513       0.0465       0.0827       0.0646        0.811      0.00845\n","    100     3      0.00685      0.00614     0.000714        0.045       0.0606       0.0343       0.0664       0.0504       0.0446       0.0839       0.0643         1.97       0.0205\n","    100     4      0.00526      0.00522     4.45e-05       0.0421       0.0559       0.0328       0.0607       0.0468       0.0414        0.077       0.0592        0.455      0.00474\n","    100     5      0.00644      0.00605      0.00039       0.0446       0.0602       0.0337       0.0665       0.0501       0.0422       0.0855       0.0638         1.43       0.0149\n","    100     6      0.00663      0.00652      0.00011        0.045       0.0625       0.0339       0.0672       0.0505       0.0438       0.0887       0.0662        0.692       0.0072\n","    100     7      0.00656       0.0065     5.54e-05       0.0468       0.0624       0.0373       0.0659       0.0516       0.0479       0.0842        0.066        0.433      0.00451\n","    100     8      0.00684      0.00636     0.000479       0.0468       0.0617       0.0381       0.0642       0.0512       0.0488       0.0815       0.0652          1.6       0.0167\n","    100     9      0.00622      0.00618     3.95e-05       0.0461       0.0608       0.0365       0.0654       0.0509       0.0457       0.0832       0.0644        0.457      0.00476\n","    100    10      0.00616       0.0059     0.000264       0.0448       0.0594       0.0343       0.0659       0.0501       0.0438       0.0822        0.063         1.13       0.0118\n","    100    11      0.00745      0.00733     0.000114       0.0504       0.0663       0.0416        0.068       0.0548       0.0523       0.0878         0.07        0.786      0.00819\n","    100    12      0.00679      0.00668      0.00011       0.0474       0.0632       0.0367       0.0688       0.0527        0.046       0.0881        0.067        0.686      0.00715\n","    100    13      0.00723      0.00698      0.00025       0.0479       0.0646       0.0362       0.0713       0.0538       0.0464       0.0906       0.0685         1.08       0.0113\n","    100    14      0.00614      0.00608     5.34e-05        0.045       0.0603       0.0338       0.0673       0.0505        0.043        0.085        0.064        0.414      0.00431\n","    100    15       0.0063      0.00588     0.000417       0.0451       0.0593       0.0357        0.064       0.0499       0.0456         0.08       0.0628         1.37       0.0143\n","    100    16       0.0073      0.00722     7.15e-05       0.0496       0.0658         0.04        0.069       0.0545       0.0517       0.0873       0.0695        0.529      0.00551\n","    100    17      0.00648      0.00639     9.12e-05        0.048       0.0618       0.0381       0.0679        0.053       0.0476       0.0833       0.0655        0.635      0.00662\n","    100    18      0.00639      0.00632     6.23e-05       0.0456       0.0615       0.0334       0.0699       0.0516       0.0431       0.0874       0.0653        0.466      0.00486\n","    100    19      0.00617      0.00615     2.47e-05       0.0451       0.0607        0.036       0.0633       0.0496       0.0462       0.0823       0.0642        0.256      0.00267\n","    100    20       0.0068      0.00663     0.000169       0.0467        0.063       0.0345       0.0712       0.0529       0.0446       0.0891       0.0668        0.913      0.00951\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","    100     1      0.00689      0.00685      4.5e-05       0.0478        0.064       0.0367         0.07       0.0533       0.0472       0.0886       0.0679        0.438      0.00456\n","    100     2      0.00688      0.00686     2.45e-05       0.0475       0.0641       0.0359       0.0706       0.0532       0.0464       0.0895       0.0679        0.306      0.00318\n","    100     3      0.00657      0.00655     2.87e-05       0.0463       0.0626       0.0349        0.069        0.052       0.0447       0.0881       0.0664        0.308      0.00321\n","    100     4      0.00675      0.00669     5.41e-05       0.0466       0.0633       0.0354       0.0692       0.0523        0.045       0.0892       0.0671        0.466      0.00485\n","    100     5      0.00624      0.00619     4.71e-05       0.0456       0.0609       0.0352       0.0662       0.0507       0.0453       0.0838       0.0645        0.419      0.00436\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train             100  315.538    0.005      0.00633     0.000193      0.00653       0.0462       0.0616       0.0359       0.0667       0.0513       0.0458       0.0847       0.0653        0.864        0.009\n","! Validation        100  315.538    0.005      0.00663     3.99e-05      0.00667       0.0468        0.063       0.0356        0.069       0.0523       0.0457       0.0879       0.0668        0.387      0.00404\n","Wall time: 315.539150652\n","! Best model      100    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","    101     1      0.00614      0.00611     2.59e-05       0.0455       0.0605       0.0347       0.0671       0.0509       0.0435       0.0848       0.0641        0.352      0.00366\n","    101     2      0.00647       0.0064     7.11e-05       0.0459       0.0619       0.0336       0.0704        0.052       0.0429       0.0884       0.0657        0.567      0.00591\n","    101     3      0.00551      0.00539     0.000118       0.0432       0.0568       0.0328       0.0641       0.0485       0.0412       0.0792       0.0602        0.714      0.00743\n","    101     4      0.00654      0.00649     4.16e-05       0.0476       0.0623       0.0367       0.0695       0.0531       0.0462        0.086       0.0661        0.473      0.00493\n","    101     5      0.00797      0.00776     0.000208       0.0525       0.0681       0.0453        0.067       0.0561       0.0571       0.0861       0.0716        0.972       0.0101\n","    101     6      0.00801      0.00797     3.97e-05       0.0531       0.0691       0.0446         0.07       0.0573       0.0562       0.0895       0.0728        0.326       0.0034\n","    101     7      0.00653      0.00649     4.02e-05       0.0471       0.0623       0.0362       0.0688       0.0525       0.0454       0.0867       0.0661        0.463      0.00483\n","    101     8      0.00641      0.00634     6.44e-05       0.0457       0.0616        0.036       0.0652       0.0506        0.046       0.0846       0.0653        0.548       0.0057\n","    101     9      0.00788      0.00782      6.1e-05       0.0529       0.0684       0.0426       0.0734        0.058       0.0534       0.0913       0.0724        0.453      0.00472\n","    101    10      0.00776      0.00771     4.24e-05       0.0518       0.0679       0.0436        0.068       0.0558       0.0561        0.087       0.0715         0.41      0.00427\n","    101    11      0.00561      0.00552     9.02e-05       0.0435       0.0575       0.0333       0.0637       0.0485       0.0423       0.0796       0.0609        0.498      0.00519\n","    101    12       0.0064      0.00636     4.18e-05       0.0461       0.0617        0.035       0.0682       0.0516       0.0441       0.0867       0.0654        0.409      0.00426\n","    101    13      0.00635      0.00633      1.3e-05       0.0468       0.0616       0.0377       0.0651       0.0514       0.0483       0.0819       0.0651        0.228      0.00237\n","    101    14      0.00779      0.00775     4.17e-05       0.0508       0.0681       0.0391       0.0743       0.0567       0.0507       0.0937       0.0722         0.38      0.00396\n","    101    15      0.00585       0.0058     5.62e-05       0.0447       0.0589       0.0336        0.067       0.0503       0.0419       0.0831       0.0625        0.541      0.00564\n","    101    16      0.00591      0.00589     2.08e-05       0.0442       0.0594       0.0338       0.0651       0.0494       0.0439        0.082        0.063        0.276      0.00288\n","    101    17      0.00595      0.00592     3.57e-05       0.0433       0.0595       0.0315       0.0669       0.0492       0.0407       0.0855       0.0631         0.36      0.00375\n","    101    18      0.00693      0.00687     5.74e-05       0.0481       0.0641       0.0368       0.0707       0.0538        0.047        0.089        0.068        0.536      0.00558\n","    101    19      0.00636      0.00631     5.21e-05       0.0459       0.0615       0.0372       0.0633       0.0503       0.0474       0.0827        0.065        0.437      0.00455\n","    101    20      0.00702      0.00699     2.94e-05       0.0483       0.0647       0.0378       0.0693       0.0535        0.048       0.0891       0.0686        0.375      0.00391\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","    101     1      0.00687      0.00683      4.5e-05       0.0477       0.0639       0.0366       0.0699       0.0533       0.0471       0.0885       0.0678        0.438      0.00456\n","    101     2      0.00686      0.00684     2.45e-05       0.0474        0.064       0.0359       0.0705       0.0532       0.0462       0.0894       0.0678        0.306      0.00318\n","    101     3      0.00655      0.00652     2.87e-05       0.0462       0.0625       0.0348        0.069       0.0519       0.0445        0.088       0.0663        0.308      0.00321\n","    101     4      0.00672      0.00667     5.41e-05       0.0465       0.0632       0.0352       0.0691       0.0522       0.0449       0.0892        0.067        0.466      0.00485\n","    101     5      0.00622      0.00617     4.72e-05       0.0455       0.0608       0.0351       0.0662       0.0507       0.0452       0.0837       0.0644        0.419      0.00437\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train             101  318.664    0.005      0.00661     5.75e-05      0.00667       0.0473       0.0629       0.0371       0.0679       0.0525       0.0474       0.0859       0.0666        0.466      0.00485\n","! Validation        101  318.664    0.005      0.00661     3.99e-05      0.00665       0.0467       0.0629       0.0355       0.0689       0.0522       0.0456       0.0878       0.0667        0.387      0.00404\n","Wall time: 318.66497212300055\n","! Best model      101    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","    102     1      0.00638      0.00633     4.92e-05        0.047       0.0615       0.0368       0.0673        0.052       0.0466       0.0838       0.0652        0.376      0.00392\n","    102     2      0.00822      0.00817     5.23e-05       0.0539       0.0699       0.0459       0.0701        0.058       0.0585       0.0884       0.0735        0.489       0.0051\n","    102     3      0.00847      0.00843     3.66e-05       0.0545        0.071       0.0449       0.0739       0.0594       0.0564       0.0938       0.0751        0.391      0.00407\n","    102     4       0.0077      0.00766      4.6e-05       0.0512       0.0677       0.0399       0.0736       0.0568       0.0511       0.0924       0.0717        0.469      0.00488\n","    102     5      0.00661      0.00652     9.82e-05        0.047       0.0624       0.0365        0.068       0.0522       0.0464        0.086       0.0662        0.614       0.0064\n","    102     6      0.00547      0.00542     4.81e-05       0.0425       0.0569        0.033       0.0615       0.0472       0.0417        0.079       0.0604        0.427      0.00445\n","    102     7      0.00638      0.00628     0.000104       0.0458       0.0613       0.0339       0.0696       0.0518       0.0432       0.0869        0.065        0.595       0.0062\n","    102     8      0.00611      0.00605     6.35e-05       0.0454       0.0602       0.0358       0.0645       0.0501       0.0451       0.0824       0.0638        0.546      0.00569\n","    102     9      0.00749      0.00744     5.25e-05       0.0504       0.0667       0.0399       0.0715       0.0557       0.0509       0.0904       0.0706        0.483      0.00503\n","    102    10      0.00706      0.00684     0.000219       0.0474        0.064       0.0345       0.0732       0.0539       0.0444       0.0913       0.0679         1.05        0.011\n","    102    11      0.00647      0.00646     1.23e-05       0.0466       0.0622       0.0361       0.0678       0.0519       0.0471       0.0847       0.0659        0.184      0.00191\n","    102    12      0.00592      0.00588     3.94e-05       0.0447       0.0593       0.0356        0.063       0.0493       0.0447        0.081       0.0629        0.436      0.00454\n","    102    13      0.00574      0.00563     0.000106       0.0442        0.058       0.0352       0.0621       0.0486       0.0445       0.0785       0.0615        0.697      0.00726\n","    102    14      0.00646      0.00641      5.2e-05       0.0468       0.0619       0.0356       0.0693       0.0525       0.0456       0.0857       0.0656        0.445      0.00463\n","    102    15      0.00646      0.00629     0.000169       0.0464       0.0614       0.0365       0.0663       0.0514       0.0455       0.0846        0.065        0.825       0.0086\n","    102    16      0.00679      0.00677      1.8e-05       0.0475       0.0637       0.0359       0.0705       0.0532       0.0455       0.0896       0.0675        0.273      0.00285\n","    102    17      0.00597      0.00593     3.17e-05       0.0449       0.0596       0.0361       0.0626       0.0493       0.0456       0.0806       0.0631        0.326       0.0034\n","    102    18       0.0061      0.00606     4.17e-05       0.0445       0.0602       0.0341       0.0652       0.0497       0.0434       0.0844       0.0639        0.454      0.00473\n","    102    19      0.00702      0.00701     1.42e-05       0.0484       0.0648       0.0367       0.0719       0.0543       0.0465       0.0909       0.0687        0.236      0.00246\n","    102    20      0.00824      0.00818     6.02e-05       0.0539         0.07       0.0456       0.0703        0.058       0.0585       0.0885       0.0735        0.501      0.00522\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","    102     1      0.00685       0.0068     4.51e-05       0.0476       0.0638       0.0365       0.0698       0.0531       0.0469       0.0884       0.0676        0.439      0.00457\n","    102     2      0.00683      0.00681     2.45e-05       0.0473       0.0638       0.0358       0.0704       0.0531       0.0461       0.0893       0.0677        0.306      0.00319\n","    102     3      0.00653       0.0065     2.87e-05       0.0461       0.0624       0.0348       0.0689       0.0518       0.0444       0.0879       0.0662        0.308      0.00321\n","    102     4       0.0067      0.00665     5.41e-05       0.0465       0.0631       0.0352       0.0691       0.0521       0.0448        0.089       0.0669        0.466      0.00485\n","    102     5       0.0062      0.00615     4.72e-05       0.0454       0.0607        0.035       0.0661       0.0506        0.045       0.0836       0.0643         0.42      0.00437\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train             102  321.792    0.005      0.00669     6.57e-05      0.00675       0.0477       0.0633       0.0374       0.0681       0.0528       0.0478       0.0862        0.067        0.491      0.00512\n","! Validation        102  321.792    0.005      0.00658     3.99e-05      0.00662       0.0466       0.0628       0.0354       0.0688       0.0521       0.0455       0.0877       0.0666        0.388      0.00404\n","Wall time: 321.79304370000045\n","! Best model      102    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","    103     1      0.00718      0.00717     1.07e-05       0.0505       0.0655       0.0414       0.0687        0.055       0.0518       0.0867       0.0692        0.219      0.00228\n","    103     2      0.00653       0.0065     3.39e-05       0.0466       0.0624       0.0345       0.0708       0.0526       0.0438       0.0885       0.0662        0.382      0.00398\n","    103     3      0.00728      0.00702     0.000263       0.0482       0.0648       0.0367       0.0713        0.054       0.0468       0.0906       0.0687         1.15       0.0119\n","    103     4      0.00666      0.00661     5.35e-05       0.0476       0.0629       0.0379        0.067       0.0524        0.048       0.0852       0.0666        0.527      0.00549\n","    103     5      0.00587      0.00542     0.000453       0.0441        0.057       0.0362       0.0597        0.048       0.0454       0.0749       0.0601         1.55       0.0161\n","    103     6      0.00614      0.00613     8.73e-06       0.0451       0.0606       0.0341       0.0673       0.0507       0.0433       0.0852       0.0642        0.199      0.00208\n","    103     7      0.00773      0.00749     0.000239       0.0507        0.067       0.0384       0.0752       0.0568       0.0484       0.0937        0.071         1.13       0.0118\n","    103     8      0.00721      0.00715        6e-05       0.0495       0.0654       0.0391       0.0703       0.0547       0.0497       0.0889       0.0693        0.515      0.00536\n","    103     9      0.00761      0.00741     0.000203       0.0521       0.0666       0.0464       0.0635       0.0549       0.0575       0.0818       0.0696        0.971       0.0101\n","    103    10      0.00665      0.00653     0.000121       0.0462       0.0625       0.0361       0.0663       0.0512        0.047       0.0855       0.0662         0.81      0.00844\n","    103    11       0.0071      0.00702     8.19e-05       0.0495       0.0648        0.038       0.0724       0.0552       0.0474       0.0901       0.0687         0.45      0.00469\n","    103    12      0.00582       0.0057     0.000118       0.0439       0.0584       0.0343       0.0632       0.0487       0.0442       0.0795       0.0619        0.749       0.0078\n","    103    13      0.00777      0.00773     3.51e-05       0.0507        0.068       0.0375        0.077       0.0572        0.047       0.0973       0.0721        0.412      0.00429\n","    103    14      0.00639      0.00636     3.23e-05       0.0454       0.0617       0.0352       0.0657       0.0504       0.0455       0.0853       0.0654         0.39      0.00407\n","    103    15       0.0066      0.00656     4.24e-05       0.0483       0.0626       0.0392       0.0665       0.0529       0.0484       0.0842       0.0663        0.371      0.00386\n","    103    16      0.00661      0.00658     3.21e-05       0.0474       0.0627       0.0367       0.0689       0.0528       0.0458       0.0873       0.0665        0.357      0.00372\n","    103    17      0.00821      0.00813     7.58e-05       0.0556       0.0698       0.0498       0.0672       0.0585       0.0611       0.0845       0.0728        0.601      0.00626\n","    103    18      0.00843      0.00837      5.6e-05       0.0554       0.0708       0.0483       0.0696        0.059       0.0602       0.0883       0.0742        0.423       0.0044\n","    103    19      0.00972      0.00965     7.19e-05       0.0575        0.076       0.0439       0.0847       0.0643       0.0556        0.106       0.0806        0.566      0.00589\n","    103    20      0.00764      0.00757     6.81e-05       0.0513       0.0673       0.0403       0.0733       0.0568       0.0498       0.0929       0.0714        0.521      0.00543\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","    103     1      0.00682      0.00678     4.51e-05       0.0475       0.0637       0.0364       0.0697       0.0531       0.0468       0.0882       0.0675        0.439      0.00457\n","    103     2      0.00681      0.00678     2.45e-05       0.0472       0.0637       0.0357       0.0703        0.053        0.046       0.0892       0.0676        0.306      0.00319\n","    103     3      0.00651      0.00648     2.88e-05        0.046       0.0623       0.0347       0.0688       0.0517       0.0443       0.0878       0.0661        0.309      0.00322\n","    103     4      0.00668      0.00663     5.41e-05       0.0464        0.063       0.0351        0.069        0.052       0.0446        0.089       0.0668        0.466      0.00485\n","    103     5      0.00618      0.00613     4.73e-05       0.0453       0.0606       0.0349        0.066       0.0505       0.0449       0.0835       0.0642         0.42      0.00438\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train             103  324.903    0.005      0.00705     0.000103      0.00716       0.0493        0.065       0.0392       0.0694       0.0543       0.0496        0.088       0.0688        0.615       0.0064\n","! Validation        103  324.903    0.005      0.00656        4e-05       0.0066       0.0465       0.0627       0.0354       0.0688       0.0521       0.0453       0.0876       0.0665        0.388      0.00404\n","Wall time: 324.9040664710001\n","! Best model      103    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","    104     1      0.00573      0.00563     9.79e-05       0.0445       0.0581       0.0348       0.0639       0.0494       0.0441        0.079       0.0615        0.614      0.00639\n","    104     2      0.00691      0.00666     0.000255       0.0464       0.0631       0.0341       0.0708       0.0525       0.0438         0.09       0.0669         1.14       0.0119\n","    104     3      0.00782      0.00776     5.89e-05        0.054       0.0681       0.0486        0.065       0.0568       0.0605       0.0812       0.0709        0.503      0.00524\n","    104     4      0.00984      0.00983     1.07e-05       0.0597       0.0767       0.0521       0.0748       0.0635       0.0658       0.0949       0.0803        0.224      0.00233\n","    104     5      0.00949      0.00908      0.00041       0.0563       0.0737       0.0462       0.0767       0.0614       0.0577       0.0982        0.078         1.39       0.0145\n","    104     6      0.00625       0.0062     5.41e-05       0.0455       0.0609       0.0353       0.0659       0.0506       0.0447       0.0844       0.0646        0.475      0.00495\n","    104     7      0.00583      0.00573     0.000102       0.0441       0.0585        0.035       0.0622       0.0486       0.0439       0.0802        0.062        0.645      0.00672\n","    104     8        0.007      0.00679     0.000214        0.048       0.0637       0.0386       0.0668       0.0527       0.0484       0.0866       0.0675        0.981       0.0102\n","    104     9      0.00816      0.00812     3.82e-05       0.0542       0.0697        0.047       0.0686       0.0578        0.059       0.0872       0.0731        0.304      0.00316\n","    104    10       0.0067      0.00637     0.000326       0.0477       0.0618       0.0387       0.0658       0.0522       0.0482       0.0825       0.0653         1.28       0.0133\n","    104    11       0.0068      0.00668     0.000114       0.0481       0.0633       0.0377       0.0687       0.0532       0.0487       0.0852        0.067        0.753      0.00785\n","    104    12      0.00753      0.00733     0.000205       0.0511       0.0662       0.0435       0.0663       0.0549        0.055       0.0843       0.0697        0.953      0.00993\n","    104    13      0.00868       0.0085     0.000181       0.0538       0.0713       0.0424       0.0767       0.0595       0.0534       0.0977       0.0756        0.892      0.00929\n","    104    14      0.00717      0.00714     2.53e-05       0.0487       0.0654       0.0369       0.0723       0.0546        0.047       0.0917       0.0693        0.351      0.00366\n","    104    15      0.00644      0.00629     0.000154       0.0458       0.0613       0.0367        0.064       0.0504        0.047       0.0829       0.0649        0.901      0.00939\n","    104    16      0.00623      0.00592     0.000318        0.045       0.0595       0.0359       0.0631       0.0495       0.0457       0.0803        0.063          1.3       0.0136\n","    104    17      0.00877      0.00861     0.000158       0.0566       0.0718       0.0494       0.0709       0.0601       0.0616       0.0888       0.0752        0.893       0.0093\n","    104    18      0.00788      0.00765     0.000228       0.0532       0.0677       0.0455       0.0684        0.057       0.0563        0.086       0.0712         1.07       0.0112\n","    104    19      0.00713       0.0071     2.76e-05       0.0478       0.0652       0.0348       0.0739       0.0543       0.0443       0.0939       0.0691        0.344      0.00359\n","    104    20      0.00802      0.00782     0.000196       0.0529       0.0684       0.0457       0.0671       0.0564       0.0573       0.0865       0.0719        0.916      0.00955\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","    104     1       0.0068      0.00676     4.49e-05       0.0474       0.0636       0.0363       0.0696        0.053       0.0467       0.0882       0.0674        0.435      0.00453\n","    104     2      0.00679      0.00677     2.45e-05       0.0472       0.0636       0.0356       0.0703       0.0529       0.0459       0.0891       0.0675        0.307       0.0032\n","    104     3      0.00649      0.00646      2.9e-05        0.046       0.0622       0.0346       0.0687       0.0517       0.0442       0.0877        0.066        0.311      0.00324\n","    104     4      0.00666      0.00661     5.42e-05       0.0463       0.0629        0.035        0.069        0.052       0.0445       0.0889       0.0667        0.467      0.00486\n","    104     5      0.00616      0.00611     4.77e-05       0.0452       0.0605       0.0348        0.066       0.0504       0.0448       0.0835       0.0641        0.421      0.00439\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train             104  328.015    0.005      0.00726     0.000159      0.00742       0.0502       0.0659       0.0409       0.0686       0.0548       0.0521       0.0873       0.0697        0.797       0.0083\n","! Validation        104  328.015    0.005      0.00654     4.01e-05      0.00658       0.0464       0.0626       0.0353       0.0687        0.052       0.0452       0.0875       0.0664        0.388      0.00404\n","Wall time: 328.0162482120004\n","! Best model      104    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","    105     1      0.00772      0.00759     0.000124       0.0514       0.0674       0.0423       0.0697        0.056       0.0537       0.0887       0.0712        0.704      0.00733\n","    105     2      0.00722      0.00709     0.000127       0.0479       0.0652       0.0344       0.0751       0.0547       0.0443       0.0938       0.0691        0.752      0.00783\n","    105     3      0.00706      0.00663     0.000435       0.0469        0.063        0.036       0.0687       0.0524       0.0465       0.0871       0.0668         1.46       0.0153\n","    105     4      0.00641       0.0064     1.26e-05       0.0475       0.0619       0.0384       0.0656        0.052       0.0476       0.0833       0.0655        0.214      0.00223\n","    105     5      0.00696      0.00631     0.000652       0.0468       0.0615       0.0377       0.0651       0.0514       0.0482       0.0818        0.065         1.86       0.0193\n","    105     6      0.00614       0.0061     3.98e-05        0.045       0.0604       0.0348       0.0655       0.0501       0.0438       0.0843       0.0641         0.27      0.00281\n","    105     7      0.00632      0.00618     0.000142       0.0458       0.0608       0.0353       0.0669       0.0511       0.0445       0.0845       0.0645        0.743      0.00774\n","    105     8      0.00787      0.00715     0.000722       0.0503       0.0654       0.0424       0.0662       0.0543       0.0533       0.0846       0.0689         1.98       0.0206\n","    105     9      0.00618      0.00602     0.000156       0.0441         0.06       0.0318       0.0686       0.0502       0.0409       0.0864       0.0636        0.868      0.00904\n","    105    10       0.0071      0.00679      0.00031       0.0501       0.0638       0.0423       0.0657        0.054        0.053       0.0812       0.0671         1.28       0.0133\n","    105    11       0.0082      0.00814     5.72e-05       0.0532       0.0698       0.0423       0.0749       0.0586       0.0537        0.094       0.0739         0.53      0.00552\n","    105    12      0.00861      0.00852        9e-05       0.0544       0.0714       0.0429       0.0774       0.0601       0.0532       0.0982       0.0757        0.598      0.00623\n","    105    13      0.00645      0.00641     4.27e-05       0.0462       0.0619        0.037       0.0645       0.0507       0.0471        0.084       0.0656        0.388      0.00404\n","    105    14      0.00703      0.00699     3.74e-05       0.0482       0.0647       0.0359       0.0728       0.0543       0.0453       0.0919       0.0686        0.405      0.00422\n","    105    15      0.00821       0.0082     1.22e-05       0.0537         0.07       0.0464       0.0683       0.0574       0.0597       0.0871       0.0734        0.194      0.00202\n","    105    16      0.00819      0.00818     9.36e-06       0.0551         0.07       0.0502       0.0649       0.0576       0.0622       0.0834       0.0728         0.18      0.00187\n","    105    17      0.00792      0.00788     3.79e-05       0.0511       0.0687       0.0388       0.0759       0.0573        0.049       0.0967       0.0728        0.404      0.00421\n","    105    18      0.00706      0.00699     7.07e-05       0.0492       0.0647       0.0398       0.0681       0.0539       0.0494       0.0875       0.0685        0.578      0.00602\n","    105    19      0.00627      0.00622     5.16e-05        0.045        0.061        0.034        0.067       0.0505       0.0437       0.0857       0.0647        0.459      0.00478\n","    105    20      0.00802        0.008     1.75e-05       0.0523       0.0692         0.04       0.0769       0.0585       0.0506       0.0961       0.0734        0.229      0.00239\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","    105     1      0.00679      0.00674     4.54e-05       0.0474       0.0635       0.0363       0.0696       0.0529       0.0466       0.0881       0.0674        0.442       0.0046\n","    105     2      0.00678      0.00675     2.44e-05       0.0471       0.0636       0.0355       0.0703       0.0529       0.0458        0.089       0.0674        0.305      0.00318\n","    105     3      0.00648      0.00645     2.85e-05       0.0459       0.0621       0.0345       0.0687       0.0516       0.0441       0.0877       0.0659        0.306      0.00319\n","    105     4      0.00665       0.0066      5.4e-05       0.0463       0.0628       0.0349        0.069       0.0519       0.0444       0.0888       0.0666        0.465      0.00484\n","    105     5      0.00614       0.0061      4.7e-05       0.0451       0.0604       0.0347       0.0659       0.0503       0.0446       0.0834        0.064        0.419      0.00437\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train             105  331.142    0.005      0.00709     0.000157      0.00725       0.0492       0.0651       0.0391       0.0694       0.0543       0.0498       0.0882        0.069        0.705      0.00734\n","! Validation        105  331.142    0.005      0.00653     3.98e-05      0.00657       0.0464       0.0625       0.0352       0.0687       0.0519       0.0451       0.0875       0.0663        0.387      0.00404\n","Wall time: 331.1424041850005\n","! Best model      105    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","    106     1      0.00664       0.0066     4.31e-05       0.0485       0.0629       0.0404       0.0647       0.0525       0.0511       0.0814       0.0663        0.389      0.00405\n","    106     2      0.00714      0.00711     2.97e-05       0.0506       0.0652       0.0429       0.0661       0.0545       0.0539       0.0834       0.0687        0.363      0.00378\n","    106     3      0.00624      0.00618     6.42e-05       0.0458       0.0608       0.0341       0.0692       0.0516       0.0435       0.0855       0.0645        0.517      0.00538\n","    106     4      0.00676      0.00666     9.25e-05       0.0476       0.0631       0.0385       0.0657       0.0521       0.0485       0.0852       0.0669        0.557      0.00581\n","    106     5      0.00625      0.00613     0.000114       0.0446       0.0606       0.0337       0.0665       0.0501       0.0432       0.0853       0.0643        0.606      0.00632\n","    106     6      0.00695      0.00693     1.42e-05        0.048       0.0644       0.0365       0.0708       0.0537       0.0472       0.0894       0.0683         0.24       0.0025\n","    106     7      0.00715      0.00712     3.67e-05         0.05       0.0653       0.0413       0.0674       0.0544        0.052       0.0858       0.0689        0.338      0.00352\n","    106     8      0.00671      0.00656     0.000146       0.0479       0.0627       0.0393       0.0651       0.0522       0.0493       0.0832       0.0662        0.841      0.00876\n","    106     9      0.00612      0.00609      3.5e-05       0.0458       0.0604       0.0362       0.0652       0.0507       0.0448       0.0832        0.064         0.38      0.00396\n","    106    10      0.00664       0.0066     4.37e-05       0.0475       0.0628       0.0381       0.0664       0.0522       0.0479       0.0853       0.0666        0.454      0.00473\n","    106    11      0.00569      0.00557     0.000122        0.044       0.0577       0.0351       0.0617       0.0484       0.0441       0.0782       0.0611        0.753      0.00785\n","    106    12      0.00734       0.0073     3.85e-05       0.0507       0.0661       0.0415       0.0691       0.0553       0.0528       0.0867       0.0698        0.397      0.00413\n","    106    13      0.00701      0.00691     9.91e-05        0.048       0.0643       0.0387       0.0666       0.0527       0.0492        0.087       0.0681        0.668      0.00696\n","    106    14       0.0077      0.00765     5.17e-05       0.0511       0.0677       0.0397       0.0738       0.0567       0.0498       0.0937       0.0717        0.464      0.00483\n","    106    15      0.00648      0.00635     0.000131       0.0463       0.0617       0.0355       0.0677       0.0516       0.0457       0.0851       0.0654        0.743      0.00774\n","    106    16      0.00658      0.00656     1.89e-05       0.0473       0.0627       0.0372       0.0676       0.0524       0.0473       0.0855       0.0664        0.294      0.00306\n","    106    17      0.00724      0.00723     1.66e-05       0.0486       0.0658       0.0365        0.073       0.0547       0.0464       0.0932       0.0698        0.265      0.00276\n","    106    18      0.00683       0.0067     0.000127       0.0471       0.0633       0.0364       0.0685       0.0525       0.0474       0.0869       0.0671        0.763      0.00794\n","    106    19      0.00676      0.00675     1.44e-05       0.0498       0.0635       0.0429       0.0636       0.0533       0.0531       0.0804       0.0668        0.258      0.00269\n","    106    20      0.00695      0.00683     0.000123       0.0482       0.0639       0.0375       0.0696       0.0535       0.0475        0.088       0.0678        0.656      0.00683\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","    106     1      0.00677      0.00673     4.51e-05       0.0473       0.0635       0.0362       0.0695       0.0528       0.0465        0.088       0.0673        0.437      0.00456\n","    106     2      0.00676      0.00674     2.44e-05       0.0471       0.0635       0.0355       0.0702       0.0528       0.0457        0.089       0.0673        0.306      0.00319\n","    106     3      0.00647      0.00644     2.88e-05       0.0459       0.0621       0.0345       0.0687       0.0516        0.044       0.0876       0.0658        0.309      0.00322\n","    106     4      0.00664      0.00658     5.41e-05       0.0462       0.0628       0.0349       0.0689       0.0519       0.0444       0.0888       0.0666        0.466      0.00485\n","    106     5      0.00613      0.00608     4.74e-05       0.0451       0.0603       0.0346       0.0659       0.0503       0.0445       0.0834        0.064         0.42      0.00438\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train             106  334.249    0.005      0.00669     6.81e-05      0.00676       0.0479       0.0633       0.0381       0.0674       0.0528       0.0483       0.0857        0.067        0.497      0.00518\n","! Validation        106  334.249    0.005      0.00651        4e-05      0.00655       0.0463       0.0624       0.0351       0.0686       0.0519       0.0451       0.0874       0.0662        0.388      0.00404\n","Wall time: 334.249512071\n","! Best model      106    0.007\n","\n","training\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","    107     1      0.00631      0.00629     2.24e-05       0.0468       0.0614       0.0378        0.065       0.0514       0.0475       0.0824       0.0649        0.308      0.00321\n","    107     2      0.00604        0.006     4.32e-05       0.0459       0.0599       0.0369       0.0639       0.0504       0.0467       0.0801       0.0634        0.395      0.00411\n","    107     3      0.00754      0.00726     0.000277       0.0488       0.0659       0.0371       0.0722       0.0546       0.0479       0.0919       0.0699         1.16       0.0121\n","    107     4      0.00644      0.00638     5.98e-05       0.0458       0.0618        0.035       0.0673       0.0512       0.0445       0.0866       0.0655        0.458      0.00477\n","    107     5       0.0063      0.00621     9.11e-05       0.0446       0.0609       0.0341       0.0656       0.0499       0.0445       0.0847       0.0646        0.629      0.00655\n","    107     6      0.00632       0.0062     0.000125       0.0456       0.0609        0.035       0.0668       0.0509       0.0443       0.0849       0.0646        0.689      0.00718\n","    107     7      0.00644      0.00633     0.000111       0.0467       0.0615       0.0362       0.0678        0.052       0.0457       0.0847       0.0652        0.671      0.00699\n","    107     8      0.00744      0.00712     0.000322       0.0492       0.0653       0.0392       0.0693       0.0543       0.0503       0.0879       0.0691         1.29       0.0134\n","    107     9      0.00611      0.00603     7.61e-05       0.0447       0.0601       0.0331       0.0678       0.0505       0.0428       0.0846       0.0637        0.577      0.00601\n","    107    10      0.00601      0.00593     8.22e-05       0.0446       0.0596        0.033        0.068       0.0505       0.0419       0.0845       0.0632         0.64      0.00667\n","    107    11      0.00624       0.0062     4.57e-05        0.046       0.0609       0.0349       0.0682       0.0516       0.0444       0.0848       0.0646        0.363      0.00378\n","    107    12      0.00647      0.00645     2.24e-05       0.0462       0.0621       0.0349       0.0687       0.0518       0.0448        0.087       0.0659        0.318      0.00332\n","    107    13      0.00628      0.00625     2.91e-05       0.0457       0.0612       0.0349       0.0672        0.051       0.0437        0.086       0.0649        0.375       0.0039\n","    107    14      0.00594       0.0059     3.51e-05       0.0446       0.0594       0.0342       0.0655       0.0499       0.0438       0.0822        0.063        0.341      0.00355\n","    107    15      0.00637      0.00634     3.14e-05       0.0472       0.0616       0.0393       0.0632       0.0512       0.0494       0.0806        0.065        0.363      0.00378\n","    107    16      0.00601      0.00599     2.27e-05       0.0445       0.0599       0.0337        0.066       0.0498       0.0437       0.0832       0.0635        0.307       0.0032\n","    107    17      0.00609        0.006     9.36e-05       0.0446       0.0599       0.0353       0.0632       0.0493       0.0452       0.0818       0.0635        0.513      0.00535\n","    107    18       0.0064      0.00635     5.17e-05       0.0458       0.0617       0.0355       0.0665        0.051       0.0454       0.0853       0.0654        0.421      0.00438\n","    107    19      0.00764      0.00752      0.00012       0.0503       0.0671       0.0398       0.0714       0.0556       0.0505       0.0916       0.0711        0.759      0.00791\n","    107    20      0.00706      0.00697     8.55e-05         0.05       0.0646       0.0403       0.0694       0.0549       0.0503       0.0864       0.0683        0.617      0.00643\n","\n","validation\n","# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","    107     1      0.00675      0.00671     4.53e-05       0.0472       0.0634       0.0361       0.0694       0.0528       0.0464        0.088       0.0672         0.44      0.00458\n","    107     2      0.00674      0.00672     2.44e-05        0.047       0.0634       0.0354       0.0702       0.0528       0.0456       0.0889       0.0672        0.305      0.00318\n","    107     3      0.00645      0.00642     2.86e-05       0.0458        0.062       0.0344       0.0686       0.0515       0.0439       0.0875       0.0657        0.307       0.0032\n","    107     4      0.00662      0.00656     5.39e-05       0.0461       0.0627       0.0348       0.0688       0.0518       0.0443       0.0887       0.0665        0.465      0.00484\n","    107     5      0.00611      0.00606     4.71e-05        0.045       0.0602       0.0346       0.0658       0.0502       0.0444       0.0833       0.0639        0.419      0.00437\n","\n","\n","  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      O_f_mae  psavg_f_mae     H_f_rmse     O_f_rmse psavg_f_rmse        e_mae      e/N_mae\n","! Train             107  337.373    0.005      0.00639     8.73e-05      0.00647       0.0464       0.0618        0.036       0.0672       0.0516       0.0459       0.0851       0.0655         0.56      0.00583\n","! Validation        107  337.373    0.005      0.00649     3.99e-05      0.00653       0.0462       0.0623        0.035       0.0686       0.0518       0.0449       0.0873       0.0661        0.387      0.00403\n","Wall time: 337.3739928390005\n","! Best model      107    0.007\n","! Stop training: Early stopping: validation_loss has not reduced for 50 epochs\n","Wall time: 337.40102663700054\n","Cumulative wall time: 337.40102663700054\n"]}],"source":["!ls /content/drive/MyDrive/Colab\\ \\Notebooks/nequip/configs/my-full-example.yaml\n","!rm -rf ./results\n","!nequip-train /content/drive/MyDrive/Colab\\ \\Notebooks/nequip/configs/my-full-example.yaml"]},{"cell_type":"markdown","metadata":{"id":"5EwuQZLDO4Cr"},"source":["We see that the model has converged to an energy accuarcy < 1meV/atom and a force accuracy of approx. 40 meV/A within 5 minutes and trained on only 100 samples. That should give us a good first potential! Note that these numbers will decrease significantly if you increase the training set size and the number of epochs to train. "]},{"cell_type":"markdown","metadata":{"id":"kJitSZgLYNNF"},"source":["### Deploy the model"]},{"cell_type":"markdown","metadata":{"id":"Lo_kIpYV00as"},"source":["<img src=\"https://github.com/mir-group/nequip_mrs_tutorial/blob/master/deploy.png?raw=true\" width=\"60%\">"]},{"cell_type":"markdown","metadata":{"id":"7VoeGtlA02KQ"},"source":["We now convert the model to a potential file. This makes it independent of NequIP and we can use it any downstream application, such as LAMMPS. "]},{"cell_type":"code","source":["! ls -lrth results/water/example-run-water"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eLlagzVhrVGz","executionInfo":{"status":"ok","timestamp":1657046672127,"user_tz":-120,"elapsed":7,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"d2f49814-d52a-4edb-ad52-094349f2d785"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["total 5.3M\n","-rw------- 1 root root 227K Jul  5 18:38 config.yaml\n","-rw-r--r-- 1 root root  489 Jul  5 18:38 metrics_initialization.csv\n","-rw-r--r-- 1 root root 517K Jul  5 18:43 metrics_batch_train.csv\n","-rw-r--r-- 1 root root 131K Jul  5 18:43 metrics_batch_val.csv\n","-rw-r--r-- 1 root root  45K Jul  5 18:43 metrics_epoch.csv\n","-rw------- 1 root root 657K Jul  5 18:43 best_model.pth\n","-rw-r--r-- 1 root root 594K Jul  5 18:43 log\n","-rw------- 1 root root 2.5M Jul  5 18:43 trainer.pth\n","-rw------- 1 root root 657K Jul  5 18:43 last_model.pth\n"]}]},{"cell_type":"code","source":["! nequip-deploy -h"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PJmFAbBzez3P","executionInfo":{"status":"ok","timestamp":1657026603721,"user_tz":-120,"elapsed":2170,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"626ad133-774e-464a-bba7-46bea7dd9886"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["usage: nequip-deploy [-h] [--verbose VERBOSE] {info,build} ...\n","\n","Create and view information about deployed NequIP potentials.\n","\n","optional arguments:\n","  -h, --help         show this help message and exit\n","  --verbose VERBOSE  log level\n","\n","commands:\n","  {info,build}\n","    info             Get information from a deployed model file\n","    build            Build a deployment model\n"]}]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5985,"status":"ok","timestamp":1657047170885,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"},"user_tz":-120},"id":"Y3NJJgtDIDNc","outputId":"560759bb-c787-445b-9fa8-67d0355b2b4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:root:Loading best_model from training session...\n","INFO:root:Compiled & optimized model.\n"]}],"source":["!nequip-deploy build --train-dir /content/results/water/example-run-water water-deploy.pth"]},{"cell_type":"markdown","metadata":{"id":"UXpcE3oP0LyD"},"source":["## Evaluate Test Error on all remaining frames"]},{"cell_type":"markdown","metadata":{"id":"4wRKKCZ2PRl3"},"source":["Before running inference, we'd like to know how well the model is doing on a hold-out test set. We run the nequip-evaluate command to compute the test error on all data that we didn't use for training or validation. "]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59675,"status":"ok","timestamp":1657047238355,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"},"user_tz":-120},"id":"mB54WSrN0PaS","outputId":"41b0430a-4f18-488c-d64b-a84b2fd97a7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","WARNING: please note that models running on CUDA are usually nondeterministc and that this manifests in the final test errors; for a _more_ deterministic result, please use `--device cpu`\n","Loading model... \n","loaded model from training session\n","Loading original dataset...\n","Loaded dataset specified in config.yaml.\n","Using origial training dataset (10000 frames) minus training (100 frames) and validation frames (50 frames), yielding a test set size of 9850 frames.\n","Starting...\n","  0% 0/9850 [00:00<?, ?it/s]\n","\u001b[A\n","  1% 50/9850 [00:00<01:15, 129.57it/s]\n","  1% 100/9850 [00:01<02:07, 76.54it/s]\n","  2% 150/9850 [00:02<03:15, 49.60it/s]\n","  2% 200/9850 [00:04<03:44, 42.93it/s]\n","  3% 250/9850 [00:04<02:39, 60.11it/s]\n","  3% 300/9850 [00:04<02:00, 79.17it/s]\n","  4% 350/9850 [00:04<01:36, 98.85it/s]\n","  4% 400/9850 [00:05<01:19, 118.14it/s]\n","  5% 450/9850 [00:05<01:08, 136.32it/s]\n","  5% 500/9850 [00:05<01:01, 151.77it/s]\n","  6% 550/9850 [00:05<00:56, 164.34it/s]\n","  6% 600/9850 [00:06<00:53, 174.33it/s]\n","  7% 650/9850 [00:06<00:50, 182.06it/s]\n","  7% 700/9850 [00:06<00:48, 187.54it/s]\n","  8% 750/9850 [00:06<00:47, 192.12it/s]\n","  8% 800/9850 [00:07<00:46, 195.41it/s]\n","  9% 850/9850 [00:07<00:45, 198.47it/s]\n","  9% 900/9850 [00:07<00:44, 200.46it/s]\n"," 10% 950/9850 [00:07<00:43, 202.71it/s]\n"," 10% 1000/9850 [00:07<00:43, 203.57it/s]\n"," 11% 1050/9850 [00:08<00:43, 203.83it/s]\n"," 11% 1100/9850 [00:08<00:42, 204.56it/s]\n"," 12% 1150/9850 [00:08<00:42, 205.06it/s]\n"," 12% 1200/9850 [00:08<00:41, 206.10it/s]\n"," 13% 1250/9850 [00:09<00:41, 206.53it/s]\n"," 13% 1300/9850 [00:09<00:41, 207.76it/s]\n"," 14% 1350/9850 [00:09<00:40, 207.85it/s]\n"," 14% 1400/9850 [00:09<00:40, 207.47it/s]\n"," 15% 1450/9850 [00:10<00:40, 207.54it/s]\n"," 15% 1500/9850 [00:10<00:40, 207.73it/s]\n"," 16% 1550/9850 [00:10<00:39, 208.33it/s]\n"," 16% 1600/9850 [00:10<00:39, 208.63it/s]\n"," 17% 1650/9850 [00:11<00:39, 208.38it/s]\n"," 17% 1700/9850 [00:11<00:39, 208.58it/s]\n"," 18% 1750/9850 [00:11<00:38, 208.21it/s]\n"," 18% 1800/9850 [00:11<00:38, 207.57it/s]\n"," 19% 1850/9850 [00:12<00:38, 207.11it/s]\n"," 19% 1900/9850 [00:12<00:38, 207.13it/s]\n"," 20% 1950/9850 [00:12<00:38, 207.16it/s]\n"," 20% 2000/9850 [00:12<00:37, 207.79it/s]\n"," 21% 2050/9850 [00:13<00:37, 207.20it/s]\n"," 21% 2100/9850 [00:13<00:37, 206.96it/s]\n"," 22% 2150/9850 [00:13<00:37, 206.88it/s]\n"," 22% 2200/9850 [00:13<00:36, 207.02it/s]\n"," 23% 2250/9850 [00:14<00:36, 207.49it/s]\n"," 23% 2300/9850 [00:14<00:36, 207.19it/s]\n"," 24% 2350/9850 [00:14<00:36, 206.81it/s]\n"," 24% 2400/9850 [00:14<00:35, 207.26it/s]\n"," 25% 2450/9850 [00:14<00:35, 207.95it/s]\n"," 25% 2500/9850 [00:15<00:35, 208.21it/s]\n"," 26% 2550/9850 [00:15<00:35, 206.92it/s]\n"," 26% 2600/9850 [00:15<00:35, 206.42it/s]\n"," 27% 2650/9850 [00:15<00:34, 206.58it/s]\n"," 27% 2700/9850 [00:16<00:34, 206.88it/s]\n"," 28% 2750/9850 [00:16<00:34, 207.26it/s]\n"," 28% 2800/9850 [00:16<00:33, 207.71it/s]\n"," 29% 2850/9850 [00:16<00:33, 207.60it/s]\n"," 29% 2900/9850 [00:17<00:33, 207.18it/s]\n"," 30% 2950/9850 [00:17<00:33, 207.83it/s]\n"," 30% 3000/9850 [00:17<00:32, 208.28it/s]\n"," 31% 3050/9850 [00:17<00:32, 208.07it/s]\n"," 31% 3100/9850 [00:18<00:32, 209.25it/s]\n"," 32% 3150/9850 [00:18<00:31, 210.25it/s]\n"," 32% 3200/9850 [00:18<00:31, 209.75it/s]\n"," 33% 3250/9850 [00:18<00:31, 210.30it/s]\n"," 34% 3300/9850 [00:19<00:31, 209.94it/s]\n"," 34% 3350/9850 [00:19<00:31, 208.83it/s]\n"," 35% 3400/9850 [00:19<00:30, 209.03it/s]\n"," 35% 3450/9850 [00:19<00:30, 208.57it/s]\n"," 36% 3500/9850 [00:20<00:30, 208.74it/s]\n"," 36% 3550/9850 [00:20<00:30, 208.58it/s]\n"," 37% 3600/9850 [00:20<00:30, 208.03it/s]\n"," 37% 3650/9850 [00:20<00:29, 207.26it/s]\n"," 38% 3700/9850 [00:20<00:29, 206.62it/s]\n"," 38% 3750/9850 [00:21<00:29, 206.55it/s]\n"," 39% 3800/9850 [00:21<00:29, 206.24it/s]\n"," 39% 3850/9850 [00:21<00:29, 205.73it/s]\n"," 40% 3900/9850 [00:21<00:28, 205.52it/s]\n"," 40% 3950/9850 [00:22<00:28, 205.33it/s]\n"," 41% 4000/9850 [00:22<00:28, 205.37it/s]\n"," 41% 4050/9850 [00:22<00:28, 204.87it/s]\n"," 42% 4100/9850 [00:22<00:28, 204.90it/s]\n"," 42% 4150/9850 [00:23<00:27, 204.36it/s]\n"," 43% 4200/9850 [00:23<00:27, 204.17it/s]\n"," 43% 4250/9850 [00:23<00:27, 204.42it/s]\n"," 44% 4300/9850 [00:23<00:27, 204.01it/s]\n"," 44% 4350/9850 [00:24<00:26, 204.70it/s]\n"," 45% 4400/9850 [00:24<00:26, 203.98it/s]\n"," 45% 4450/9850 [00:24<00:26, 204.26it/s]\n"," 46% 4500/9850 [00:24<00:26, 205.06it/s]\n"," 46% 4550/9850 [00:25<00:25, 205.33it/s]\n"," 47% 4600/9850 [00:25<00:25, 205.62it/s]\n"," 47% 4650/9850 [00:25<00:25, 204.38it/s]\n"," 48% 4700/9850 [00:25<00:25, 204.61it/s]\n"," 48% 4750/9850 [00:26<00:24, 204.66it/s]\n"," 49% 4800/9850 [00:26<00:24, 204.04it/s]\n"," 49% 4850/9850 [00:26<00:24, 204.03it/s]\n"," 50% 4900/9850 [00:26<00:24, 203.96it/s]\n"," 50% 4950/9850 [00:27<00:24, 203.84it/s]\n"," 51% 5000/9850 [00:27<00:23, 203.73it/s]\n"," 51% 5050/9850 [00:27<00:23, 203.71it/s]\n"," 52% 5100/9850 [00:27<00:23, 203.40it/s]\n"," 52% 5150/9850 [00:28<00:23, 204.03it/s]\n"," 53% 5200/9850 [00:28<00:22, 204.31it/s]\n"," 53% 5250/9850 [00:28<00:22, 204.73it/s]\n"," 54% 5300/9850 [00:28<00:22, 204.67it/s]\n"," 54% 5350/9850 [00:29<00:22, 204.18it/s]\n"," 55% 5400/9850 [00:29<00:21, 203.18it/s]\n"," 55% 5450/9850 [00:29<00:21, 202.44it/s]\n"," 56% 5500/9850 [00:29<00:21, 202.64it/s]\n"," 56% 5550/9850 [00:30<00:21, 201.87it/s]\n"," 57% 5600/9850 [00:30<00:21, 202.30it/s]\n"," 57% 5650/9850 [00:30<00:20, 202.12it/s]\n"," 58% 5700/9850 [00:30<00:20, 202.13it/s]\n"," 58% 5750/9850 [00:31<00:20, 202.04it/s]\n"," 59% 5800/9850 [00:31<00:20, 202.10it/s]\n"," 59% 5850/9850 [00:31<00:19, 201.98it/s]\n"," 60% 5900/9850 [00:31<00:19, 202.92it/s]\n"," 60% 5950/9850 [00:32<00:19, 202.87it/s]\n"," 61% 6000/9850 [00:32<00:18, 202.92it/s]\n"," 61% 6050/9850 [00:32<00:18, 202.52it/s]\n"," 62% 6100/9850 [00:32<00:18, 202.44it/s]\n"," 62% 6150/9850 [00:32<00:18, 202.56it/s]\n"," 63% 6200/9850 [00:33<00:18, 202.43it/s]\n"," 63% 6250/9850 [00:33<00:17, 202.55it/s]\n"," 64% 6300/9850 [00:33<00:17, 202.81it/s]\n"," 64% 6350/9850 [00:33<00:17, 202.59it/s]\n"," 65% 6400/9850 [00:34<00:16, 203.40it/s]\n"," 65% 6450/9850 [00:34<00:16, 203.43it/s]\n"," 66% 6500/9850 [00:34<00:16, 204.07it/s]\n"," 66% 6550/9850 [00:34<00:16, 203.73it/s]\n"," 67% 6600/9850 [00:35<00:15, 203.75it/s]\n"," 68% 6650/9850 [00:35<00:15, 203.35it/s]\n"," 68% 6700/9850 [00:35<00:15, 203.12it/s]\n"," 69% 6750/9850 [00:35<00:15, 203.10it/s]\n"," 69% 6800/9850 [00:36<00:15, 203.17it/s]\n"," 70% 6850/9850 [00:36<00:14, 203.15it/s]\n"," 70% 6900/9850 [00:36<00:14, 202.58it/s]\n"," 71% 6950/9850 [00:36<00:14, 203.71it/s]\n"," 71% 7000/9850 [00:37<00:13, 203.96it/s]\n"," 72% 7050/9850 [00:37<00:13, 204.07it/s]\n"," 72% 7100/9850 [00:37<00:13, 203.61it/s]\n"," 73% 7150/9850 [00:37<00:13, 203.64it/s]\n"," 73% 7200/9850 [00:38<00:13, 203.71it/s]\n"," 74% 7250/9850 [00:38<00:12, 203.73it/s]\n"," 74% 7300/9850 [00:38<00:12, 203.94it/s]\n"," 75% 7350/9850 [00:38<00:12, 203.66it/s]\n"," 75% 7400/9850 [00:39<00:12, 203.75it/s]\n"," 76% 7450/9850 [00:39<00:11, 203.95it/s]\n"," 76% 7500/9850 [00:39<00:11, 204.32it/s]\n"," 77% 7550/9850 [00:39<00:11, 204.34it/s]\n"," 77% 7600/9850 [00:40<00:10, 204.85it/s]\n"," 78% 7650/9850 [00:40<00:10, 204.95it/s]\n"," 78% 7700/9850 [00:40<00:10, 203.38it/s]\n"," 79% 7750/9850 [00:40<00:10, 203.73it/s]\n"," 79% 7800/9850 [00:41<00:10, 203.61it/s]\n"," 80% 7850/9850 [00:41<00:09, 204.34it/s]\n"," 80% 7900/9850 [00:41<00:09, 204.16it/s]\n"," 81% 7950/9850 [00:41<00:09, 204.36it/s]\n"," 81% 8000/9850 [00:42<00:09, 203.99it/s]\n"," 82% 8050/9850 [00:42<00:08, 203.39it/s]\n"," 82% 8100/9850 [00:42<00:08, 202.93it/s]\n"," 83% 8150/9850 [00:42<00:08, 203.66it/s]\n"," 83% 8200/9850 [00:43<00:08, 204.44it/s]\n"," 84% 8250/9850 [00:43<00:07, 204.65it/s]\n"," 84% 8300/9850 [00:43<00:07, 204.83it/s]\n"," 85% 8350/9850 [00:43<00:07, 205.05it/s]\n"," 85% 8400/9850 [00:44<00:07, 205.05it/s]\n"," 86% 8450/9850 [00:44<00:06, 204.64it/s]\n"," 86% 8500/9850 [00:44<00:06, 204.14it/s]\n"," 87% 8550/9850 [00:44<00:06, 204.30it/s]\n"," 87% 8600/9850 [00:45<00:06, 204.07it/s]\n"," 88% 8650/9850 [00:45<00:05, 204.75it/s]\n"," 88% 8700/9850 [00:45<00:05, 205.15it/s]\n"," 89% 8750/9850 [00:45<00:05, 204.98it/s]\n"," 89% 8800/9850 [00:45<00:05, 204.91it/s]\n"," 90% 8850/9850 [00:46<00:04, 204.43it/s]\n"," 90% 8900/9850 [00:46<00:04, 204.53it/s]\n"," 91% 8950/9850 [00:46<00:04, 203.86it/s]\n"," 91% 9000/9850 [00:46<00:04, 203.97it/s]\n"," 92% 9050/9850 [00:47<00:03, 203.85it/s]\n"," 92% 9100/9850 [00:47<00:03, 203.70it/s]\n"," 93% 9150/9850 [00:47<00:03, 202.97it/s]\n"," 93% 9200/9850 [00:47<00:03, 203.13it/s]\n"," 94% 9250/9850 [00:48<00:02, 203.65it/s]\n"," 94% 9300/9850 [00:48<00:02, 204.16it/s]\n"," 95% 9350/9850 [00:48<00:02, 204.36it/s]\n"," 95% 9400/9850 [00:48<00:02, 204.07it/s]\n"," 96% 9450/9850 [00:49<00:01, 203.13it/s]\n"," 96% 9500/9850 [00:49<00:01, 202.45it/s]\n"," 97% 9550/9850 [00:49<00:01, 202.23it/s]\n"," 97% 9600/9850 [00:49<00:01, 202.45it/s]\n"," 98% 9650/9850 [00:50<00:00, 202.32it/s]\n"," 98% 9700/9850 [00:50<00:00, 201.86it/s]\n"," 99% 9750/9850 [00:50<00:00, 201.03it/s]\n"," 99% 9800/9850 [00:50<00:00, 200.96it/s]\n","100% 9850/9850 [00:51<00:00, 192.46it/s]\n","\n","\n","--- Final result: ---\n","               f_mae =  0.046482           \n","              f_rmse =  0.062725           \n","             H_f_mae =  0.035164           \n","             O_f_mae =  0.069118           \n","         psavg_f_mae =  0.052141           \n","            H_f_rmse =  0.045382           \n","            O_f_rmse =  0.087660           \n","        psavg_f_rmse =  0.066521           \n","               e_mae =  0.349667           \n","             e/N_mae =  0.003642           \n","               f_mae =  0.046482           \n","              f_rmse =  0.062725           \n","             H_f_mae =  0.035164           \n","             O_f_mae =  0.069118           \n","         psavg_f_mae =  0.052141           \n","            H_f_rmse =  0.045382           \n","            O_f_rmse =  0.087660           \n","        psavg_f_rmse =  0.066521           \n","               e_mae =  0.349667           \n","             e/N_mae =  0.003642           \n"]}],"source":["!nequip-evaluate --train-dir results/water/example-run-water --batch-size 50"]},{"cell_type":"markdown","metadata":{"id":"HQHrMMnsPaJO"},"source":["Again, energy errors of < 1meV/atom (converted from kcal/mol to eV), and force errors of ~45 meV/A 🎉"]},{"cell_type":"markdown","metadata":{"id":"H4r5FBXaum9n"},"source":["# LAMMPS"]},{"cell_type":"markdown","metadata":{"id":"0qIYIYyr1B4O"},"source":["We are now in a position to run MD with our potential. Here, we will minimize the geometry of the toluene molecule we trained on from a perturbed initial state. "]},{"cell_type":"markdown","metadata":{"id":"UirNBTlJ1BNZ"},"source":["<img src=\"https://github.com/mir-group/nequip_mrs_tutorial/blob/master/run.png?raw=true\" width=\"60%\">"]},{"cell_type":"markdown","metadata":{"id":"JQs0ijPhvAGb"},"source":["Set up a simple LAMMPS input file\n","\n","CAUTION: the reference data here are in kcal/mol for the energies and kcal/mol/A for the forces. The NequIP model will therefore also be predicting outputs in these units. We are therefore using `units real` in LAMMPS (see [docs](https://docs.lammps.org/units.html)). If your reference data are in other units, you should using the corresponding units command in LAMMPS (e.g. if you use eV, A then `units metal` would be appropriate, which would then also change time units from `fs` to `ps`)."]},{"cell_type":"code","execution_count":51,"metadata":{"id":"W090KfMsd2Do","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657049543816,"user_tz":-120,"elapsed":224,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"337ee1b7-6ffa-4f68-ccc7-f2d0c6236200"},"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘lammps_run’: File exists\n"]}],"source":["lammps_input_md = \"\"\"\n","units           metal\n","boundary        p p p\n","atom_style      atomic\n","\n","neighbor        1.0 bin\n","neigh_modify    every 10 delay 0 check no\n","\n","pair_style\tnequip\n","pair_coeff\t* * ../water-deploy.pth O H \n","mass            1 15.9994\n","mass            2 1.00794\n","\n","velocity        all create 330.0 23456789\n","\n","fix             1 all nvt temp 330.0 330.0 1.0\n","timestep        0.001\n","thermo_style    custom step pe ke etotal temp press vol\n","thermo          100\n","\n","dump            1 all custom 100 water_sheets.dump id type x y z\n","dump            2 all custom 1 dump_frc.lamppstrj id type element fx fy fz\n","dump_modify     2 element O H\n","dump            3 all custom 1 dump.lammpstrj id type element x y z\n","dump_modify     3 element O H\n","\n","run             10000\n","\"\"\"\n","\n","!mkdir lammps_run\n","with open(\"lammps_run/water_md.in\", \"w\") as f:\n","    f.write(lammps_input_md)"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"4tAHO8ODrpwG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657047403426,"user_tz":-120,"elapsed":213,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"2d110464-9cd1-4749-efcc-56141bd18fce"},"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘lammps_run’: File exists\n"]}],"source":["lammps_input_minimize = \"\"\"\n","units\treal\n","atom_style atomic\n","newton off\n","thermo 1\n","read_data structure.data\n","\n","pair_style\tnequip\n","pair_coeff\t* * ../water-deploy.pth O H \n","mass            1 15.9994\n","mass            2 1.00794\n","\n","neighbor 1.0 bin\n","neigh_modify delay 5 every 1\n","\n","minimize 0.0 1.0e-8 10000 1000000\n","write_dump all custom output.dump id type x y z fx fy fz\n","\"\"\"\n","!mkdir lammps_run\n","with open(\"lammps_run/water_minimize.in\", \"w\") as f:\n","    f.write(lammps_input_minimize)"]},{"cell_type":"code","source":["! cp /content/water-deploy.pth /content/lammps_run/."],"metadata":{"id":"Mu4kbiXOt1pI","executionInfo":{"status":"ok","timestamp":1657047316261,"user_tz":-120,"elapsed":251,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AvWZCw1zvjRc"},"source":["Here's starting configuration for Toluene at CCSD(T) accuracy. We will strongly perturb the inital positions by sampling from a uniform distribution $\\mathcal{U}([0, 0.5])$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JEPfMeGnJUVH"},"outputs":[],"source":["# toluene_example = \"\"\"15\n","#  Lattice=\"100.0 0.0 0.0 0.0 100.0 0.0 0.0 0.0 100.0\" Properties=species:S:1:pos:R:3 -169777.5840406276=T pbc=\"F F F\"\n","#  C       52.48936904      49.86911725      50.09520748\n","#  C       51.01088202      49.89609925      50.17978049\n","#  C       50.36647401      50.04650925      48.96054247\n","#  C       48.95673398      50.29576626      48.71580846\n","#  C       48.04533296      50.26023426      49.82589448\n","#  C       48.70932398      49.85770925      51.01923950\n","#  C       50.06326400      49.77782925      51.25691751\n","#  H       52.94467905      50.48672926      50.86545150\n","#  H       52.89060405      48.87175023      50.14480949\n","#  H       53.02173405      50.05890725      49.03968247\n","#  H       51.01439802      50.38234726      48.05314045\n","#  H       48.80598498      50.64314926      47.68195744\n","#  H       46.96754695      50.20586626      49.53998848\n","#  H       48.16716997      49.75850325      51.88622952\n","#  H       50.45791001      49.55387424      52.15303052\n","#  \"\"\"\n","\n","# with open('toluene.xyz', 'w') as f: \n","#     f.write(toluene_example)\n","\n","# # read as ASE objects\n","# atoms = read('toluene.xyz', format='extxyz')\n","\n","# # perturb positions\n","# p = atoms.get_positions()\n","# p += np.random.rand(15, 3) * 0.5\n","# atoms.set_positions(p)\n","# atoms.set_pbc(False)\n","\n","# # write to a LAMMPS file\n","# write(\"lammps_run/structure.data\", atoms, format=\"lammps-data\")"]},{"cell_type":"code","source":["wat_pos_frc_trj = read('/content/AIMD_data/wat_pos_frc-10k.extxyz')\n","write(\"/content/lammps_run/structure.data\", wat_pos_frc_trj,format='lammps-data')\n"],"metadata":{"id":"eXeHb2ZPvIbU","executionInfo":{"status":"ok","timestamp":1657047904302,"user_tz":-120,"elapsed":549,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}}},"execution_count":47,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QDuyueY11YBF"},"source":["### Run the LAMMPS command: "]},{"cell_type":"code","source":["cat /content/lammps_run/water_md.in"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RG1LE98LukSO","executionInfo":{"status":"ok","timestamp":1657047907354,"user_tz":-120,"elapsed":217,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"}},"outputId":"7c8da14a-ea12-477a-c556-45698bb536a8"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","units\treal\n","atom_style atomic\n","newton off\n","thermo 1\n","read_data structure.data\n","\n","pair_style\tnequip\n","pair_coeff\t* * ../water-deploy.pth O H \n","mass            1 15.9994\n","mass            2 1.00794\n","\n","neighbor 1.0 bin\n","neigh_modify delay 5 every 1\n","\n","minimize 0.0 1.0e-8 10000 1000000\n","write_dump all custom output.dump id type x y z fx fy fz\n"]}]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47791,"status":"ok","timestamp":1657047960283,"user":{"displayName":"Gabriele T.","userId":"11617781626997935386"},"user_tz":-120},"id":"gurLjNK5upvq","outputId":"96925bd2-876c-43dd-c68a-746d899b7a51"},"outputs":[{"output_type":"stream","name":"stdout","text":["LAMMPS (29 Sep 2021 - Update 2)\n","OMP_NUM_THREADS environment is not set. Defaulting to 1 thread. (src/comm.cpp:98)\n","  using 1 OpenMP thread(s) per MPI task\n","Reading data file ...\n","  orthogonal box = (0.0000000 0.0000000 0.0000000) to (9.8500000 9.8500000 9.8500000)\n","  1 by 1 by 1 MPI processor grid\n","  reading atoms ...\n","  96 atoms\n","  read_data CPU = 0.001 seconds\n","NEQUIP is using device cuda\n","NequIP Coeff: type 1 is element O\n","NequIP Coeff: type 2 is element H\n","Loading model from ../water-deploy.pth\n","Freezing TorchScript model...\n","WARNING: Using 'neigh_modify every 1 delay 0 check yes' setting during minimization (src/min.cpp:188)\n","Neighbor list info ...\n","  update every 1 steps, delay 0 steps, check yes\n","  max neighbors/atom: 2000, page size: 100000\n","  master list distance cutoff = 5\n","  ghost atom cutoff = 5\n","  binsize = 2.5, bins = 4 4 4\n","  1 neighbor lists, perpetual/occasional/extra = 1 0 0\n","  (1) pair nequip, perpetual\n","      attributes: full, newton off\n","      pair build: full/bin/atomonly\n","      stencil: full/bin/3d\n","      bin: standard\n","Setting up cg style minimization ...\n","  Unit style    : real\n","  Current step  : 0\n","Per MPI rank memory allocation (min/avg/max) = 4.202 | 4.202 | 4.202 Mbytes\n","Step Temp E_pair E_mol TotEng Press \n","       0            0   -408.60553            0   -408.60553            0 \n","       1            0   -420.54495            0   -420.54495            0 \n","       2            0   -432.87006            0   -432.87006            0 \n","       3            0   -441.79883            0   -441.79883            0 \n","       4            0   -450.14377            0   -450.14377            0 \n","       5            0   -459.24805            0   -459.24805            0 \n","       6            0   -468.36078            0   -468.36078            0 \n","       7            0   -476.06061            0   -476.06061            0 \n","       8            0   -481.56412            0   -481.56412            0 \n","       9            0   -485.98511            0   -485.98511            0 \n","      10            0    -489.5748            0    -489.5748            0 \n","      11            0   -492.44742            0   -492.44742            0 \n","      12            0   -495.50748            0   -495.50748            0 \n","      13            0    -499.7103            0    -499.7103            0 \n","      14            0   -503.79459            0   -503.79459            0 \n","      15            0   -506.76764            0   -506.76764            0 \n","      16            0   -508.97354            0   -508.97354            0 \n","      17            0   -513.66553            0   -513.66553            0 \n","      18            0   -520.43677            0   -520.43677            0 \n","      19            0   -527.22437            0   -527.22437            0 \n","      20            0   -535.33545            0   -535.33545            0 \n","      21            0   -544.86914            0   -544.86914            0 \n","      22            0   -547.32208            0   -547.32208            0 \n","      23            0   -551.94269            0   -551.94269            0 \n","      24            0    -556.8324            0    -556.8324            0 \n","      25            0   -564.08905            0   -564.08905            0 \n","      26            0   -592.16376            0   -592.16376            0 \n","      27            0    -616.3338            0    -616.3338            0 \n","      28            0   -617.53033            0   -617.53033            0 \n","      29            0   -665.52472            0   -665.52472            0 \n","      30            0    -687.7655            0    -687.7655            0 \n","      31            0   -688.50684            0   -688.50684            0 \n","      32            0   -690.28284            0   -690.28284            0 \n","      33            0   -697.59442            0   -697.59442            0 \n","      34            0   -699.10577            0   -699.10577            0 \n","      35            0   -699.13806            0   -699.13806            0 \n","      36            0   -710.41901            0   -710.41901            0 \n","      37            0   -710.65887            0   -710.65887            0 \n","      38            0   -710.86163            0   -710.86163            0 \n","      39            0   -711.04291            0   -711.04291            0 \n","      40            0   -712.82715            0   -712.82715            0 \n","      41            0    -714.5025            0    -714.5025            0 \n","      42            0   -714.52344            0   -714.52344            0 \n","      43            0   -714.55237            0   -714.55237            0 \n","      44            0    -730.1994            0    -730.1994            0 \n","      45            0   -956.65985            0   -956.65985            0 \n","      46            0   -1183.6732            0   -1183.6732            0 \n","      47            0   -1184.6262            0   -1184.6262            0 \n","      48            0   -2956.8721            0   -2956.8721            0 \n","      49            0   -3613.6965            0   -3613.6965            0 \n","      50            0   -4121.0176            0   -4121.0176            0 \n","      51            0   -6917.2998            0   -6917.2998            0 \n","      52            0    -7019.187            0    -7019.187            0 \n","      53            0   -7038.9077            0   -7038.9077            0 \n","      54            0   -7098.2832            0   -7098.2832            0 \n","      55            0   -7110.1792            0   -7110.1792            0 \n","      56            0   -7252.0522            0   -7252.0522            0 \n","      57            0   -7380.3325            0   -7380.3325            0 \n","      58            0   -7398.3809            0   -7398.3809            0 \n","      59            0   -7458.9624            0   -7458.9624            0 \n","      60            0   -7487.8848            0   -7487.8848            0 \n","      61            0   -7488.7461            0   -7488.7461            0 \n","      62            0    -7504.854            0    -7504.854            0 \n","      63            0   -7513.0552            0   -7513.0552            0 \n","      64            0   -9482.0928            0   -9482.0928            0 \n","      65            0   -9774.7451            0   -9774.7451            0 \n","      66            0    -11006.12            0    -11006.12            0 \n","      67            0   -12293.082            0   -12293.082            0 \n","      68            0   -13069.916            0   -13069.916            0 \n","      69            0   -13456.098            0   -13456.098            0 \n","      70            0   -13539.198            0   -13539.198            0 \n","      71            0    -13625.13            0    -13625.13            0 \n","      72            0   -13666.792            0   -13666.792            0 \n","      73            0   -13986.851            0   -13986.851            0 \n","      74            0   -14087.825            0   -14087.825            0 \n","      75            0   -14102.518            0   -14102.518            0 \n","      76            0   -14181.184            0   -14181.184            0 \n","      77            0   -14324.156            0   -14324.156            0 \n","      78            0   -14359.437            0   -14359.437            0 \n","      79            0   -14388.117            0   -14388.117            0 \n","      80            0   -14446.879            0   -14446.879            0 \n","      81            0   -14628.303            0   -14628.303            0 \n","      82            0   -14721.705            0   -14721.705            0 \n","      83            0   -14994.895            0   -14994.895            0 \n","      84            0   -15383.415            0   -15383.415            0 \n","      85            0       -15695            0       -15695            0 \n","      86            0   -15809.173            0   -15809.173            0 \n","      87            0   -15910.936            0   -15910.936            0 \n","      88            0   -15918.339            0   -15918.339            0 \n","      89            0    -15931.95            0    -15931.95            0 \n","      90            0   -15999.797            0   -15999.797            0 \n","      91            0   -16008.319            0   -16008.319            0 \n","      92            0    -16024.28            0    -16024.28            0 \n","      93            0    -16027.15            0    -16027.15            0 \n","      94            0   -16027.169            0   -16027.169            0 \n","      95            0   -16033.825            0   -16033.825            0 \n","      96            0   -16037.318            0   -16037.318            0 \n","      97            0   -16099.772            0   -16099.772            0 \n","      98            0   -16106.726            0   -16106.726            0 \n","      99            0   -16110.737            0   -16110.737            0 \n","     100            0   -16127.292            0   -16127.292            0 \n","     101            0   -16153.794            0   -16153.794            0 \n","     102            0   -16153.844            0   -16153.844            0 \n","     103            0   -16154.799            0   -16154.799            0 \n","     104            0   -16154.807            0   -16154.807            0 \n","     105            0   -16155.876            0   -16155.876            0 \n","     106            0   -16156.169            0   -16156.169            0 \n","     107            0   -16156.292            0   -16156.292            0 \n","     108            0   -16156.408            0   -16156.408            0 \n","     109            0   -16156.422            0   -16156.422            0 \n","     110            0   -16156.506            0   -16156.506            0 \n","     111            0   -16157.313            0   -16157.313            0 \n","     112            0   -16174.462            0   -16174.462            0 \n","     113            0   -16175.802            0   -16175.802            0 \n","     114            0   -16177.027            0   -16177.027            0 \n","     115            0    -16177.33            0    -16177.33            0 \n","     116            0   -16179.779            0   -16179.779            0 \n","     117            0   -16181.182            0   -16181.182            0 \n","     118            0   -16185.527            0   -16185.527            0 \n","     119            0   -16189.556            0   -16189.556            0 \n","     120            0   -16194.108            0   -16194.108            0 \n","     121            0   -16205.823            0   -16205.823            0 \n","     122            0   -16209.023            0   -16209.023            0 \n","     123            0   -16211.969            0   -16211.969            0 \n","     124            0   -16214.581            0   -16214.581            0 \n","     125            0   -16216.091            0   -16216.091            0 \n","     126            0   -16216.925            0   -16216.925            0 \n","     127            0   -16217.105            0   -16217.105            0 \n","     128            0   -16217.726            0   -16217.726            0 \n","     129            0   -16218.797            0   -16218.797            0 \n","     130            0   -16227.909            0   -16227.909            0 \n","     131            0   -16228.731            0   -16228.731            0 \n","     132            0    -16368.54            0    -16368.54            0 \n","     133            0   -16454.004            0   -16454.004            0 \n","     134            0   -16470.869            0   -16470.869            0 \n","     135            0   -16682.152            0   -16682.152            0 \n","     136            0   -16685.824            0   -16685.824            0 \n","     137            0   -16700.977            0   -16700.977            0 \n","     138            0   -16703.285            0   -16703.285            0 \n","     139            0     -16704.9            0     -16704.9            0 \n","     140            0   -16706.066            0   -16706.066            0 \n","     141            0   -16710.877            0   -16710.877            0 \n","     142            0   -16714.248            0   -16714.248            0 \n","     143            0   -16718.201            0   -16718.201            0 \n","     144            0    -16718.84            0    -16718.84            0 \n","     145            0   -16729.352            0   -16729.352            0 \n","     146            0   -16730.529            0   -16730.529            0 \n","     147            0   -16734.178            0   -16734.178            0 \n","     148            0   -16742.762            0   -16742.762            0 \n","[2b79e67b07a7:12139] *** Process received signal ***\n","[2b79e67b07a7:12139] Signal: Segmentation fault (11)\n","[2b79e67b07a7:12139] Signal code: Address not mapped (1)\n","[2b79e67b07a7:12139] Failing at address: 0x7fa26840b20d\n","[2b79e67b07a7:12139] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980)[0x7fa26aeb0980]\n","[2b79e67b07a7:12139] [ 1] /lib/x86_64-linux-gnu/libc.so.6(getenv+0xa5)[0x7fa26aaef775]\n","[2b79e67b07a7:12139] [ 2] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(_ZN13TCMallocGuardD1Ev+0x34)[0x7fa26b35ae44]\n","[2b79e67b07a7:12139] [ 3] /lib/x86_64-linux-gnu/libc.so.6(__cxa_finalize+0xf5)[0x7fa26aaf0605]\n","[2b79e67b07a7:12139] [ 4] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(+0x13cb3)[0x7fa26b358cb3]\n","[2b79e67b07a7:12139] *** End of error message ***\n","^C\n"]}],"source":["!cd /content/lammps_run/ && ../lammps/build/lmp -in water_md.in"]},{"cell_type":"code","source":["!pip3 install nglview\n","import nglview as nv"],"metadata":{"id":"AZUCqNnfxTe0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#proj1 = mda.Merge(backbone1)\n","#proj1.load_new(coordinatesu1, order=\"fac\")"],"metadata":{"id":"QYxvyvyK2ctM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#view = nv.show_mdanalysis(proj1.atoms)\n","#view"],"metadata":{"id":"-MnKFEmC2gE_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install moviepy==0.2.2.11\n","# !pip install imageio==1.6"],"metadata":{"id":"V1-YetGR2ij-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from nglview.contrib.movie import MovieMaker\n","# movie = MovieMaker(view, output='pc1u1.gif', in_memory=True)\n","# movie.make()"],"metadata":{"id":"qPFHrJJm2lEe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BOKfQ83JQESc"},"source":["We see LAMMPS converges quickly to a minimum. Let's check how well we did. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPcQU9HbsaVl"},"outputs":[],"source":["# read the final structure back in \n","#minimized = read('./lammps_run/output.dump', format='lammps-dump-text')"]},{"cell_type":"markdown","metadata":{"id":"brqGqVtdWpCF"},"source":["### Compare optimized bond length to true coupled cluster reference from CCCBDB"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1644071930562,"user":{"displayName":"Simon Batzner","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01516403350906604395"},"user_tz":300},"id":"ltFlaHrTRn97","outputId":"1c6a131b-01a5-4b39-b972-945508bb7c6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Relative Error in bond length w.r.t. Coupled Cluster from CCCBDB: 0.100%\n"]}],"source":["# get distances of optimized geometry (reference data: CCSD(T) [Psi4, cc-pVDZ])\n","# d_12 = minimized.get_distances(1, 2)\n","\n","# # reference: https://cccbdb.nist.gov/geom3x.asp?method=6&basis=2, coupled cluster\n","# d_12_ccd = 1.4086\n","\n","# print('Relative Error in bond length w.r.t. Coupled Cluster from CCCBDB: {:.3f}%'.format((100 * np.abs(d_12 - d_12_ccd) / d_12_ccd)[0]))"]},{"cell_type":"markdown","metadata":{"id":"iT64gDUeQOvO"},"source":["We find a final relative error close to Coupled Cluster accuracy 🎉"]},{"cell_type":"markdown","metadata":{"id":"T4ZD6U0EkIp5"},"source":["## Next Steps\n","\n","This concludes our tutorial. A next step would be to head over to https://github.com/mir-group/nequip, install NequIP and get started with your own system. If you have questions, please don't hesitate to reach out to batzner@g.harvard.edu, we're happy to help! \n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"my-short-nequip-tutorial.ipynb","provenance":[{"file_id":"1_r348f6oIyKxH4FnpKeD8g4QjwDhP8mT","timestamp":1656689687220}]},"gpuClass":"standard","interpreter":{"hash":"c9be9acec9edbd902b751bf46a8fbd7b71bbc5f0438c72d3ebaee4bffeb5e5e4"},"kernelspec":{"display_name":"Python 3.7.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"nbformat":4,"nbformat_minor":0}